<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[《实现领域驱动设计》读书笔记(5) - 战术建模之值对象]]></title>
    <url>%2F%E6%9E%B6%E6%9E%84%E4%B8%8E%E6%A8%A1%E5%BC%8F%2FDDD%2Fnote-ddd-tactical-value-object%2F</url>
    <content type="text"><![CDATA[值对象用于度量和描述事物，即便一个领域概念必须建模成实体，在设计时也应该更偏向于将其作为值对象的容器，而不是子实体的容器 笔者曾一度认为值对象就是 C# 语言中使用 struct 结构来表示的多个数据代表一个整体的集合，后来发现书中讲到的值对象无关技术实现，而是从概念上定义它的职责，包括不可变性和非唯一性。 同样的，在有了实体这把武器之后，当一个实体需要嵌套其他对象时，实体经常遭到滥用。当面临将对象定义为实体还是值对象的选择时，由于缺乏对于值对象的充分认识，很多开发人员选择了嵌套实体。 不变性当我们只关心某个对象的属性时，该对象便可作为一个值对象，为其添加有意义的属性，并赋予它们相应的行为。值对象在其生命周期中是「不可变」的，本身代表了某种状态，它没有任何身份标识，也应该尽量避免像实体一样复杂。在设计得当的前提下，我们可以对值对象的实例进行创建和传递，甚至在使用完之后将其直接扔掉。我们不必担心客户代码对值对象进行修改，一个值对象的生命周期可长可短，它就像一个无害的过客在系统中来来往往。 当决定一个领域概念是否是一个值对象时，考虑以下特征： 它度量或者描述了领域中的一件东西 它可以作为不变量 它将不同的相关的属性组合成一个概念性的整体 当度量和描述改变时，可以用另一个值对象予以替换 它可以和其他值对象进行相等性比较 它不会对协作对象造成副作用 为了保持值对象的不变性，创建它所依赖的参数必须一次性全部传给其构造函数，之后任何时间都不可能再改变它。有时根据需要，会在值对象中引用实体对象，这种情况需要谨慎，当实体对象的状态发生改变时，引用它的值对象也将发生改变，这违背了值对象不变性特征。 概念整体编程语言提供的基元类型(如 string, int, double 等)似乎是值对象的最佳类型，但有时，这种思维方式会造成对基元类型的滥用。 假如需要在 「ThingOfWorth」 类中加入名为 「Name」 的属性，我们自然而然的会想到将其定义为 string 类型，但很快我们就发现该类型的名字需要以不同的方式进行展示，此时，处理展示方式的逻辑就会莫名其妙的由客户代码来完成，例如：123// 客户代码String name = thingOfWorth.name();String capitalizedName = name.subString(0,1).toUpperCase() + name.subString(1).toLowerCase(); 在以上示例中，客户代码自己试图解决 name 的大小写问题。通过定义 「ThingName」 类型，我们可以将与 name 有关的所有逻辑操作放到该类型中，然后在构造该值对象时进行格式化，客户代码只需调用相应的方法即可得到结果，而不必自行处理这些逻辑。 有些编程语言允许我们简单地向一个类添加新的行为(例如 C# 的扩展方法)。此时，你可能会想着用 Double 类型来表示货币，如果需要计算不同货币之间的汇率，我们只需要向 Double 类型添加 convertToCurrency(Currency aCurrency) 扩展方法即可。但是在这种场景下使用语言特性就一定是一个好主意吗？首先，和货币相关的行为很有可能丢失在浮点数计算中；其次，Double 类型也丝毫没有表达出领域概念。很快，我们就会丢掉领域关注点。 当你试图将多个属性加在一个实体上，这有可能弱化了各个属性之间的关系，那么此时就应该考虑将这些相互关联的属性组合在一个值对象中了。每个值对象都是一个「内聚的概念整体」，它表达了通用语言中的一个概念。 可替换性值对象的可替换性可通过数字的替换来理解，假设领域中有一个名为 total 的概念，该概念用整数表示。如果 total 的当前值为 3，但是之后需要重设为 4，此时我们并不会将整数修改成 4，而是简单地将 total 的值重新赋值为 4。 从语言层面来说，这里的修改其实是对该属性赋新值，但看上去像是修改，实际上只是语法糖，原先为 3 的内存并不会被修改为 4，而是被新的代表 4 的内存块替代。 考虑下面一种更复杂的值对象替换：123FullName name = new FullName("金","沐");// 稍后name = new FullName("金","灶沐"); 这里，我们并没有使用 FullName 类型的某个方法来修改其自身的状态(这破坏了值对象的不变性)，而是构造一个新的值对象实例来替换原来的实例。 值对象相等性值对象的相等性应该由组成其实例的每一个属性及其类型来决定，在上文的 「FullName」 对象中，当两个 「FullName」 实例的每个属性及其类型都相等，我们才认为两个实例相等，尽管他们在内存中是不同的地址。值对象的相等性可用来支撑「聚合」唯一标识的比较，实体的唯一标识是不能改变的，这可以部分通过值对象的不变性实现。值对象的整体概念也可以用来支撑不只一个属性的实体标识，同时，如果实体的唯一标识需要一些「无副作用行为」，这些行为便可以在值对象上实现。 无副作用行为一个对象的方法可以设计成一个「无副作用函数(Side-Effect Free Function)」，该函数表示对某个对象的操作，只用于产生输出，而不会修改对象的状态。对于不变的值对象而言，所有的方法都必须是无副作用函数。下面的例子通过调用 「FullName」 对象上的无副作用方法将该对象本身替换成另一个实例：123FullName name = new FullName("金","沐");// 稍后name = name.withMiddleInitial("灶"); 这里的代码更具表达性，withMiddleInitial 方法并没有修改值对象的状态，因此它不会产生副作用。该方法通过已有 firstName 和 lastName，外加传入的 middleName 创建一个新的 FullName 值对象实例。withMiddleInitial() 还捕获到了重要的领域业务逻辑，从而避免了将这些逻辑泄漏到客户代码中。 这里所说的捕获重要的领域业务逻辑，是指该方法本身是具有表达性的，比起使用 new 语句创建实例，更像是调用了该实例支持的某个行为满足了客户代码的需求。 有些值对象的方法引用了实体，这存在一些问题。例如下面的代码，我们有一个实体对象 product，该对象被值对象 BusinessPriority 引用。1float priority = businessPriority.priorityOf(product); 我们至少可以看出以下问题： BusinessPriority 不仅依赖 Product 类型，还试图去理解该实体的内部状态，我们应该尽量使值对象只依赖于它自己的属性，并且只理解它自身的状态。 阅读本段代码的人并不知道使用了 Product 的哪些部分，这种表达方法并不明确，从而降低了模型的清晰度。更好的方式是只传入需要用到的 Product 属性。 更重要的是，在将实体作为参数的值对象方法中，我们很难看出该方法是否会对实体进行修改，测试也将变得非常困难。 有了以上分析，我们需要对值对象进行改进，要增加一个值对象的健壮性，我们传给值对象方法的参数依然应该是值对象。这样我们可以获得更高层次的无副作用行为：1float priority = businessPriority.priority(product.businessPriorityTotals()); 这里，我们把 Product 实体的 BusinessPriorityTotals 值对象传递给了 priority() 方法。 如果打算使用编程语言提供的基本值对象类型，而不使用特定的值对象，我们是无法将领域特定的无副作用函数分配给编程语言提供的基元值对象的。有些真正简单的属性是没有必要特殊对待的。例如，一些布尔类型或数值类型，它们已经能够自给了，并不需要额外的功能支持，也并不和实体中的其他属性关联。这些简单的属性称为意义整体。 最小化集成当模型概念从上游上下文流入下游上下文时，尽量使用值对象来表示这些概念。这样做的好处是可以达到最小化集成，即最小化下游模型中用于管理职责的属性数目。 用值对象表示标准类型系统中既有表示事物的实体和描述实体的值对象，同时还存在「标准类型(Standard Type)」来区分不同的类型。假设通用语言中定义了一个 「PhoneNumber」 值对象，同时需要为每个 「PhoneNumber」 对象制定一个类型，用以区分家庭电话，移动电话，工作电话还是其他类型的电话号码。不同类型的电话号码类型需要建模成一种类的层级关系吗？为每一个类型创建一个类对于客户代码的使用来说是非常困难的。此时，你需要标准类型来描述不同的电话号码，比如 Home，Mobile，Work 或者 Other。 枚举类型是实现标准类型的一种简单方法。枚举提供了一组有限数量的值对象，它非常轻量且无副作用。通常来说，没有必要为标准类型提供描述信息，只需要名字就足够了。为什么？文本描述通常只在用户界面层中才会用到，此时可以用一个显示资源和类型名字匹配起来。很多时候用于显示的文本都需要进行本地化，因此将这种功能放在模型中并不合适。通常来说，在模型中使用标准类型的名字是最好的方式。 为了维护方便，最好是为标准类型创建单独的限界上下文。 有些标准类型所表达的概念不像是某种标准而更像是一种状态，此时标准类型实现为状态模式，但为每一种状态创建单独的类会使系统变得复杂。对于实体的状态类来说，有些行为来自于自身，有些继承自抽象基类，这一方面在子类和父类之间形成了紧耦合，另一方面使代码的可读性变差。如果你不打算使用状态模式，那么枚举可能是最简单的方法。 一个共享不变的值对象可以从持久化存储中获取，此时可以通过标准类型的「领域服务」或「工厂」来获取值对象。我们应该为每组标准类型创建一个领域服务或工厂(比如一个服务处理电话号码类型，一个服务处理邮寄地址类型，另一个服务处理货币类型)，服务或工厂将按需从持久化存储中获取标准类型，而客户方代码并不知道这些标准类型是来自数据库中的。另外，使用领域服务或工厂还使得我们可以加入不同的缓存机制，由于值对象在数据库中是只读的，并且在整个系统中是不变的，缓存机制也将变得更加简单安全。 总的来说，建议尽量使用枚举来表示标准类型，即便你认为某个标准类型更像一种状态模式。 实现通常来说，值对象至少包含两个构造函数，第一个构造函数接受用于构建对象状态的所有属性参数，称为主构造函数。该构造函数调用私有的 setter 方法初始化默认的对象状态，该私有的 setter 方法向我们展示了一种自委派性。 只有主构造函数才能使用自委派性来设置属性值，除此之外，其他任何方法都不能使用 setter 方法。由于所有的 setter 方法都是私有的，消费方是没有机会调用这些方法的，这是保持值对象不变性的两个重要因素。 第二个构造函数用于将一个值对象复制到另一个新的值对象，即复制构造函数。它将构造过程委派给主构造函数，先从原对象中取出各个属性，再将这些属性作为参数传给主构造函数。 复制构造函数对于测试来说是非常重要的，测试对象时，我们希望验证值对象的不变性，通过复制构造函数创建一个原实例的副本，验证两者的相等性。 持久化值对象以下着重讨论如何持久化包含值对象的聚合实例。聚合的读取和保存通过资源库完成。 有时，值对象需要以实体的身份进行持久化。换句话说，某个值对象实例会单独占据一张表中的某条记录，而该表也是专门为这个值对象类型而设计的，它甚至拥有自己的主键列。当面临「对象 - 关系阻抗失配」时，考虑以下几个问题： 我当前所建模的概念表示领域中的一个东西呢，还是只是用于描述和度量其他东西？ 如果该概念起描述作用，那么它是否满足值对象的几个特征？ 将该概念建模成实体是不是只是持久化上的考虑？ 将该概念建模成实体是不是因为它拥有唯一标识，我们关注的是对象实例的个体性，并且需要在其整个生命周期中跟踪其变化？ 我们不应该使持久化机制影响到对值对象的建模。无论使用什么技术来完成数据建模，数据库实体，主键，引用完整性和索引都不能用来驱动你对领域概念的建模。 单个值对象当实体包含单个值对象，值对象的属性需要和包含它的实体保存在一张数据表中时，其列名最好采用与数据库一致的形式，例如：123BusinessPriority.Ratings.Benefit=&gt;business_priority_ratings_benefit 值对象集合序列化到单个列中将一个 List 或 Set 的值对象保存在单个列中需要考虑以下问题： 列宽：有些对象集合可以包含任意多个元素，但数据库的列宽是有限制的。 查询：如果需要对该集合中的元素进行查询，无法用 SQL 语句实现，但从一个集合中查询一个或多个属性是比较少见的情况。 序列化器和反序列化器：需要自定义类型来实现序列化器和反序列化器，这只是增加了工作量。 使用数据库实体保存多个值对象我们不能因为某个概念非常符合数据库实体而将其建模成领域模型中的实体。有时，是对象 - 关系阻抗失配需要我们采用这种方法，但这绝非 DDD 原则。要实现这种方案，我们可以采用「层超类型」，或又名「委派身份标识(主键)」。下面的例子使用了两层层超类型：123456789public abstract class IdentifiedDomainObject: ISerializable&#123; private long _id = -1; protected long Id &#123; get =&gt; this._id; set =&gt; this._id = value; &#125;&#125; 接下来定义另一层层超类型，该层超类型是值对象专属的：1234public abstract class IdentifiedValueObject: IdentifiedDomainObject&#123;&#125; 虽然 IdentifiedValueObject 什么也不做，但它显式地表明了建模意图。IdentifiedValueObject 还应该有另外一个专属于实体的抽象子类 Entity。现在，每一个值对象类型都可以方便地获得一个隐藏的委派主键，我们可以自由地将其映射成数据库实体，而在领域模型中将其建模成值对象。 委派标识主要用于数据建模，其没有领域模型含义，这里更多是说明当实体包含值对象集合并且需要对其进行查询时如何对它们进行持久化，这样的值对象在数据库中会有一张单独的表，但这并不代表他们就是领域模型中的实体。 ORM 与枚举状态对象参考 《实现领域驱动设计》 P230]]></content>
      <categories>
        <category>架构与模式</category>
        <category>DDD</category>
      </categories>
      <tags>
        <tag>ddd</tag>
        <tag>note</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《实现领域驱动设计》读书笔记(4) - 战术建模之实体]]></title>
    <url>%2F%E6%9E%B6%E6%9E%84%E4%B8%8E%E6%A8%A1%E5%BC%8F%2FDDD%2Fnote-ddd-tactical-entity%2F</url>
    <content type="text"><![CDATA[当我们需要考虑一个对象的个性特征，或需要区分不同的对象时，我们引入实体这个领域概念。一个实体是一个唯一的东西，并且可以在相当长的时间内持续地变化。「唯一的身份标识」和「可变性特征」将实体和值对象区分开来。 常年进行 .NET 生态开发的人很容易把实体等同于 Entity Framework 中的 Entity，认为 Entity 就是数据库模型的对象映射，然而书中所说的实体完全是不同的概念，是面向业务领域的模型，纯数据模型而不具备任何行为的实体被称作「贫血领域模型」 唯一标识以下是常用的创建实体身份标识的策略，从简单到复杂依次为： 用户提供一个或多个初始唯一值作为程序输入，程序应该保证这些初始值是唯一的 程序内部通过某种算法自动生成身份标识 程序依赖于持久化存储，比如数据库来生成唯一标识 另一个限界上下文已经决定出了唯一标识，这作为程序的输入，用户可以在一组标识中进行选择 聚合根实体对象的唯一标识是全局唯一的，在同一个聚合中，一般实体的唯一标识只要和聚合内的其他实体区分开来即可。 将唯一标识的生成放在「资源库(Repository)」中是一种自然的选择 从数据库中获取标识比直接从应用程序中生成标识要慢得多，一种解决方法是将数据库序列缓存在应用程序中，比如缓存在资源库中。 有时，标识的生成和赋值时间对于实体来说是重要的，及早标识生成和赋值发生在持久化实体之前。延迟标识生成和赋值发生在持久化实体的时候 委派标识有些 ORM 工具通过自己的方式来处理对象的身份标识，如果我们自己的领域需要另外一种实体标识，此时两者将产生冲突。为了解决这个问题，需要使用两种标识，一种为领域所用，一种为 ORM 所用，在 Hibernate 中，被称为委派标识。委派标识与领域中的实体标识没有任何关系，委派标识只是为了迎合 ORM 创建的。 标识稳定性在多数情况下，我们都不应该修改实体的唯一标识，这样可以在实体的整个生命周期中保持标识的稳定性。 实体及其本质特征贫血领域模型过多拥有 getter 和 setter 方法而缺乏行为的模式可以概括为贫血领域模型。 强类型实体标识标识需要有特殊的类型还是可以使用简单的字符串？实体的唯一标识会用在很多地方，它可以用在不同限界上下文的所有实体上。在这种情况下，使用一个强类型的实体标识可以保证所有订阅方所持有的实体都能使用正确的标识。 这里所说的实体标识更多是指聚合根的实体标识？ 模型所扮演的角色在面向对象编程中，通常由接口来定义实现类的角色，在正确的设计情况下，一个类对于每一个它所实现的接口都存在一种角色。如果一个类没有显式的角色 - 即该类没有实现任何接口，那么默认情况下它扮演的即是本类的角色，也即，该类的公有方法表示该类的隐式接口。 不变条件不变条件是在整个实体生命周期中都必须保持事务一致性的一种状态，有时一个实体维护了一个或多个不变条件。如果实体的不变条件要求该实体所包含的所有对象都不能为 null，那么这些状态需要作为参数传递给构造函数，并且在相应的 setter 方法中对新值进行非 null 检查来确保一致性。 验证 自封装：无论从何处访问对象的状态，即使从对象内部访问数据，都必须通过 getter 和 setter 方法实现。 自封装首先为对象的实例变量和类变量提供了一层抽象。其次，我们可以方便地在对象中访问其所引用对象的属性。重要的是，自封装使验证变得非常简单。 验证的主要目的在于检查模型的正确性，我们将对模型进行三个级别的验证： 验证属性: 通过自封装的方式在 setter 方法中对属性进行验证 验证整体对象: 为了实现对整体对象的验证，可创建 Entity 层超类型，在其中定义 Validate 虚方法，实现类通过重写该方法按需调用验证逻辑，同时，由于验证逻辑的变化速度比实体本身还要快，所以应该将真正的验证逻辑委托给专门的验证类，实体在其 Validate 方法中使用这些验证类，从而使验证逻辑与实体解耦。 验证组合对象: 关注点从单个实体是否合法转向多个实体的是组合是否全部合法，包括一个或多个聚合实例。最好的方式是把这样的验证过程创建成一个领域服务，该领域服务通过资源库读取需要验证的聚合实例，然后对每个实例进行验证，可以是单独验证，也可以和其他聚合实例一起验证。 跟踪变化领域专家可能会关心发生在模型中的一些重要事件，此时就需要对实体的一些特殊变化进行跟踪了。跟踪变化最实用的方法是「领域事件」和「事件存储」。可以为领域专家所关心的所有状态改变都创建单独的事件类型，事件的名字和属性表明发生了什么样的事件。当命令操作执行完后，系统发出这些领域事件，订阅方接收发生在模型上的所有事件。接收到事件后，订阅方将事件保存在事件存储中。]]></content>
      <categories>
        <category>架构与模式</category>
        <category>DDD</category>
      </categories>
      <tags>
        <tag>ddd</tag>
        <tag>note</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《实现领域驱动设计》读书笔记(2) - 战略建模]]></title>
    <url>%2F%E6%9E%B6%E6%9E%84%E4%B8%8E%E6%A8%A1%E5%BC%8F%2FDDD%2Fnote-ddd-strategic%2F</url>
    <content type="text"><![CDATA[通用语言(Ubiquitous Language)通用语言是团队成员间能够互相理解的语言，它统一了开发团队和领域专家之间的术语，从而提高了沟通效率。通用语言不同于「统一建模语言(UML, Unified Modelling Language)」，UML 是开发人员之间的语言。 通用语言的几点注意： 限界上下文和通用语言存在一对一的关系 只有当团队工作在独立的限界上下文中时，通用语言才是 “通用”的 虽然我们只工作在一个限界上下文中，但我们可能经常会与其他限界上下文打交道，这时可以通过上下文映射图来对这些限界上下文进行集成，每个限界上下文都有自己的通用语言，而有时语言间的术语可能有重叠的部分 领域和子域在 DDD 中，一个领域可能包含多个限界上下文，通常一个限界上下文对应一个子域。“领域”一词承载了太多含义，领域既可以表示整个业务系统，也可以表示其中的某个核心域或支撑子域，一个模型在一个子域应该表达出清晰的含义。 例如，在一个电子商务系统中，至少要向买家展示不同类别的产品，允许买家下单和付款，还需要安排物流。这个特定的领域可以划分为「产品目录(Product Catalog)」，「订单(Order)」，「发票(Invoicing)」和「物流(Shipping)」。子域不一定会很大，可以简单到只包含一套算法，这套算法对业务系统来说可能非常重要，但并不包含在核心域之中。在正确实施 DDD 的情况下，这种简单的子域可以以「模块(Module)」的形式从核心域中分离出来。 核心域通常代表了促进业务成功的核心功能，核心域应该配备最好的领域专家和开发团队。 支撑子域如果一个限界上下文对应着业务的某些重要方面，但却不是核心，那么它便是一个「支撑子域」。 通用子域如果一个子域被用于整个业务系统，那么这个子域便是「通用子域」。例如在众多系统中都有的「认证与授权子系统」通常就是一个通用子域。 问题空间(Problem Space)和解决方案空间(Solution Space) 问题空间是领域的一部分，对问题空间的开发将产生一个新的核心域，对问题空间的评估应该同时考虑已有子域和额外所需子域。因此，问题空间是核心域和其他子域的组合。 解决方案空间包括一个或多个限界上下文，因为限界上下文即是一个特定的解决方案。 在我们实施某个解决方案之前，我们需要对问题空间和解决方案空间进行评估，首先回答以下问题： 这个战略核心域的名字是什么？ 它的目标是什么？ 它包含哪些概念？ 它的支撑子域和通用子域是什么？ 如何安排项目人员？ 你能组件一支合适的团队吗？ 解决方案空间在很大程度上受到现有系统和技术的影响。我们应该根据限界上下文仔细考虑以下问题： 有哪些软件资产是已经存在的，它们可以重用吗？ 哪些资产是需要创建的，或者从别处获得？ 这些资产是如何集成在一起的？ 还需要什么样的集成？ 假设已经有了现有资产和那些需要被创建的资产，我们还需要做些什么？ 核心域和那些支撑项目的成功几率如何？会不会出现由于其中一个失败而导致整个项目失败的可能？ 有哪些地方我们使用了完全不同的术语？ 限界上下文之间在哪些地方存在概念重叠？ 这些重叠的概念在不同的限界上下文之间是如何映射和翻译的？ 哪些限界上下文包含了核心域中的概念，其中使用了哪些战术建模工具？ 限界上下文(Bounded Context)限界上下文采用 模型+上下文 的形式来命名。 同一个概念在不同的限界上下文中的关注点是不一样的，例如在一个电子商务系统中，”顾客” 这个概念在订单系统上下文中，其关注点有先前购买情况，忠诚度，可买产品，折扣和物流方式，而在下单时，”顾客” 的上下文包括名字，产品寄送地址，订单总价和一些付款术语。所以 “顾客” 在这个例子中并没有一个清晰的含义。类似的问题其实是脱离了不同限界上下文中协作概念的关注点，在不同的限界上下文中，”顾客” 扮演了不同的协作概念，例如在产品目录上下文中，”顾客” 可以用 “浏览者” 表示，而在订单上下文中，”顾客” 以 “购买者” 表示。”顾客” 一词本身包含了太多可能的角色，不同的角色有不同的职责。在不同的限界上下文中，不同角色充当了 “顾客” 的某种角色，进而使得单一限界上下文该角色的含义清晰，并与其他限界上下文的关注点得以分离。 限界上下文是一个显式的语义边界，领域模型便存在于这个边界之内。领域模型把通用语言表达成软件模型，创建边界的原因在于，每一个模型概念，包括它的属性和行为，在边界之内都具有特殊的含义。限界上下文并不旨在创建单一的项目资产，它并不是一个单独的组件，文档或者框图。因此，它并不是一个 jar 或者 dll，但这些可以用来表示限界上下文。 在上下文边界之外，我们通常不会使用该上下文之内的对象实例，但是不同上下文中彼此关联的对象可能共享一些状态。 一个限界上下文并不是只包含领域模型。模型自然是限界上下文的一等公民，但它并不局限于此。它通常标定了一个系统，一个应用程序或者一个业务服务。有时一个限界上下文包含的内容可能比较少，例如，一个通用子域可能只包含领域模型。 当模型驱动着数据库 Schema 的设计时，数据库 Schema 也应该位于该模型所处的上下文边界之内。因为数据库 Schema 是由建模团队设计，开发并维护的。这也意味着数据库中表和列的名字应该和模型的名字保持一致。另一方面，如果数据库 Schema 已经存在，或者另有一个专门的数据建模团队要求有别于模型的数据库 Schema 设计，此时的 Schema 便不能和模型位于同一个限界上下文中了。 如果「用户界面(UI)」被用于渲染模型，并且驱动着模型的行为设计时，同样，该用户界面也应该属于模型所在的上下文边界之内。但是，这并不表示我们应该在用户界面中对领域进行建模，因为这样将导致「贫血领域对象」或者任何试图将领域概念带到领域模型之外的举措。 通常情况下，一个系统/应用程序的使用者并不只是人，还可能是另外的计算机系统。系统中有可能存在诸如 Web 服务之类的组件，或者使用 REST 资源来与模型交互，在所有可能的情形下，这些面向服务的组件都应该位于上下文边界之内。 用户界面和面向服务的端点都会将操作委派给「应用服务(Application Service)」，应用服务包含了不同类型的服务，比如安全和事务管理等。对于模型来说，应用服务扮演的是一种门面模式(Facade)。同时，应用服务还具有任何管理功能，它将来自用例流(Use Case Flow)的请求转换成领域逻辑的执行流。应用服务也是位于上下文边界之内的。 限界上下文主要用来封装通用语言和领域对象，但同时它也包含了那些为领域模型提供交互手段和辅助功能的内容。需要注意的是，对于架构中的每个组件，我们都应该将其放在适当的地方。限界上下文可以包含「模块(Module)」，「聚合(Aggregate)」，「领域事件(Domain Event)」和「领域服务(Domain Service)」。限界上下文应该足够大，以表达它所对应的整套通用语言。 上下文映射图上下文映射图表示了不同限界上下文之间是如何集成的，任何两个限界上下文可能存在某种模式： 合作关系(Partnership): 两个团队各自负责自己的上下文，在接口的演化上进行合作以同时满足两个系统的需求 共享内核(Shared Kernel): 两个上下文对模型和代码的共享产生一种紧密的依赖性，需要为共享的部分指定一个显式的边界，并保持共享内核的最小化。在没有与另一个团队协商的情况下，共享内核是不能改变的。应该引入一种持续集成机制来保证共享内核与通用语言的一致性。 客户方-供应方开发(Customer-Supplier Development): 两个上下文处于上-下游关系，上游团队独立于下游团队完成开发，下游团队的开发可能会受到很大的影响。因此在上游团队的计划中，应该顾及下游团队的需求。 遵奉者(Confirmist): 在存在上-下游关系的两个团队中，上游团队完全不考虑下游团队的需求，而下游团队只能盲目地使用上游团队的模型。 防腐层(Anticorruption Layer): ACL，当两个上下文不是合作，共享内核或者客户-供应方关系时，翻译将变得复杂。下游团队需要根据自己的领域模型创建一个单独的层，该层作为上游系统的代理提供功能。防腐层通过已有的接口与其他系统交互，在防腐层内部，在自己的模型和他方的模型之间进行翻译转换。如果翻译过于复杂，并且需要大量的数据复制和同步，从而使得翻译前后的模型存在很大的相似度，那么你可能过多地使用了外部上下文中的数据，导致自己的模型混淆不清了。 开放主机服务(Open Host Service): OHS，定义一种协议，其他系统通过该协议来访问该系统，协议是公开的，这样任何想与这个系统集成的人都可以使用该协议。通常来讲，我们可以将开发主机服务看成是远程过程调用 (Remote Procedure Call) 的 API。同时，它也可以通过消息机制实现。 发布语言(Published Language): PL，在两个限界上下文之间翻译模型需要一种公用的语言。此时你应该使用一种发布出来的共享语言来完成集成交流。发布语言通常与开放主机服务一起使用，常见的发布语言使用 XML Schema。在使用 REST 服务时，可以使用 XML 和 JSON，也可以使用 Google Proto Buffer 来表示。使用 REST 的好处是每个客户端都可以指明使用哪种语言，同时还可以指明资源的展现方法。 另谋他路(SeperateWay): 如果两套系统之间没有任何显著的关系，那么他们是完全解耦的，集成总是昂贵的。 大泥球(Big Ball of Mud): 当我们检查已有系统时，经常会发现系统中存在混杂在一起的模型，它们之间的边界非常模糊，此时应该为整个系统绘制一个边界，然后将其归纳在大泥球范围之列。 系统间集成经常依赖于 RPC。RPC 与编程语言中的过程调用非常相似。和在相同进程中的过程调用不同的是，RPC 更容易产生有损性能的时间延迟，并有可能导致调用彻底失败。虽然 REST 并不是真正意义上的 RPC，但它却具有与 RPC 相似的特征。如果系统所依赖的状态已经存在于本地，那么系统将获得更大的自治性。DDD 的做法是在本地创建一些由外部模型翻译而成的领域对象，这些对象保留着本地模型所需的最小状态集。为了初始化这些对象，我们只需要有限的 RPC 调用或 REST 请求。然而，要与远程模型保持同步，最好的方式是在远程系统中采用面向消息的通知机制(例如 RabbitMQ)。消息通知可以通过服务总线进行发布，也可以采用消息队列或者 REST。]]></content>
      <categories>
        <category>架构与模式</category>
        <category>DDD</category>
      </categories>
      <tags>
        <tag>ddd</tag>
        <tag>note</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《实现领域驱动设计》读书笔记(1) - 总览]]></title>
    <url>%2F%E6%9E%B6%E6%9E%84%E4%B8%8E%E6%A8%A1%E5%BC%8F%2FDDD%2Fnote-ddd-overview%2F</url>
    <content type="text"><![CDATA[面向对象编程的博大精深至今只浅尝一二，开发实践中一直希望能够持久向好的设计方向上靠而不过度设计。2015 年时第一次接触到领域驱动设计，当时看了 《实现领域驱动设计》这本书，初看时晦涩难懂，许多概念与当时的理解存在很大偏差，一度不理解为何要那样设计。在经过了几个项目的实战之后，如今再翻出来看，对书中总结的思考方式和方法论有了一番新的体会。现在看来，领域驱动设计之所以难以理解，在于其方法论的概念是抽象于任何语言和技术实现的，长期工作于一线的开发人员要转换思维去理解类似「值对象」，「标准类型」等这样的概念，需要一些时间。 总览一谈到「领域驱动设计」或者 DDD，总是很难通过一句话来概括，它既不是设计模式，也不代表任何技术实现，仅仅是面向对象程序设计的一种方法论，其中涵盖了在任何软件系统中可能涉及的方方面面。 领域模型什么是领域模型？领域模型是关于某个特定业务领域的软件模型。通常，领域模型通过对象来实现，这些对象同时包含了「数据」和「行为」，并且表达了准确的业务含义 ——《领域驱动设计》 全书由高层视角深入到实现的细枝末节来组织章节，其索引大致为： 战略建模 通用语言(Ubiquitous Language) 领域，子域和核心域 限界上下文(Bounded Context) 上下文映射图(Context Mapping) 架构(Archiecture) 战术建模 实体(Entity) 值对象(Value Object) 领域服务(Domain Service) 领域事件(Domain Event) 模块(Module) 聚合(Aggregate) 工厂(Factory) 资源库(Repository) 集成限界上下文(Integrating Bounded Contexts) 应用程序 这些不同的内容会在后续的笔记中一一提到，只取我觉得有价值的部分记录下来。设计一个系统时所需要的所有建模工具都能在以上这些概念中找到，并且针对这些应用场景提出了指导意见和最佳实践。]]></content>
      <categories>
        <category>架构与模式</category>
        <category>DDD</category>
      </categories>
      <tags>
        <tag>ddd</tag>
        <tag>note</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在 MacOS 上安装 nginx]]></title>
    <url>%2FMacOS%2Fmacos-install-nginx%2F</url>
    <content type="text"><![CDATA[不同于其他 Linux 系统，MacOS 使用了 brew 作为包管理器，并同时肩负了服务进程管理器的角色，在本机完成网站内容的准备工作之后，开始考虑把 MacOS 变成一个 web server。 安装 nginx使用 HomeBrew 在 MacOS 上安装 nginx:1$ brew install nginx 安装完成后，会显示如下提示信息：12345678910111213==&gt; CaveatsDocroot is: /usr/local/var/wwwThe default port has been set in /usr/local/etc/nginx/nginx.conf to 8080 so thatnginx can run without sudo.nginx will load all files in /usr/local/etc/nginx/servers/.To have launchd start nginx now and restart at login: brew services start nginxOr, if you don&apos;t want/need a background service you can just run: nginx==&gt; Summary 简要归纳为： 网站根目录在 /usr/local/var/www 默认端口在 为 /usr/local/etc/nginx/nginx.conf 文件中配置为 8080，这样 nginx 无需 $sudo 权限就可执行 nginx 将从 /usr/local/etc/nginx/servers/ 目录读取所有配置文件信息 要让 nginx 随用户登录一同启动请执行命令 brew services start nginx 若不需要作为后台服务启动，请直接执行命令 nginx 配置新站点创建一个目录作为新站点的根目录，例如1mkdir -p /usr/local/var/www/your-site-name 查看 /usr/local/etc/nginx 目录，有一个名为 nginx.conf.default 的文件，该文件通常为网站配置的起始点。首先导航到 /usr/local/etc/nginx/servers/ 目录，然后将该默认配置文件复制一份。12cd /usr/local/etc/nginx/servers/cp ../nginx.conf.default your-site-name.conf 修改 listen, server_name, location 块下的 root 和 index 项的值到对应的值，保存并退出配置文件。利用 nginx -t 检查配置的有效性，一切准备就绪后，执行 brew services reload nginx 命令重新加载配置。 之后，通过在浏览器中的输入对应主机的 ip 地址或域名及端口号，即可访问到部署到 nginx 的站点]]></content>
      <categories>
        <category>MacOS</category>
      </categories>
      <tags>
        <tag>make-the-best-of-my-macmini</tag>
        <tag>diy</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git push 到 MacOS]]></title>
    <url>%2FMacOS%2Fmacos-git-push-to-repository%2F</url>
    <content type="text"><![CDATA[MacOS 没有自带 git，需要通过 XCode Command Line Tools 进行安装，当通过 ssh 客户端远程登录到 MacOS 并执行 git --version，MacOS 会自动弹出确认框以进行安装，这里需要手动在 MacOS 系统界面下点击确认按钮才能继续。完成安装后再次执行 git --version，已能够看到版本号。新建或导航到一个目录，将其作为新 repository 的根目录。 12mkdir -p development/hobby-project/my-first-git-repositorycd development/hobby-project/my-first-git-repository 因为这里有 3 层目录结构，不带任何参数的 mkdir 命令将不会递归创建目录，-p 选项表示，如果任何层级的目录不存在，将递归创建目录，如果所有层次的目录都已存在，则不会进行任何操作。同时，要确保登录到远程机器的用户拥有针对创建目录的所有层级的读写权限，否则 git pull 和 git push 将会报错。如果权限不正确，使用 $sudo chown -R 命令更改文件夹或文件权限。 现在，development/hobby-project/my-first-git-repository 将作为远程 repository 根目录，执行：12$sudo git init --bareInitialized empty Git repository in /Users/XXX/development/hobby-project/my-first-git-repository/ git init --bare 参数指明该 repository 用于分布式版本控制的中心仓库，git 将仅保存历史记录，一般来说服务器上的仓库多使用 --bare 创建，其目的在于分发而非修改，参考 what is a git bare repository。 远程仓库创建完成后，回到客户端主机，这里采用 ssh 协议进行通信，如果没有现成的 key，需要先生成 key pair。ssh 默认配置存放在用户 home 目录下的 .ssh 文件夹下，如果没有指定 config 文件，则 id_rsa 作为默认的 key 文件名，具体参考 How To Configure Custom Connection Options for your SSH Client。]]></content>
      <categories>
        <category>MacOS</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>make-the-best-of-my-macmini</tag>
        <tag>diy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在 Windows 环境下远程控制 MacOS]]></title>
    <url>%2FMacOS%2Fmacos-remote-control%2F</url>
    <content type="text"><![CDATA[为了把闲置已久的 Mac mini 变成一个可在 Windows 环境下远程操作的小型私有服务器，需要现实至少以下两点目标： 使用 ssh 客户端远程登录，类似通过 PuTTy 管理其他类 Linux 系统 使用 sftp客户端实现文件传输的需求 同时，要确保 MacOS 主机与客户端主机在网络上是互通的，要么在同一局域网下通过 ip 地址访问，要么使用域名映射固定 ip 地址。 准备工作MacOS 自带了 ssh，但默认是禁用的，通常我们进行以下步骤的确认： 12$sudo systemsetup -getremoteloginRemote Login: Off 该命令查询本地计算机远程登录功能是否启用，如果显示 Off，则执行以下命令开启：1$sudo systemsetup -setremotelogin on 再次执行查询命令以确认上一条命令生效并且该功能启用：12$sudo systemsetup -getremoteloginRemote Login: On $sudo systemsetup -getremotelogin 将同时启用 ssh 以及 sftp server 在这些命令前加上 sudo 是必须的，因为这些操作均要求管理员权限。 在 Windows 下远程操作 MacOS现在，在 Windows 系统下使用 bash 或 PuTTy 客户端，连接到该 Mac 所在的 ip 地址：1ssh username@ipaddress 登录完成后便与在 MacOS 本机上使用该账号操作 terminal 一样了。 远程登录同时开启了 sftp 服务，这意味着如果使用类似 winscp 之类的文件传输客户端也可以连接 MacOS 并完成文件传输。 为远程登录添加安全访问机制ssh 针对不同 group 的用户提供了不同的远程访问策略，使用密码登录是一件非常不安全的，如果该 MacOS 主机在通过内网穿透或拥有公网 ip 暴露在互联网下，那么随时有遭受攻击的可能，为了加强安全性，我们可以： 禁止使用密码验证登录 开启 ssh key pair 验证登录 确保我们已经进行远程登录后，首先导航到 ssh 配置所在的目录：1cd /etc/ssh/ 列出文件列表：1ls -ll 使用 vim 编辑器打开 sshd_config 文件：1vi sshd_config 按下 ‘i’ 使 vim 进入 insert 模式找到 #PasswordAuthentication yes 一行，删除行头的 ‘#’ 字符，并将 ‘yes’ 改为 ‘no’ ‘#’ 表示对该行进行注释 找到 #PubKeyAuthentication yes 一行，删除行头的 ‘#’ 字符，按下 ‘esc’ 键退出 ‘insert’ 模式，按下 ‘:wq’ 以保存并退出 vim 编辑器。 若要修改生效， sshd 进程需要重新读取该配置，但这会让已经通过密码登录的会话中断，并且在 public key 部署前没有任何机会重新进行远程连接，所以这一步放到最后来做。 现在，复制先准备好的 ssh public key 的值，回到登录用户的主目录并导航到 .ssh 目录下：12cd #cd .ssh 新建 authorized_keys 文件并使用 vim 编辑器编辑：12touch authorized_keys$sudo vi authorized_keys 粘贴已经复制到剪贴板中的 ssh public key 的值，’:wq’ 保存并退出。 在前文提及的 /etc/ssh/sshd_config 中有一行 AuthorizedKeyFiles，该行的默认值为 .ssh/authorized_keys，该项配置是 sshd 进程提取 public key 的依据，如果对该值进行了修改，那么这里新建的文件也必须要与之对应。 现在，重新读取 sshd 的配置文件信息1$sudo launchctl load -w /System/Library/LaunchDaemons/ssh.plist]]></content>
      <categories>
        <category>MacOS</category>
      </categories>
      <tags>
        <tag>make-the-best-of-my-macmini</tag>
        <tag>diy</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建 Hexo 轻博客]]></title>
    <url>%2FWeb%2Fhexo%2Fhexo_setup%2F</url>
    <content type="text"><![CDATA[搭建博客的第一步，就是要找到符合自己需求的博客框架。之前用 LAMP 搭过 Wordpress，但就写博客这个需求来说 Wordpress 的功能太重了，希望环境尽量越简单越好。与同事们交流得知 Hexo 是一个轻量级的基于 Markdown(.md) 的轻博客框架，自己便开始了 DIY。 环境准备 Node.js 安装 hexo npm 包 git bash 客户端 hexo 是 npm 的一个包，首先从 Node.js 官网下载对应系统的安装包。Node.js 安装完成后会自动在环境变量中加入 npm cli 的路径，接着在 cli 中使用以下命令安装 hexo 包：1npm install -g hexo-cli 确认安装已经成功：1hexo version 初始化以下两种途径初始化 hexo： 首先创建指定目录作为 hexo 的根目录，在该目录下运行命令行工具，执行 hexo init，该命令会以当前目录作为 hexo 的根 启动命令行工具，执行 hexo init &lt;folder&gt; 初始化指定目录为 hexo 的根，随后执行 cd &lt;folder&gt; 导航到该目录 hexo init &lt;folder&gt; 命令中，如果 folder 所包含的目录层级中包含不存在的层级，该命令会自动创建该层级下的目录 初始化完成后，得到以下的目录结构：12345678.├── _config.yml├── package.json├── scaffolds├── source| ├── _drafts| └── _posts└── themes 在初始化完成后的目录中包含了 package.json 文件，意味着该项目有其自己的 npm 包依赖，执行 npm install 解析依赖并在本地安装。 配置 _config.yml_config.yml 文件包含了对 hexo 博客站点的配置信息。 网站(site) 参数 描述 title 网站标题 subtitle 网站副标题 description 网站描述 author 作者名字 language 网站使用的语言 timezone 时区 其中，description 主要用于 SEO，为搜索引擎提供一个关于站点的简单描述，通常建议包含网站的关键词。author 参数用于主题显示文章的作者。 网址(url) 参数 描述 默认值(示例值) url 根地址 http://www.your-site.conm/blog/ root 站点根目录 /blog/ permalink 文章的永久链接格式 :year/:month/:day/:title/ permalink_defaults 永久链接中各部分的默认值 永久链接是指，当执行 hexo s 或发布到 web server 之后，其生成文件的 url 组成策略，默认值为 :year/:month/:day/:title/，这意味着 url 将以分隔的日期值来定位文章。 url 和 root 总是成对修改，例如，想要把站点的根目录放在子目录 /blog 下，那么 root 的值应该修改为 /blog/，url 的值对应修改为 http://www.your-site.com/blog/。官方文档中的网站存放于子目录的意思是，hexo 项目包含的是生成站点的源代码文件，包括 source/_posts 目录，均用于生成网站，而“网站”是指生成好之后的静态资源文件集。 更多配置详情参考官方文档 本地测试本地生成并 serve：123cd &lt;target-directory&gt;hexo ghexo server 此时在浏览器中访问 localhost 对应的端口号将看到一个新的模板页面已经生成成功，执行如下命令来创建新的文章，在 source/_posts 目录下一个对应的文件被创建1hexo new "my-first-post" 导航到该文件可以看到其模板内容 12345---title: my-first-postdate: 2018-03-01 02:51:53tags:--- 重新生成博客文章并启动 hexo server12hexo generatehexo server -o --debug -o 参数代表在成功 serve 立即打开一个浏览器窗口以访问站点的根页面，--debug 参数启用在控制台打印 debug 级别的日志信息，方便排错。hexo generate 可简写为 hexo g，hexo server 可简写为 hexo s 文章列表中已经列出刚刚创建的文章名称，进一步修改该文件，hexo server 将实时更新页面内容 部署到 Github Pages当站点准备就绪后，下一步就是要给它找个家，GitHub 为每个账号提供了站点寄宿服务——GitHub Pages，在 GitHub 中创建一个 username.github.io 的公开仓库，将 build 好的站点资源文件集 push 到该仓库，再访问唯一的 https://username.github.io/ 即可。 hexo 提供了自动部署机制，在 _config.yml 中找到 deploy 这一项：123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: git@github.com:username/username.github.io.git branch: master 部署的更多详情参考官方文档 GitHub Pages 同时支持自定域名解析，假设已经有了一个域名 example.com，那么在 dns 提供商后台将自定的二级域名或 www 域名指向 username.github.io 即可，具体参考 https://help.github.com/articles/using-a-custom-domain-with-github-pages/GitHub Pages 使用自定域名后无法启用 https 通信协议。]]></content>
      <categories>
        <category>Web</category>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为 Linux 系统配置 CSF]]></title>
    <url>%2Flinux%2Flinux-configure-csf%2F</url>
    <content type="text"><![CDATA[Config Server Firewall(CSF) 基于一般的防火墙功能(数据包过滤)进行了扩展，支持大多数 Linux 发行版本，其支持列表可在其官网找到。以下以 ubuntu 系统为例介绍 CSF 的使用。 对 CSF 的几乎所有指令操作都需要管理员权限，本篇文章仅涵盖 ipv4 的防火墙设置 - iptables。ipv6 对应的是 ip6tables。 功能认证失败检测守护进程CSF 每隔一段时间就会检查系统登录日志，对那些登录失败的请求尝试进行监控，在达到预设的失败次数后，CSF 将对发起这些请求的 ip 地址做预设的处理，失败次数和处理动作都是可自定义的。 以下程序对该功能兼容： Courier imap, Dovecot, uw-imap, Kerio openSSH cPanel, WHM, Webmail (cPanel servers only) Pure-ftpd, vsftpd, Proftpd Password protected web pages (htpasswd) Mod_security failures (v1 and v2) Suhosin failures Exim SMTP AUTH同时，可以自定义匹配 Regex 的登录文件来，对登录失败尝试的用户进行屏蔽。 进程追踪CSF 可检测异常行为的进程或异常开启端口的行为，在捕获到这些行为时可配置发送邮件给服务器管理员。 目录监控CSF 可监控 /temp 和其他相关的目录扫描恶意脚本，并在发现风险时发送邮件给服务器管理员。 消息服务启用该功能可让 CSF 在屏蔽客户端时传送一些有用的信息，但这样做可能会为黑客提供一些线索信息，继而增加服务器的风险。 端口涌流保护该设置提供端口涌流保护，比如 DDoS 攻击，可以为每个端口指定特定时间内允许最大的连接数。启用该功能可以极大降低黑客的野蛮攻击导致服务器宕机。找到一个适合的参数需要一些尝试，太过严格的流量限制会降低正常用户的体验。 Port Knocking参考 Port Knocking。 连接限制保护该功能可限制由单一 ip 地址对特定端口建立的连接数，这也是防止 DDoS 攻击的手段之一。 Port/IP 地址重定向可配置 CSF 将对特定 IP/Port 的连接重定向到另一个 IP/Port。注意，重定向之后，请求发起的客户端将变为服务器的 ip 地址，该功能与 NAT 不同。 UI 集成除了命令行工具之外，CSF 对 cPanel 和 Webmin 提供了 UI 集成。 IP 屏蔽列表CSF 可使用该功能从预设的源下载屏蔽的 ip 地址列表。 安装 ConfigServer Firewall下载从官网下载安装包到当前工作目录：1wget http://download.configserver.com/csf.tgz 解压缩下载下来的是一个经过压缩的压缩包，安装之前需要解压缩1tar -xzf csf.tgz 安装在进行安装之前，首先禁用其他防火墙脚本，例如 UFW，执行以下指令禁用 UFW：1$sudo ufw disable 导航到刚刚解压出来的文件夹 csf，执行安装脚本：1234cd csf$sudo sh install.sh...Installation Completed 安装完成后，查看指定的 iptables 是否可用：123456789101112131415$sudo perl /usr/local/csf/bin/csftest.plTesting ip_tables/iptable_filter...OKTesting ipt_LOG...OKTesting ipt_multiport/xt_multiport...OKTesting ipt_REJECT...OKTesting ipt_state/xt_state...OKTesting ipt_limit/xt_limit...OKTesting ipt_recent...OKTesting xt_connlimit...OKTesting ipt_owner/xt_owner...OKTesting iptable_nat/ipt_REDIRECT...OKTesting iptable_nat/ipt_DNAT...OKRESULT: csf should function on this server 出现以上报告内容则表明 CSF 已可在服务器上正常运行。 此时，通过登录到服务器的 ip 地址会被自动加入到白名单中，同时 SSH 占用的端口(即便是自定义的端口)会自动开启，CSF 默认使用测试模式，该模式下所有的 iptables 规则将在 5 分钟后自动被移除。一旦确认所有配置已经就绪，应切换为工作模式。 基本配置通过编辑 /etc/csf/csf.conf 文件来配置 CSF，保存更改后，执行 csf -r 来使配置重新生效。1$sudo nano /etc/csf/csf.conf 配置端口配置文件中默认开启的端口如下：1234567TCP_IN = "20,21,22,25,53,80,110,143,443,465,587,993,995"TCP_OUT = "20,21,22,25,53,80,110,113,443"UDP_IN = "20,21,53"UDP_OUT = "20,21,53,113,123" 这些端口代表的默认服务如下： Port 20: FTP 数据传输 Port 21: FTP 控制 Port 22: 安全 shell (SSH) Port 25: 简单邮件传输协议 (SMTP) Port 53: 域名系统 (DNS) Port 80: 超文本传输协议 (HTTP) Port 110: 邮局协议 v3 (POP3) Port 113: 身份协议 Port 123: 网络时间协议 (NTP) Port 143: 因特网信息访问协议 (IMAP) Port 443: 超文本安全传输协议 (HTTPS) Port 465: URL Rendesvous Directory for SSM (Cisco) Port 587: 简单邮件传输协议 (SMTP) Port 993: 因特网安全信息访问协议 (IMAPS) Port 995: 安全邮局协议 v3 (POP3S) 以下是针对常见场景开启的服务端口： 任何主机1234TCP_IN: 22,53TCP_OUT: 22,53,80,113,443UPD_IN: 53UPD_OUT: 53,113,123 Apache1TCP_IN: 80,443 FTP 服务器1234TCP_IN: 20,21TCP_OUT: 20,21UPD_IN: 20,21UPD_OUT:20,21 邮件服务器12TCP_IN: 25,110,143,587,993,995TCP_OUT: 25,110 MySQL 服务器12TCP_IN: 3306TCP_OUT: 3306 进阶配置CSF 提供了大量的可配置项，最常用的列表如下： ICMP_IN: 设置为 1 时将允许外部主机 ping，设为 0 则禁止任何请求 ICMP_IN_LIMIT: 特定时间内允许同一 ip 地址的 ping 的请求数，通常不用修改，默认值为 1/s DENY_IP_LIMIT: 设置屏蔽 ip 地址的最大数量，保留太多数量会降低服务器性能 DENY_TEMP_IP_LIMIT: 与 DENY_IP_LIMIT 类似，但仅作用于临时屏蔽的 ip 地址 PACKET_FILTER: 过滤无效的，不需要的和非法的数据包 SYNFLOOD, SUNFLOOD_RATE 和 SYNFLOOD_BURST: 这三项提供了针对 SYN flood 攻击的保护，但会降低每个连接的初始化速度，仅当明确服务器正遭受攻击时启用该项 CONNLIMIT: 限制指定端口的并发连接数 如: 22;5;443;20 - 该值允许在 22 端口上最大 5 个并发连接数，在 443 端口上最大 20 个并发连接数 PORTFLOOD: 限制指定端口上单位时间内的最大连接数 如: 22;tcp;5;250 - 该值限制如果 22 端口上已有 5 个 tcp 连接，那么第 6 个来临的 tcp 连接将等待 250 秒，之后屏蔽解除，5 个新的 tcp 连接放行 其他设置在大多数情况都无需改动，如果确实需要自定义这些配置，阅读 /etc/csf/csf.conf 各项配置上的注释来了解其用途。 应用更改在应用更改前将第一项配置 TESTING = “1” 改为 TESTING = “0” 以使 csf 切换为工作模式。再以管理员权限执行 sudo csf -r 使更改生效。 屏蔽与允许 ip 地址防火墙最基础的功能是屏蔽，允许及忽略特定的 ip 地址，csf 可通过编辑 csf.deny, csf.allow 和 csf.ignore 文件来实现。 屏蔽 ip 地址使用编辑器打开 csf.deny1$sudo nano /etc/csf/csf.deny 每一行代表一条屏蔽项，可以是单一的 ip 地址，也可以是一个网段，例如：121.2.3.42.3.0.0/16 允许 ip 地址如果希望指定的 ip 地址或网段避开屏蔽和过滤扫描，可将它们加入到白名单列表，一旦将它们加入白名单，即便它们在 csf.deny 中已经存在，也会让它们绕过防火墙。 编辑 csf.allow 文件来加入白名单：1$sudo nano /etc/csf/csf.allow 忽略 ip 地址忽略名单与白名单的区别在于，忽略名单仅仅不进行过滤检查，但依然可能被加入黑名单中。1$sudo nano /etc/csf/csf.ignore 最后，执行 sudo csf -r 重载 csf 以使配置生效。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建 Ubuntu 16.04 LTS]]></title>
    <url>%2Flinux%2Flinux-setup-a-new-ubuntu-server%2F</url>
    <content type="text"><![CDATA[近年来云计算服务器越来越流行，在适当的时机准备一台拥有公网 ip 的云服务器以备不时之需。最近租用了一台预装 ubuntu 操作系统(这里选择 ubuntu 是因为笔者对其预装的工具集比较熟悉)的服务器之后，还要为这台服务器做一些额外的配置以使其能够在互联网环境中正常运行。很多云服务提供商都提供了适配不同需求的预装环境，但为了对服务器的搭建过程有一个直观的感觉和更多的控制权，决定亲手过一遍这个过程。 本篇文章涉及的所有指令细节可参考Linux 基础 - 用户管理 通常，配置一台裸机至少要完成以下几个步骤 新建群组 新建用户，并为其分配群组 配置 ssh 配置服务器安全策略 准备工作在开始配置之前，我们需要知道该服务器的以下信息： 服务器的公网 ip 地址 确认 22 端口打开 root 用户的初始密码 在 windows 系统下启动 PuTTy，使用 root 用户远程登录到该服务器 主机命名 hostname(可选的)如果不想修改云服务提供商默认分配的主机名，可跳过此步。 执行命令 hostname 显示当前主机名12$ hostnameVM-0-4 执行以下命令进行修改，修改完成后，再次执行命令以查看效果：123$sudo hostname &lt;your-new-hostname&gt;$ hostnameyour-new-hostname 新建群组 - groupadd执行如下命令新建一个带有 &lt;gid&gt; 的群组1$sudo groupadd &lt;your-new-group-name&gt; -g &lt;gid&gt; 新建用户 - useradd1$sudo useradd -u 2500 -m -c "FrostHe" -s -g sudo -G pango pango 该命令创建一个名为 pango 的用户，uid 为 2500，要求为该用户创建 Home 目录，使用预设值设置 shell 环境，加入初始群组 sudo，同时加入次要群组 pango。由于先前已经创建了群组，在创建该用户时就不会再创建与之同名的新的群组，而是将该用户加入到该群组下。 现在，新建用户 pango 还没有密码，设置密码之前是无法登录 shell 的，执行 passwd 来为新用户指定密码：123$sudo passwd pangoEnter new Unix Password:Retype new Unix Password: passwd 指令在不接参数时表示修改当前登录用户的密码 现在，退出 PuTTy 客户端，以新建用户名和密码登录，如果登录成功，则表明新用户创建无误。 配置服务器安全策略将云服务器的 22 端口暴露于互联网并允许 root 用户及一般用户以密码进行登录是不推荐的，特别是 root 帐号，一旦被攻击者破解那么服务器上的资源可任由其修改。为了使服务器免于这些危险，我们需要让这台服务器： 禁用 root 帐号密码登录，仅启用公钥认证 开启防火墙并限定端口 设置 ip 登录策略及 禁用密码登录并启用 ssh 公钥登录以新建用户登录系统，修改 sshd_config 文件：1234$sudo nano /etc/ssh/sshd_configPermitRootLogin noPublicAuthentication yesPasswordAuthentication no 该配置对 ssh 客户端远程登录作出限制：启用公钥认证并禁用密码认证，同时禁止 root 远程登录。 若要修改生效， sshd 进程需要重新读取该配置，但这会让已经通过密码登录的会话中断，并且在 public key 部署前没有任何机会重新进行远程连接，所以这一步放到最后来做。 接下来在新用户 Home 目录下的 .ssh/authorized_keys 文件中复制 openssh 格式的公钥值。 在 /etc/ssh/sshd_config 中有一行 AuthorizedKeyFiles，该行的默认值为 .ssh/authorized_keys，该项配置是 sshd 进程提取 public key 的依据，如果对该值进行了修改，那么这里新建的文件也必须要与之对应。 现在执行 sudo service sshd reload 以使配置生效。此时重新打开一个 PuTTy 客户端，使用新用户密码登录，将收到错误对话框：在 Putty 中设置对应的私钥路径，重试即可登录成功： 至此，一个基本的云服务器配置就完成了，有的云服务提供商推出了「安全组」功能，即从云端配置端口进出通道。更多安全配置查阅 为 Linux 系统配置 CSF。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>diy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git Module 与嵌套 Repository]]></title>
    <url>%2FVersion-Control%2FGit%2Fgit-embeded-repository%2F</url>
    <content type="text"><![CDATA[Git 可将一个 Git repository 作为另外一个 Git repository 的子目录，这允许在你的项目中引用另一个项目，并将两个项目分开维护。假设我们希望将一个现有的 Git repository 作为一个 submodule 添加到当前工作项目上，执行 git submodule add 并跟上绝对或相对 url 作为参数来添加 submodule。 Submodules 至少有两种应用场景： 项目依赖一个外部项目，并希望将两者分开维护 将一个大项目拆分为多个小项目并将它们黏合在一起 添加一个 Submodule1$ git submodule add https://github.com/chaconinc/DbConnector 默认情况下，submodules 将使用与 Git repository 一致的名称作为 directory 添加到当前项目的根目录下，在这个例子中为 “DbConnector”。也可以在命令最后指定一个自定义的路径作为该 submodule 的目录。 执行 git status，看到以下变化：123456789$ git statusOn branch masterYour branch is up-to-date with 'origin/master'.Changes to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) new file: .gitmodules new file: DbConnector 一个新的文件 .gitmodules 被创建了，该配置文件存储了当前项目与 submodule 之间的关系映射，以下是其内容举例：123[submodule "DbConnector"] path = DbConnector url = https://github.com/chaconinc/DbConnector 如果包含多个 submodule，那么该文件会有更多的 entry，值得注意的是，该文件一起受 git 版本控制。 作为 submodule 被管理的 Git repository 将不会受到父级 Git repository 的状态追踪。因此，在当前项目执行 git push origin master 之后，从另一台机器 git clone 父级项目时，将只包含 .gitmodules 文件及对应于各个 submodules 的空的 directory。123456789101112131415161718192021222324$ git clone https://github.com/chaconinc/MainProjectCloning into 'MainProject'...remote: Counting objects: 14, done.remote: Compressing objects: 100% (13/13), done.remote: Total 14 (delta 1), reused 13 (delta 0)Unpacking objects: 100% (14/14), done.Checking connectivity... done.$ cd MainProject$ ls -latotal 16drwxr-xr-x 9 schacon staff 306 Sep 17 15:21 .drwxr-xr-x 7 schacon staff 238 Sep 17 15:21 ..drwxr-xr-x 13 schacon staff 442 Sep 17 15:21 .git-rw-r--r-- 1 schacon staff 92 Sep 17 15:21 .gitmodulesdrwxr-xr-x 2 schacon staff 68 Sep 17 15:21 DbConnector-rw-r--r-- 1 schacon staff 756 Sep 17 15:21 Makefiledrwxr-xr-x 3 schacon staff 102 Sep 17 15:21 includesdrwxr-xr-x 4 schacon staff 136 Sep 17 15:21 scriptsdrwxr-xr-x 4 schacon staff 136 Sep 17 15:21 src$ cd DbConnector/$ ls$ 要获得与提交之前的 submodules，一种方式是执行 git submodule init 指令来初始化本地配置和 git submodule update 从 submodules 对应的地址 clone 所有数据并签出对应的 commit。12$ git submodule init$ git submodule update 或者：1git submodule update --init --recursive 另外一种方式是在执行 git clone 父级项目时添加 --recurse-submodules 参数，将一次完成父级项目及所有 submodules 的克隆1$ git clone --recurse-submodules https://github.com/chaconinc/MainProject 之后，如果希望同父级项目一同获取所有 submodules 的更新，执行1git pull --recurse-submodules 获取子项目更新使用 Git Submodules 一个最典型的应用场景是，引用一个由外部维护的 Git repository，仅仅使用它而不做任何修改。 首先导航到指定 submodule 所在目录，执行 git fetch 和 git merge 获取本地更新。12345678910$ git fetchFrom https://github.com/chaconinc/DbConnector c3f01dc..d0354fc master -&gt; origin/master$ git merge origin/masterUpdating c3f01dc..d0354fcFast-forward scripts/connect.sh | 1 + src/db.c | 1 + 2 files changed, 2 insertions(+) 回到父级项目目录，执行 git diff --submodule，可以看到 submodules 已经获得更新并列出一个添加到该项目的 commit 列表。如果不想每次在执行 git diff 时都输入 --submodule 参数，可在 git config 文件中添加该命令的默认参数或执行 git config diff.submodule log，之后再执行 diff 将会将列出所有子项目更新日志。12345$ git config --global diff.submodule log$ git diffSubmodule DbConnector c3f01dc..d0354fc: &gt; more efficient db routine &gt; better connection routine 此时如果主项目提交至远程 Git repository，之后其他开发人员再获取代码时将会得到与主项目同步后的 submodule。 另外一种方式是直接在主项目目录下执行 git submodule update --remote 命令，git 将自动更新所有 submodules。12345678$ git submodule update --remote DbConnectorremote: Counting objects: 4, done.remote: Compressing objects: 100% (2/2), done.remote: Total 4 (delta 2), reused 4 (delta 2)Unpacking objects: 100% (4/4), done.From https://github.com/chaconinc/DbConnector 3f19983..d0354fc master -&gt; origin/masterSubmodule path 'DbConnector': checked out 'd0354fc054692d3906c85c3af05ddce39a1c0644' 该命令将默认以所有 submodules 的 master branch 作为更新依据，如何以另外一个 branch name 作为默认更新的依据，参考下文的Git Module 可在 git config 文件中为 status 命令添加默认参数或执行 git config status.submodulesummary 1，之后执行 git status 显示简短的摘要1234567891011121314151617$ git config status.submodulesummary 1$ git statusOn branch masterYour branch is up-to-date with 'origin/master'.Changes not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) modified: .gitmodules modified: DbConnector (new commits)Submodules changed but not updated:* DbConnector c3f01dc...c87d55d (4): &gt; catch non-null terminated lines Git Modulesubmodule 是嵌套在另一个 repository 中的 repository，submodule 有自己的版本历史，包含子模块的 repository 称为 superproject .gitmodules 放置在一个 Git 工作树的顶级目录下，该文件是一个匹配 git-config 的文本文件。该文件的每个 subsection 代表一个 submodule 的配置项，subsection 的值为 submodule 的名称，如果不显式指定 name 选项，该名称值将取该 submodule 的路径作为名称。同时，每一个 subsection 包含以下必填值： submodule.&lt;name&gt;.path: 相对于 Git working tree 顶层目录的路径，默认迁出位置，该值不能以 / 结尾，所有 submodule 的路径必须唯一。 submodule.&lt;name&gt;.url: 克隆 submodule 的 url，该值可以是一个绝对 url，也可以 ./ 或 ../ 起头作为 superproject origin repository 的相对 url。 同时，还有以下可选参数： submodule.&lt;name&gt;.update: 定义 submodue 的默认更新行为，在 superproject 执行 git submodule update 指令时如何更新 submodule.&lt;name&gt;.branch: 提供用于检测更新的 branch 名称，如果不指定该值，默认取 master。. 作为特殊值告知 git 取与当前 repository 当前 branch 一致的名称 submodule.&lt;name&gt;.fetchRecurseSubmodules: 该用于控制对 submodule 的递归 fetch，如果在 superproject 的 .git/config 中已经设置了该值，那么该值将覆盖在 .gitmodules 中的值。两者均可被 git fetch 和 git pull 使用 --[no-]recurse-submodules 选项覆盖 submodule.&lt;name&gt;.ignore: git status 和比较器如何对已经做出修改的 submodules 进行反应，可取以下值 all: submodule 永远不会被认为已经 modified，但在 staged 后会显示出来 dirty: 所有对 submodule 工作目录下做出的修改将被忽略，只有其 Head 与 superproject 的记录状态会纳入考虑 untracked: 只有 untracked 文件会被忽略 none: 所有修改都不会被忽略 submodule.&lt;name&gt;.shallow: 当设置为 true 时，该 submodule 会执行浅 clone(只包含一层深度的历史信息) 例子：123[submodule "libfoo"] path = include/foo url = git://foo.com/git/lib.git 文件系统中，一个 submodule 通常 在 superproject 的 $GID_DIR/modules/ 有一个 Git 目录 在 superproject 工作目录下有一个对应的子目录作为其工作目录 在其工作目录中根目录下包含一个 .git 文件指向 (1) 所在的位置 假设一个 submodule 的 Git 目录位于 $GIT_DIR/modules/foo/，工作目录位于 path/to/bar/，superproject 通过一个 path/to/bar/ 目录树下的 gitlink 和 .gitmodules 文件中的一个条目 submodule.foo.path = path/to/bar 来追踪这个 submodule。 参考资料： https://git-scm.com/book/en/v2/Git-Tools-Submodules https://git-scm.com/docs/gitmodules https://git-scm.com/docs/gitsubmodules]]></content>
      <categories>
        <category>Version Control</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 基础 - 用户和群组]]></title>
    <url>%2Flinux%2Flinux-account-and-group%2F</url>
    <content type="text"><![CDATA[Linux 使用文件及配置相应的权限来存储用户帐号和群组信息，在成功创建好用户帐号之后，以下几处文件会发生相应的改变 /etc/passwd: Linux 管理用户帐号的数据库 /etc/shadow: Linux 管理用户帐号密码配置的数据库 /etc/group: Linux 管理群组的数据库 /etc/gshadow: Linux 管理群组密码配置的数据库 用户帐号管理Linux 系统用户管理相关命令主要有： useradd：新建用户 passwd：设置用户密码 chage: 变更密码策略 usermod：编辑用户 userdel：删除用户 新建用户帐号 - useraddlinux 系统以 useradd 命令来新建 Unix 用户，该命令带有一系列参数： 12345678910111213useradd [-u UID] [-g 初始群组] [-G 次要群组] [-mM] [-c 说明栏] [-d 家目录绝对路径] [- s shell] &lt;new-user-name&gt;-u ：接 UID ，一组数字，直接指定一个特定的 UID 给这个用户-g ：为该用户指定初始群组 initial group，该群组的 GID 会被放置到/etc/passwd 的第四个栏位-G ：为该用户指定次要群组，该选项与参数会修改 /etc/group 内第四栏的值-M ：不要为用户建立 Home 目录(系统帐号预设值)-m ：为用户建立 Home 目录(一般帐号预设值)-c ：用户备注，该值修改 /etc/passwd 文件的第五栏的内容-d ：指定特定目录成为该用户的 Home 目录，而不采用预设值，需指定绝对路径-r ：建立一个系统帐号，该帐号的 UID 会有限制(参考/etc/login.defs)-s ：指定 `shell` ，若不指定则预设为 /bin/bash-e ：指定该用户的过期日期，格式为『YYYY-MM-DD』此项写入 `/etc/shadow` 第八栏-f ：指定密码是否立即失效，写入 /etc/shadow 的第七栏位。0 为立刻失效，-1 为永远不失效(密码只会过期而强制于登入时重新设定而已) 例如，执行以下命令新建一个用户：1$sudo useradd pango 该命令创建一个名为 pango 的用户，由于没有使用 -r 指令，将随机分配一个 1000 以上的数值作为 uid，创建一个名为 pango 的群组并作初始群组，为该用户创建 Home 目录，使用 /bin/bash 作为工作环境。该命令对系统的以下部分做出修改： 在 /etc/passwd 里面新建一行用户值，包含 UID/GID/Home 目录等； 在 /etc/shadow 里面将此用户的密码相关参数填入，但是尚设置密码； 在 /etc/group 里面加入一个与用户名称一样的群组名称，如果已经存在与该用户名同名的群组名，则不会新建群组 在 /home 目录下新建一个与帐号同名的目录作为用户的 Home 目录，且权限为 700 注意，在 linux 系统中新增用户帐号和群组时，名称是区分大小写的 useradd 指令参考 /etc/defaults/useradd 文件中的配置作为缺省参数的预设值，使用 useradd -D 指令查看预设值：12345678$ useradd -DGROUP=100 # 预设的群组，系统内 GID = 100 的群组为 users 群组，但目前很多发行版都采用私有群组制，即为每个新建的用户帐号创建与之同名的群组来隔离权限HOME=/home # 预设的 Home 目录INACTIVE=-1 # 密码失效日期，对应 /etc/shadow 第 7 栏EXPIRE= # 用户帐号失效日，对应 /etc/shadow 第 8 栏SHELL=/bin/sh # 默认使用的 shell 程序名，如果 server 不希望任何新建的用户帐号登入系统取得 shell，那么将此项改为 /sbin/nologinSKEL=/etc/skel # Home 目录初始内容参考目录，即为新建用户创建 Home 目录时需要复制的初始内容，例如，在该目录下新增 www 目录，那么后续每个创建的新用户 Home 目录都会有 www 目录CREATE_MAIL_SPOOL=no # 是否主动帮用户建立邮件信箱，如果该项为 yes，则会新建 /var/spool/mail/&#123;username&#125; 目录作为该用户的邮箱 使用 nano 或 vim 查看 /etc/default/useradd 文件可以得到更多的详细信息：1$ nano /etc/default/useradd 登录信息参考在 /etc/login.defs 文件中定义，使用 nano 查看该文件123456789101112131415161718192021$ nano /etc/login.defsMAIL_DIR /var/spool/mail # 用户预设邮件信箱放置目录PASS_MAX_DAYS 99999 # /etc/shadow 内的第 5 栏，多久需变更密码日数 PASS_MIN_DAYS 0 # /etc/shadow 内的第 4 栏，多久不可重新设定密码日数 PASS_MIN_LEN 5 # 密码最短字符长度，已被 pam 模组取代PASS_WARN_AGE 7 # /etc/shadow 内的第 6 栏，过期前会警告的日数UID_MIN 1000 # 用户最小的 UID，意即小于 1000 的 UID 为系统保留 UID_MAX 60000 # 用户能够用的最大 UID SYS_UID_MIN 201 # 保留给用户自行设定的系统帐号最小值 UID SYS_UID_MAX 999 # 保留给用户自行设定的系统帐号最大值 UID GID_MIN 1000 # 用户自订群组的最小 GID，小于 1000 为系统保留 GID_MAX 60000 # 用户自订群组的最大 GID SYS_GID_MIN 201 # 保留给用户自行设定的系统帐号最小值 GID SYS_GID_MAX 999 # 保留给用户自行设定的系统帐号最大值 GIDCREATE_HOME yes # 在不加 -M 及 -m 时，是否主动建立用户家目录UMASK 077 # 用户 Home 目录建立的 umask ，因此权限会是 700 USERGROUPS_ENAB yes # 使用 userdel 删除时，是否删除初始群组 ENCRYPT_METHOD SHA512 # 密码加密的机制使用的是 sha512 加密算法 所以，系统在执行 useradd 命令时至少会参考： /etc/default/useradd /etc/login.defs /etc/skel/* 现在查看 /etc/passwd 档案的最后一行：1pango:x:1000:1000::/home/pango:/bin/bash 该文件是存放所有用户信息的数据库，每一行代表一个用户，每行由 6 个 : 分隔成了 7 个栏位： 用户名 密码 用户 UID：0 保留给系统管理员 root 账号；1~999 保留给系统账号，这些账号通常为执行某些系统服务所用，不能通过 shell 登录；1000~4294967295，保留给一般账号 用户初始群组 GIP 备注 Home 目录，预设值为 /home/{username} 执行 Shell 的程序目录，预设值为 /bin/bash 设置帐号密码 - passwd现在，新建的用户 pango 还没有密码，在设置密码之前是无法登录的，执行 passwd 来为新用户指定密码：12345678910111213141516$ passwd [--stdin] [帐号名称] # 所有人均可使用来改自己的密码 $ passwd [-l] [-u] [--stdin] [-S] [-n 日数] [-x 日数] [-w 日数] [-i 日数] 帐号 # root 功能选项与参数：--stdin ：可以透过来自前一个管线的资料，作为密码输入，对 shell script 有用-l ：是 Lock 的意思，会将 /etc/shadow 第 2 栏最前面加上 '!' 使密码失效；-u ：与 -l 相对，是 Unlock 的意思-S ：列出密码相关参数，亦即 shadow 档案内的大部分信息-n ：自上一次修改密码后的密码不可修改天数，shadow 的第 4 栏位-x ：自上一次修改密码后的密码有效天数，shadow 的第 5 栏位-w ：密码过期前的警告天数，shadow 的第 6 栏位-i ：密码失效缓冲天数，shadow 的第 7 栏位$sudo passwd pangoEnter new Unix Password:Retype new Unix Password: passwd 指令在不接参数时表示修改当前登录用户的密码 密码设置成功后，在 /etc/shadow 文件中发生了一些改变，定位到该文件的最后一行：1pango:$6$csIys5qj$OslSKU.3SljbHXTXJEPgWvNi1w9CGlBKO3uqJyWueQN1ypA7SuNzJWjesdSvg6KPv0X6tRmkkDBFI2cbSJ.xR/:17600:0:99999:7::: 该文件存储了所有用户的密码相关配置，每一行代表一个用户的密码信息，每行由 8 个 : 分隔为 9 个栏位： 用户名 经过加密的密码 最近修改密码日期，该值为一个代表 day 的数值，从 1970-01-01 日算起 密码不可修改天数：该值指示密码在最近一次修改后多久之后才能再次被修改 密码有效期（天）：该值指示密码再最近一次修改后的有效天数 密码需要变更前的警告天数 密码失效延迟（天）：密码过期后的缓冲时间 账号失效日期（天）：该值指示该用户的总生命周期多长，与密码有效无效无关 系统保留扩展项： 通过标准输入 --stdin 来修改密码，例如，帮助 pango 用户将其密码修改为 ‘abc543CC’ 123$ echo "abc543CC" | passwd --stdin pangoChanging password for user pango.passwd: all authentication tokens updated successfully. --stdin 选项并不存在于所有 Linux 发行版本的系统中，使用前先 man passwd 查看是否支持 管理帐号密码策略 - chage除了使用 passwd 指令，还可以使用 chage 指令来管理密码策略，其用法大致如下：123456789$ chage [-ldEImMW] 用户帐号名选项与参数：-l ：列出该帐号的详细密码参数；-d ：修改 shadow 第 3 栏位(最近一次更改密码的日期)，格式 YYYY-MM-DD-E ：修改 shadow 第 8 栏位(帐号失效日)，格式 YYYY-MM-DD-I ：修改 shadow 第 7 栏位(密码失效日期)-m ：修改 shadow 第 4 栏位(密码最短保留天数)-M ：修改 shadow 第 5 栏位(密码多久需要进行变更)-W ：修改 shadow 第 6 栏位(密码过期前警告日期) passwd -S 只是简单显示了密码详情，而 chage -l 更多为管理员提供了更强的参考信息，列出 pango 的详细密码参数 ：12345678$ chage -l pangoLast password change : Jul 20, 2015Password expires : Sep 18, 2015Password inactive : Sep 28, 2015Account expires : neverMinimum number of days between password change : 0Maximum number of days between password change : 60Number of days of warning before password expires : 7 修改用户帐号信息 - usermod当需要修改用户帐号的信息时，我们可以通过前往相应的文件例如，/etc/passwd 和 /etc/shadow 中去修改对应行的值以达到修改用户帐号信息的目的。也可以使用 usermod 指令对用户帐号进行修改：1234567891011121314$ usermod [-cdegGlsuLU] username 选项与参数：-c ：修改用户备注，对应 /etc/passwd 第 5 栏-d ：修改帐号 Home 目录，对应 /etc/passwd 的第 6 栏；-e ：修改帐号失效日期，格式是 YYYY-MM-DD，对应 /etc/shadow 内的第 8 栏-f ：修改密码失效延迟时间，对应 shadow 的第 7 栏。-g ：修改初始群组，修改 /etc/passwd 的第 4 栏-G ：修改次要群组组，修改该用户支援的群组，修改应用到 /etc/group-a ：与 -G 合用，表示 append，追求次要群组而非改变-l ：修改帐号名称， /etc/passwd 的第 1 栏-s ：修改 shell 接入程序，后面接 Shell 的实际程序，例如 /bin/bash 或 /bin/csh 等等-u ：修改 uid 对应 /etc/passwd 第 3 栏-L ：暂时锁定用户，暂时无法登入。仅修改 /etc/shadow 的密码栏。-U ：解锁用户，移除 /etc/shadow 密码栏的 '!' 删除用户帐号 - userdel当需要删除用户帐号时，执行 userdel 命令，该命令会对以下文件造成影响： 用户帐号/密码相关值：/etc/passwd，/etc/shadow 用户群组相关参数：/etc/group，/etc/gshadow 用户个人资料目录：/home/{username}，/var/spool/mail/{username} 该指令用法如下：123$ userdel [-r] username 选项与参数：-r ：连同用户的 Home 目录也一起删除 例如，删除 pango 用户帐号及其 Home 目录：1$sudo userdel -r pango 通常，在移除一个帐号时，我们可以手动修改 /etc/passwd 和 /etc/shadow 文件中该用户关联的行数据。如果该帐号只是「暂时冻结」，那么将 /etc/shadow 中第 8 栏（帐号失效日）设为 0 就可让该账户无法使用，但所有与该帐号相关的资料都会保留，使用 userdel 意味着「真的确定该用户不会在主机上的使用任何资料了」。 通常，一个用户在使用主机一段时间之后，会在更多其他的目录中产生属于他的文档，因此，在下达 userdel -r username 之前，先以 find / -user username 指令查出整个系统内属于 username 的档案，删除之后，再删除该用户帐号。 用户端指令 - id, finger, chfn, chshuseradd，usermod，userdel 都是系统管理员才能使用的命令，一般用户无法进行操作，有以下几个指令供一般用户使用： id: 该指令可以查询当前用户或其他用户的 UID/GID 值 finger: 查询用户的口令信息，将有 Login: 用户帐号信息 Name: 备注信息 Directory: Home 目录 Shell: shell 对应的程序 Never logged in: 登入信息 No mail: 查看 /var/spool/mail 中的信箱资料 No Plan: 查看 ~{username}/.plan 资料 chfn: 修改指纹信息，不常用 chsh: 修改 shell，参数如下： -l，列出所有可用的 shell，即 /etc/shells 中的内容 -s，修改为指定的 shell 群组管理群组管理涉及新增，修改和删除，群组的内容与以下两个档案有关： /etc/group /etc/gshadow 新增群组 - groupadd使用 groupadd 来新增群组，该命令使用方法如下：1234$ groupadd [-g gid] [-r] 群组名称选项与参数：-g ：指定群组 GID-r ：指定该群组为系统群组，与 /etc/login.defs 内的 GID_MIN 有关 执行命令查看新建的群组：123$ nano /etc/group...&lt;your-new-group-name&gt;:x:&lt;gid&gt;: 该命令查询 /etc/group 文件，该文件是 linux 系统保存所有群组的数据库，每一行代表一个群组，每行的值由 3 个 : 分隔为 4 栏不同的值，其具体指： 群组名称 群组密码，以 x 表示，引用 /etc/gshadow 的第 2 栏 群组 id 该群组包含的用户名称，每个用户名称由 , 分隔 x 表示该群组的密码，其在 /etc/gshadow 文件中对应第 2 栏的值，gshadow 文件保存了所有群组的详细配置，但只有拥有 root 权限的用户才能查看该文件。由于该群组刚刚创建，没有指定任何用户，故该值为空。 查看 /etc/gshadow 文件可以看到对应的行，其格式如下：1&lt;your-new-group-name&gt;:!::usernames 这个文件内的格式几乎与 /etc/group 一摸一样，第 2 栏是密码栏，如果密码栏为 ‘!’ 或空，表示该群组不具有群组管理员： 群组名称 密码栏，若为 ‘!’ 表示无合法密码，无群组管理员 群组管理员的帐号 所有加入该群组的帐号，与 /etc/group 内容相同 修改群组 - groupmod与 usermod 类似，groupmod 指令用于对已有群组的信息进行修改1234$ groupmod [-g gid] [-n group_name] 群组名选项与参数：-g ：修改既有的 GID 值；-n ：修改既有的群组名称 一个群组创建之后，为了避免引起不必要的错乱，通常不建议随意修改其 GID 删除群组 - groupdel1groupdel [groupname] 使用 groupdel 来删除已有的群组，如果有用户帐号已经关联一个群组作为其初始群组，将无法直接删除该群组，否则当用户登入系统后，系统将找不到其对应的群组。想要删除该群组，必须： 修改与之关联的用户的初始群组 删除该用户，再删除群组 群组管理员 - gpasswd1234567891011$ gpasswd groupname $ gpasswd [-A user1,...] [-M user3,...] groupname $ gpasswd [-rR] groupname 选项与参数：若没有任何参数时，表示给予 groupname 一个密码(/etc/gshadow)-A ：将 groupname 的主控权交由参数代表的多个用户管理(该群组的管理员)-M ：将某些帐号加入这个群组当中！-r ：将 groupname 的密码移除-R ：让 groupname 的密码栏失效-a ：将用户加入到 groupname 这个群组中-d ：将用户移除 groupname 这个群组中 初始群组，次要群组和有效群组在执行 useradd 命令新建用户时，使用 -g 命令指定初始群组，该群组的 GID 被写入到 /etc/passwd 对应的 GID 栏位，而 -G 指定的次要群组则将用户名写入 /etc/group 第 4 栏。 当用户登入系统进入 shell 环境后，系统总是以该用户所在的初始群组作为有效群组，即，当用户执行类似 touch 的指令创建新的文件或文件夹时，其权限会给予用户当前的有效群组。执行 groups 可查看当前登录用户所属的所有群组，排在第一位的即表示当前有效群组。 可通过执行 newgrp 指令将用户所属的另一个群组切换为当前有效群组，该动作导致用户进入另一个 shell 环境，当用户完成操作不再需要该群组支持时，应使用 exit 指令退回到之前的 shell 环境。 参考资料：http://linux.vbird.org/linux_basic/0410accountmanager.php]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于我的博客]]></title>
    <url>%2Fdiary%2Fabout%2F</url>
    <content type="text"><![CDATA[自成为程序员以来，就养成了记笔记的习惯，很多细节问题当时解决了，大多数时候是以某种 workaround 的方式解决的，如果问题的根源没有找准，那么以后遇到又会 repeat yourself。虽然记笔记一度花掉很多时间，但它能够帮助自己对遇到的问题以及寻求解决途径的过程进行梳理，在这个过程中，也能训练自己对表达和记录某件事的思路，进而加深理解并巩固印象。同时，这也为所有不同种类的信息提供了一个统一的入口进行查阅。 最近，用了两年的 WizNote 又到期了，借着这个契机，便有了自建博客的想法。 我想在这里写下所有我认为有价值的内容，其中可能包括某个技术的备忘要点，某些技术的深入探索，读书笔记，和日常工作中遇到的问题。这些内容将主要涵盖： .NET 技术生态 Web 技术生态 数据库技术栈 架构设计与模式 Linux 学习与心得 自己 diy 的一些过程 这里的内容主要是给我自己看，但又不像私人日记那么随意。大部分内容是从以往的云笔记经过重新梳理搬移过来，我保持了与当时一致的创建日期，在搬移和记录过程中我也会随时调整文件的分类和标签，以使其符合某种逻辑进行组织。 总之，我暂时想象不出这个站点日后会变成什么样子。希望今后某一天我回看这些内容的时候，会欣慰的发现原来自己已经学到了这么多东西，并且能够追寻这些文字找到来时的路。]]></content>
      <categories>
        <category>diary</category>
      </categories>
  </entry>
</search>
