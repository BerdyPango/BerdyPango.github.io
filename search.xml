<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Web Frontend Learning Notes - CSS]]></title>
    <url>%2Flearning-frontend-notes-css%2F</url>
    <content type="text"><![CDATA[Three Pillars of Writing Good HTML and CSSResponse Design Fluid layout: Float Layout Flex Box Layout Grid Box Layout Media queries Responsive images Correct units Desktop-first vs. mobile-first Maintainable and Scalable Code Clean Easy-to-understand Growth Reusable How to organize files How to name classes How to structure HTML Web Performance Less HTTP requests Less code Compress code Use a CSS preprocessor Less images Compress images How CSS works behind scenesCascade(Resolving conflicting CSS declarations)The cascade is the process of combining different stylesheets and resolving conflicts between different CSS rules and declarations when more than one rule applies to a certain element. CSS styles can come from different sources: Author: writen by developers User: customized by user, like font-size and font-family Browser(user agent): browsers have default styles for some certain elements. How does the cascade resolve conflicts of different sources? It goes from 1-3 phases and each of them takes some aspects for precedence. First, decide Importance: User !important declarations Author !important declarations Author declarations User declarations Default browser declarations If Importance is a tie, consider Specificity: Inline styles: writen in HTML IDs Classes, pseudo-classes, attribute Element, pseudo-elements If Specificity is also a tie, consider Source Order: The last declaration in the code will override all other declarations and will be applied. To summarize: CSS declarations marked with !important have the highest priority; But, only use !important as a last resource. It’s better to use correct specificities - more maintainable code! Inline styles will always have priority over styles in external stylesheets; A selector that contains 1 ID is more specific than one with 1000 classes; A selector that contains 1 class is more specific than one with 1000 elements; The universal select * has no specificity value (0, 0, 0, 0); Rely more on Specificity than on the order of selectors; But, rely on order when using 3rd-party stylesheets - always put your author stylesheets last. CSS Parsing Phases(Process final CSS values) Declared value(author declarations): Gathering all declaration values for a single CSS property. For font-size, browsers usually have a default value of 16 pixels. This is the user-agent declaration, not a CSS initial value. Cascaded value(after the cascade): Determine a final value that will take precedence. Specified value(defaulting if there is no cascaded value): In each element of the page, every CSS property needs to have value even if there’s no declaration at all. Each CSS property has something called an inital value. Computed value(converting relative values to absolute):Value with relative units like rem, em are computed to pixels, and CSS key words like orange, oral, boulder will be computed and replaced here in this step. rem is calculated in this step by multiplying 16. rem is always relative to the root font-size. Some properties like the ones related to text, such as font-size inherit the computed value of their parent elements. Used value(final calculations, based on layout): The css engines uses the rendered layout to figure out some of the remaining values like percentage values that depend on the layout. Because percentage value is in relation to its parent element and the parser needs to know that width in order to calculate a pixel width. Actual value(browser and device restrictions): Browsers usually cannot really display like 184.8 pixels, a value with a comma is simply rounded. How CSS Engine Calculate Relative Units in DetailPercentage-based units: %(fonts): Percentage on fonts are explained by x% * parent&#39;s computed font-size %(lengths): Percentage on lengths(such as width, height, padding, margin) always reference their parent’s computed width property value. x% * parent&#39;s computed width Font-based units: em(font): For fonts, use the parent element as the reference. x * parent computed font-size em(lengths): For lengths, use the current element as the reference. x * current element computed font-size rem: Works the same way for both fonts and length. Uses the root font-size as the reference. x * root element computed font-size. Root font-size is defined in HTML element. By changing font-sizes, we will automatically change length since it depend on a font-size and that gives us a lot of flexibility. Viewport-based units: vh: Percentage of viewport height. x * 1% of viewport height. vw: Percentage of viewport width. x * 1% of viewport width. CSS Inheritance Inheritance passes the values for some specific properties from parents to children - more maintainable code Properties related to text are inherited: font-family, font-size, color, etc; The computed value of a property is what gets inherited, NOT the declared value. Inheritance of a property only works if no one declares a value for that property. The inherit keyword forces inheritance on a certain property. The initial keyword forces to reset a property to its initial value. Visual Formating ModelVisual Formating Model is an algorithm that calculates boxes and determines the layout of these boxes, for each element in the render tree, in order to determine the final layout of the page. Dimensions of boxes: the box model Content: text, image, etc; Padding: transparent area around the content, inside of the box; Border: goes around the padding and the content; Margin: space between boes; Fill area: area that gets filled with background color or background image. The fill area does not include Margin. For a default block level box, the visual formating model calculates: total width = right border + right padding + specified width + left padding + left border total height = top border + top padding + specified height + bottom padding + bottom borderTo fix this problem, we use box-sizing: border-box property for box level boxes. Box TypeThe type of a box is always defined by display property. Usually by specifying display: block, but display: flex display: list-item display: table also produce block-level boxes; Elements such as &lt;p&gt;, &lt;div&gt; which are usually formatted visually as blocks have their display property set to block by default. Box level elements will occupy as much as possible of their parent element like 100% width and create line breaks after and before it. Inline elements(like &lt;span&gt;, &lt;img&gt;) which have display: inline by default only occupy the space that its content actually needs. They don’t create line breaks before or after them. Inline elements work a bit different: width and height properties DO NOT apply, meaning we are not able to use these properties for inline elements. We can only specify horizontal(left and right) padding and margin on inline elements. Inline block boxes(display: inline-block) is there to apply block level box modelling to inline elements. Positioning Schemes Normal flow: Default positioning scheme; NOT floated; NOT absolutely positioned; Elements laid out according to their source order; position: relative Floats: Element is removed from the normal flow; Text and inline elements will wrap around the floated element; The container will not adjust its height to the element; float: left/right; Absolute positioning: Element is removed from the normal flow; No impact on surrounding content or elements, they can even overlap them We use top, bottom, left and right to offset the element from its relatively positioned container; position: absolute/fixed Stacking ContextsStacking contexts are what determine in which order elements are rendered on the page. With z-index, opacity and transform properties they will create new stacking contexts. Sass &amp; NPMSass is CSS preprocessor. Sass Source Code -&gt; Compiled CSS Code Sass provides: Variables: for reusable values such as colors, font-size, spacing, etc; Nesting: to nest selectors inside of one another, allowing us to write less code; Operations: for mathematical operations right inside of CSS; Partials and imports: to write CSS in different files and importing them all into one single file; Mixins: to write reusable pieces of CSS code; Functions: similar to mixins, with difference that they produce a value that can be used later; Extends: to make different selectors inherit declarations that are common to all of them; Control directives: for writing complex code using conditionals and loops; Sass &amp; SCSSSCSS stands for Sassy CSS. Sass is indentation sensitive and doesn’t use any curly braces and semicolons. Nesting123456789101112131415161718// SCSS.navigation &#123; list-style: none; li &#123; display: inline-block; margin-left: 30px; &amp;:first-child &#123; margin: 0; &#125; &#125;&#125;// CSS.navigation li:first-child &#123; margin: 0;&#125; The &amp; basically writes out the selector at this current point here. Mix-insMix-ins are a bunch of codes that can be applied in many places. Typically, a mix-in looks like below:12345678910@mixin clearfix &#123; &amp;::after &#123; content: ""; clear: both; display: table; &#125;&#125;// use the mix-in@include clearfix; We could also pass arguments to a mix-in:12345678// declare min-xins@mixin style-link-text($color) &#123; text-decoration: none; text-transform: uppercase; color: $color;&#125;// use mixins@include style-link-text(#eee); Functions123456// declare functions@function divide($a, $b) &#123; @return $a / $b;&#125;// use functionsmargin: divide(60, 2) * 1px; // 30px ExtendsBascially we write a placeholder and put a bunch of styles in there, then have other selectors extend that placeholder. Install Sass Locally1$ npm install node-sass --save-dev 7-1 Pattern7 different folders for partial Sass files: base/: basic product definitions components/: 1 file for each component layout/: define the overall layout of the project pages/: styles for specific pages of the project themes/: to implement different visual themes abstracts/: code that doesn’t output any CSS such as variables or mix-ins. vendors/: where all 3rd-party CSS goes and 1 main Sass file to import all other files into a compiled CSS stylesheet. SCSS uses @import to import partial SCSS files, SCSS files named with _ prefix are by convention recognised as partial SCSS files by SCSS compiler SCSS/CSS RemindersCSS RemindersGlobal ResetBy default, browsers apply a certain margin, or padding to some elements like &lt;h1&gt;. We don’t want that, so we usually have a global reset declaration, like:123456*,*::after,*::before &#123; margin: 0; padding: 0;&#125; box-sizing: border-boxbox-sizing: border-box is to change the box model so that the borders and the paddings are no longer added to the total width or height that we specify for a box. If you set an element’s width to 100 pixels, that 100 pixels will include any border or padding you added, and the content box will shrink to absorb that extra width. This typically makes it much easier to size elements. By default the box-sizing property is not inherited, we can specify box-sizing: inherit in * selector to make better practice. SelectorsAtrribute Selector [class^=&quot;col-&quot;] means to select all elements where they have a class name starting with col-, there are also * and $ symbols: [{attribute}^=&quot;{value}&quot;] means to select elements which have attribute start with value. [{attribute}*=&quot;{value}&quot;] means to select elements which have attribute contains value. [{attribute}$=&quot;{value}&quot;] means to select elements which have attribute end with value. Sibling Selectors is used to select elements adjusent to the element, we have: div + p: to select p element which is exact next to the div element. div ~ p: to select all p elements that are sibling of the div element. Pseudo Class/ElementsPseudo classes are special states of a selector. We use pseudo classes to select elements under a special condition. Pseudo elements with 2 : are elements that are actually on the web page. ::before/::after pseudo element creates a pseudo-element that is the first/last child of the selected element. By using this we can fully control what to render in CSS instead of declaring elements in HTML. ::-webkit-input-placeholder pseudo element is used to select the inputs’ placeholder element. This class only works on Safari and Chrome currently. :placeholder-shown is the pseudo class to select a the state where the placeholder is shown. :not(:last-child) pseudo selector means to choose all elements except :last-child. :checked pseudo class is helpful for radio and checkbox element select the state when they are checked. ::selection pseudo class is to select text that are selected by the cursor. CSS Native Functions calc function can mix units. Different from SASS, it’s evaluated during the webpage is rendered, which means it depends on the layout. To use a SASS variable, we need to wrap the variable with #{}. e.g, calc((100% - #{$gutter-horizontal})) How the clearfix come and Why we need itSince there are 3 different kinds of positioning, the normal flow, floats, and absolute positioning. floats and absolute positioning will take the element out of the natural flow. If all children elements are taken out of the natural flow, the parent element’s width will collapse. To fix it, we have different solutions for floats and absolute positioning. For floats, we can add a clearfix to ::after pseudo element:12345&amp;::after &#123; content: "", clear: both, display: table;&#125; Which means to append a child element with empty content and clear it for both sides. For absolute positioning, we can not use the clearfix as we use for floats, what we can do is to add a same height of the tallest child element to make it work. Browser SupportsFeature query:12345@supports (-webkit-backdrop-filter: blur(10px)) or (backdrop-filter: blur(10px)) &#123; -webkit-backdrop-filter: blur(10px); backdrop-filter: blur(10px); background-color: rgba($color-black, .3);&#125; Use Can I Use to check how a property is supported in different browsers. Others line-height: 1.7 means 1.7 times bigger than the predefined line height. height: 95vh: vh means viewport height, at every point the height of this element should be 95% of the viewport height. background-size: cover; means whatever the width or height of the element is, it’ll always try to fit. object-fit: cover; is to tell the element to fill the entire parent while still maintaining its aspect ratio. Unlike background-size: cover, this property works with HTML elements instead of just background images. &lt;img/&gt; is an in-line element by default. alt attribute is the description for SEO(search engine optimization). Also in case the image failed to load, the text will appear. only background-image property can be applied with linear-gradient(), not background-color. And background-size: cover; is to fit the content to the element’s width and height. background-size also accepts values like 100%, 25% and 150%, 100% has the same effect with cover value; background-blend-mode describes how the element’s background image should blend. We could specify a linear gradient and a background image together to background-image property, which looks like background-image: linear-gradient(...) url(...);. This is often useful to blend multiple background stuff while &lt;img&gt; can be applied only one element. background-image: linear-gradient() has further more functionality like gradient point, we can specify something like `background-image: linear-gradient( 105deg, rgba($color-white, 0.9) 0%, rgba($color-white, 0.9) 50%, transparent 50%, transparent 100% ), url(../img/nat-10.jpg);` to make a skewed splitter effect. overflow property tells what to do when the content is too big to fit in its block formating context. position: absolute needs to have a reference, the reference is the first element with the relative position that it can find. To make it easier, we often explicit specify the parent element position: relative; property. When an element is specified position: absolute, the width will fit its content, a width: 100% is often following the absolute positioning. top: 40px and left: 40px are in relation to the parent element. transform: translate() is in relation to the element itself. &lt;h1&gt;&lt;/h1&gt; is a single important to search engines to capture the website’s title. bakcface-visibility: determines the back part of an element when we transform it is visible or hidden for the user. It can be used to fix animation shaking at some point. display:inline-block applies box model to inline elements, this will allow paddings, width or height to take the space as it worked as a block. text-align: center; is perfect for centralizing inline or inline-block elements for they are treated as texts. Sometimes, we need to wrap a inline element and give the wrapper parent element a utility class like u-center-text to center the child inline element. margin: 0 auto; is widely used to center block elements inside of another block element. Use position: absolute; top:50%; left: 50%; to vertically and horizontally center a block box within a block box. Use transition property to quickly apply animations between pseudo classes. animation-fill-mode: backwards is to keep the element state the same as the effect specifies before animation starts. lorem in vs code just enter some random text. Use percentage unit for images for responsive design purpose. We can use outline-offset property to give space between the element and outline, which makes outline different from border property. .feature-box &gt; * means to select all the direct children of .feature-box. &gt; is a selector that only picks direct child. clip-path property in Google Chrome would break the overflow property. This can be fixed by manually setting the border-radius property. In HTML5, we have &lt;figure&gt; element we can put an image and some caption with a &lt;figcaption&gt; element shape-outside property is to define a vectorized shape of the element. It is effective only when the element’s width and height is set and floated. The best to move around with floated element is not mess with margin or left but using transform: translate() opacity to 0 just keep the element to be invisible, but the element still remains on the page. While visibility: hidden will move away the element. The reason why we set both of them sometimes is that we can not animate on visibility while we can for opacity. display: table and display: table-cell is used to make a elements like table cells in a table in order to use properties like vertical-align: middle :target pseudo class is triigered when a link is to trigger a target anchor. Then the element of that id becomes the anchor and the target.]]></content>
      <categories>
        <category>WebFrontend</category>
      </categories>
      <tags>
        <tag>javascript</tag>
        <tag>css</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DIY - 自制树莓派便携游戏机]]></title>
    <url>%2Fhobby-project-how-to-make-a-raspberry-pi-game-console%2F</url>
    <content type="text"><![CDATA[初衷在树莓派社区广大极客的浸染下，了解到了各种大神的新奇玩法。经过一番研究之后，笔者决定利用市面上能够现成买到的配件，自行组装一个便携式复古游戏机。这款游戏机应该: 自带电源 自带屏幕 即拿即用 硬件部分经过一段时间的调查和试错之后，终于组合出了一个靠谱的解决方案，下面先从硬件部分说起: 树莓派 3b+3B+ 是目前为止树莓派性能最好的型号，既然要用来跑游戏，自然性能越强越好: Micro-SD 卡(TF 卡)用于跑系统和存储游戏 ROM，容量自选: 树莓派官方 7 英寸触控屏之所以选择官方 7 英寸触控屏，是因为笔者没有找到合适的 5V 供电的第三方屏。虽然触控功能在大多数情况下用不到，但聊胜于无，且这块屏幕的做工和设计都挺不错的。 使用 Micro-USB 口供电的屏幕可以作为第二选项，但目前没有发现在性价比上超过官方屏的第三方屏 适配板左侧为 DSI 接口，接受 3 种类型的供电接口: 左上角，GPIO 杜邦线供电 左下角，Micro-USB 接口 右侧，USB Type-A 接口 UPS 模块为游戏机提供便携电源一度成为最头疼的问题，树莓派机身需要 5.1V/2.5A 的电源，网友们给出了各种各样 diy 的供电解决方案，比如: 充电宝: 最简单但也是最简陋的方案，但大多数充电宝的输出电流都达不到 2.5A，美亚上找到一款专门为树莓派设计的移动电源 Battery Pack for Raspberry Pi 3 B+, 4000mAh, Suction 自制电池盒: 使用 GPIO 为树莓派供电的模块，后接 AA 电池盒，模块仅供电，没有充电管理功能，类似于充电宝，只是连接形式从 usb 接口换到了杜邦线 锂电池模块(UPS 模块): 最理想的移动供电方式，通过杜邦线与树莓派连接的锂电池充放电管理模块，当前最流行的貌似是 PiJuice HAT，高端型号还带太阳能充电板，价格偏贵，单模块的价格都可以买两个树莓派了，有点 Overkill。在搜遍了某宝，eBay 和亚马逊之后，最终选择了一款国内厂商做的 UPS 模块，带 3800 毫安锂电池，开关和电量指示 实装 UPS 模块之后，单 USB 输出要同时为树莓派和 7 寸屏幕供电，导致屏幕右上角时不时出现闪电符号，即电压低。跟卖家沟通之后，有两种解决方案 采用两根 Micro-USB 线对屏幕和树莓派分别供电，笔者试过之后情况大有改善 不用 Micro-USB 线，自行焊上排针，改用杜邦线供电以减少线损，这个方案需自己有焊排针的能力，未曾尝试 Micro-USB 弯头线树莓派通过 Micro-USB 线连接至 UPS 输出口进行供电，而常规的安卓手机充电线都是直头且长度较长。为了一体化和美观考虑，单独购买了这根 25cm 的双弯头充电线。事实上 25 cm 仍然长了一点，但从正面看已经没有露出的线头了。 其他外设用于放置游戏机整机的支架，某东上几十块钱买的手机支架: 硬件汇总: 准备就绪，开始组装: 软件部分RetroPieRetroPie 是一款模拟器系统，参考其官方文档直接使用现成 Image 或基于已有 Raspbian 系统安装。如果选择直接下载 RetroPie 的 Image 进行安装，请参考家庭数字化系统 - 准备树莓派烧写系统镜像。 游戏 ROM视频的演示中涉及了 PS1 的游戏，目前 3B+ 的性能只能稳定运行 PS1 及以前平台的游戏，PSP 等需要更高性能的计算机。由于众所周知的原因，游戏的 ROM 请自行准备。 结论完工的游戏机从成本来看并不低，但折腾的乐趣就在于过程，对于喜欢折腾也想随时在家有个小游戏机玩的人来说，这提供了一种新思路。]]></content>
      <categories>
        <category>DIY</category>
      </categories>
      <tags>
        <tag>raspberrypi</tag>
        <tag>retropie</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[探寻 DDD 在 .NET 生态中的落地实现 - eShopOnContainers]]></title>
    <url>%2Farchitecture-ddd-in-eshopcontainers%2F</url>
    <content type="text"><![CDATA[参考资料: Github - eShopOnContainers eShopOnContainers 知多少[1]：总体概览 本文索引: eShopOnContainers 架构风格与架构模式 为何选择 CQRS 简单实现 CQRS 设计与实现面向 DDD 的 Ordering 服务 实体 值对象 聚合 聚合根或根实体 实现 .NET Core 的域模型微服务 在 .NET Standard 库中构建域模型 在实体中封装数据 SeedWork(域模型中可重用的基类型及接口) IAggregateRoot 接口 实体基类 仓储接口 值对象实现 使用可枚举类型替代 C# 原生枚举类型 在域模型中定义及实现验证 设计及实现领域事件 实现域事件 发布域事件 跨聚合单一事务还是多事务最终一致性 映射事件至事件处理器 域事件可以生成集成事件跨越服务边界 实现基础设施持久化层 每个聚合定义一个仓储 eShopOnContainerseShopOnContainers 是微软官方推出的基于 .NET Core 和 Docker 实现的一整套微服务架构体系的参考项目，以下简称「参考项目」。其各个子系统的复杂度迥异，因此文章一再强调不要把一个子系统的架构模式应用在所有系统上，本文主要提取了该书对 Ordering 子系统的实现思路。在阅读这些内容之前，我们至少应该对以下概念有所了解: 领域驱动设计的基本概念 CQRS Repository 模式 Mediator 模式 架构风格与架构模式无论是 CQRS 还是 DDD，都不是「架构风格(architecture styles)」，它们是「架构模式(architecture patterns)」，微服务，SOA，事件驱动架构是「架构风格」，而「架构模式」描述了一个子系统或组件的构建方式。不同的有界上下文应该采用不同的「架构模式」。 在实际介绍 DDD 之前，文章用了大量篇幅论述了有关 CQRS(Command and Query Responsibility Segregation) 的方法论。 为何选择 CQRSCQRS 是一种分离读写数据的架构模式，以下是 Bertrand Meyer 在其著作 Object Oriented Software Construction 首次对对两者的定义: Queries: 返回结果但不改变系统的状态，无副作用(These return a result and do not change the state of the system, and they are free of side effects.) Commands: 改变系统的状态(These change the state of a system.) 在参考项目的实现中，其高层视图为:简单起见，参考项目的「读」和「写」操作同一个数据库，但核心的思路是，「读」被处理成一种非常轻量的「幂等」操作；而「写」则暗示系统的状态变化，这意味着在处理「写」操作时要格外小心，任何业务规则的变化都可能引起一系列域模型的改变。因此，查询通常伴随着 ViewModels，命令则与域模型息息相关，将两者进行分离的目的在于将查询以及如何组装视图数据从域模型对事务及数据更新的限制条件中独立出来。 简单实现 CQRS参考项目的实现方法非常简单:图中的 API Interface 代表了 Ordering.API ASP.NET Core 项目，其 Controllers 直接调用 Infrastructure 中的 ORM 对象(这里是 Dapper)，再以 dynamic 类型作为 ViewModel 返回结果，其结构及源代码如下:123456789101112131415161718192021222324252627282930313233public interface IOrderQueries&#123; Task&lt;Order&gt; GetOrderAsync(int id);&#125;public class OrderQueries : IOrderQueries&#123; ... public async Task&lt;Order&gt; GetOrderAsync(int id) &#123; using (var connection = new SqlConnection(_connectionString)) &#123; connection.Open(); var result = await connection.QueryAsync&lt;dynamic&gt;( @"select o.[Id] as ordernumber,o.OrderDate as date, o.Description as description, o.Address_City as city, o.Address_Country as country, o.Address_State as state, o.Address_Street as street, o.Address_ZipCode as zipcode, os.Name as status, oi.ProductName as productname, oi.Units as units, oi.UnitPrice as unitprice, oi.PictureUrl as pictureurl FROM ordering.Orders o LEFT JOIN ordering.Orderitems oi ON o.Id = oi.orderid LEFT JOIN ordering.orderstatus os on o.OrderStatusId = os.Id WHERE o.Id=@id" , new &#123; id &#125; ); if (result.AsList().Count == 0) throw new KeyNotFoundException(); return MapOrderItems(result); &#125; &#125;&#125; 值得注意的是: 这里的 OrderQueries 类型直接在 Ordering.API 项目中实现，在哪一层实现并不重要，重点在于，用于表现层的数据可能来自于数据库不同的表，这些数据可能分属于不同的域对象，然而 Query 本身绕过了整个域模型而直接从数据库表提取数据，这解释了前文提及的查询独立于域模型的限制，这种方式为开发人员在更新查询时提高了灵活性和生产力。 这里直接以 dynamic 动态类型作为返回结果，但这不是必须的，传统上我们习惯创建对应的 ViewModel 静态类型。返回动态类型的好处在于，当为数据表增减列或修改列名时，无需在静态类型同步这些改变，这也暗示了这些类型仅仅是服务于表现层的数据包装，它们只是 DTO。但也存在缺点，比如无法对返回类型进行版本控制，无法自动集成 Swashbuckle 等。 设计与实现面向 DDD 的 Ordering 服务面对复杂性，聚合根必须确保所有处理不变性和业务规则的逻辑都经过统一的入口(聚合根实体)与关联的实体进行交互，下图展示了 Ordering 服务以 DDD 实现划分的不同的层以及它们的依赖关系: 实体域实体主要由其身份标识、连续性和持久化定义，实体的标识可跨越多个有界上下文或微服务。实体实现其代表的业务规则和读写状态数据，但并非所有实体都必须包含逻辑，这些实体通常都是一个聚合中的子实体，因为多数逻辑都在聚合根中实现。相反，如果大量逻辑放置在服务层(传统项目中的业务逻辑层)中，最终将导致贫血模型。然而，如果业务场景非常简单，看上去像是贫血模型的域模型也是足够的，重点在于，创建这些模型的出发点是为了便于「数据映射」还是「领域驱动」。两者的区别在于，「数据映射」仅仅从持久化的角度考虑，而忽略了模型在业务领域中代表的概念。根据业务复杂度选用合适的架构模式非常重要，这也是为何参考项目中的 Catalog 微服务以「数据驱动」模式实现而 Ordering 微服务以「领域驱动」模式实现。实体的详细描述可参考这里。 值对象值对象不包含身份标识，其仅为一组数据的「逻辑集合」，有关值对象的详细描述可参考这里。 聚合聚合描述了一系列或一组高度内聚的实体和行为，定义聚合通常以事务作为边界，一个典型的例子为: 一个 Order，通常包含一个 Item 列表，Item 通常被定义为实体，但 Item 是 Order 聚合的子实体，并将 Order 实体作为其根实体，而类似 Order 这样的实体通常被称为「聚合根」。聚合表示了一组必须维持「事务一致性」的对象，识别聚合通常由一个业务概念开始，并考虑在其事务边界内所需的所有实体。考虑「事务性边界」通常是识别一个聚合的起点。 聚合根或根实体一个「聚合」至少由一个「实体」组成——聚合根，它可能包含多个子实体、值对象。聚合根最重要的职责是确保聚合边界内的一致性，它必须是修改聚合的唯一入口。下图展示了 Buyer 聚合和 Odrer 聚合，包括它们的聚合根实体、子实体及值对象Buyer 代表了只包含一个实体的聚合。为了在聚合之间维持清晰的边界，一个最佳实践是禁止在一个聚合中直接引用另一个聚合，转而利用外键进行引用。如下代码中，Order 实体仅包包了一个 Buyer 聚合的外键，而非对象引用:12345678910public class Order : Entity, IAggregateRoot&#123;private DateTime _orderDate;public Address Address &#123; get; private set; &#125;private int? _buyerId; //FK pointing to a different aggregate rootpublic OrderStatus OrderStatus &#123; get; private set; &#125;private readonly List&lt;OrderItem&gt; _orderItems;public IReadOnlyCollection&lt;OrderItem&gt; OrderItems =&gt; _orderItems;//… Additional code&#125; 实现 .NET Core 的域模型微服务有了前文对概念理论的解释，接下来，将探索基于 ASP.NET Core 实现以 DDD 设计的 Ordering 服务。 在 .NET Standard 库中构建域模型首先来看参考项目的 Ordering 工程的文件组织：Order 和 Buyer 两个聚合所包含的实体和值对象均位于其对应的目录下，同时: 聚合中包含了 IRepository 接口，这些接口的实现必须放置在域模型之外的层——基础设施层，这样与基础设施有关的实现不至于污染域模型 SeedWork 目录包含了定义实体及值对象的基类 深入 Order 聚合，可以清晰的看出为了维持事务边界，聚合所包含的不同职责的类型:打开其中任何一个类型，无论是实体，值对象还是枚举类型，都继承自 SeedWork 文件夹下的类型，关于这些基类的实现，我们稍后会详述。 在实体中封装数据实体中一个常见的问题是，他们暴露了一些 public 的 Collection 类型，消费这些类型的开发人员不经意间可能会修改集合的元素，这种情况就会绕过集合本身所代表的业务规则，从而导致对象保持无效的状态。为了避免类似情况，可以将集合类型定义为 IReadOnlyCollection，并显式暴露修改集合的方法。123public IReadOnlyCollection&lt;OrderItem&gt; OrderItems &#123;get; private set;&#125;;public void AddOrderItem(productId, productName, pictureUrl, unitPrice, discount, units);... AddOrderItem 定义在 Order 聚合根中，其实现会包含验证，创建等与业务规则相关的逻辑(特别是与该集合中其他元素有关的逻辑)。另一方面，实体类型不应该将任何 Setter 方法暴露出来，修改实体状态应该由显式定义的描述业务规则的方法完成。 SeedWork(域模型中可重用的基类型及接口)Seedwork 是由 Michael Feathers 提出，并由 Martin Fowler 推广的用于概括这些类型的名称，也可以自行将其命名为 Common，SharedKernel 等。下图展示了 Ordering 域模中这些基类及接口: IAggregateRoot 接口一个空接口，仅用于标记某些实体为聚合根，实现了该接口的实体通常意味着保持业务逻辑一致性的逻辑都实现在该实体中，所有子实体的创建或更新都必须经过该类型。 实体基类查看 Entity 类型，定义了 ID，相等性比较器方法，域事件列表等。关于域事件将在后文中详述。 仓储接口将接口定义于域模型中遵循了抽象与实现分离的模式，同时仓储又结合了 CQRS 模式，仅是对聚合的「增删改」操作。 值对象实现唯一标识是实体及聚合用于身份跟踪的基础，而系统中还存在着大量无需进行标识及跟踪的对象和数据集合，它们是值对象。值对象可以引用实体，例如，一个程序生成了一个从 A 点至 B 点的路线，该「路线」是一个值对象，但它会引用 A 点和 B 点，A 点和 B 点则可能是代表「城市」或「街道」的实体类型。值对象是两个特征: 无需身份标识 不变性 以上特性意味着在实现值对象基类时，仅需考虑以它们的值来区别不同的对象。 使用可枚举类型替代 C# 原生枚举类型在 SeedWork 目录下有一个 Enumeration 的抽象类，其定义如下:1234567891011121314151617181920212223242526272829303132public abstract class Enumeration : IComparable&#123; public string Name &#123; get; private set; &#125; public int Id &#123; get; private set; &#125; protected Enumeration()&#123; &#125; protected Enumeration(int id, string name) &#123; Id = id; Name = name; &#125; public override string ToString() =&gt; Name; public static IEnumerable&lt;T&gt; GetAll&lt;T&gt;() where T : Enumeration &#123; var fields = typeof(T).GetFields(BindingFlags.Public | BindingFlags.Static | BindingFlags.DeclaredOnly); return fields.Select(f =&gt; f.GetValue(null)).Cast&lt;T&gt;(); &#125; public override bool Equals(object obj) &#123; var otherValue = obj as Enumeration; if (otherValue == null) return false; var typeMatches = GetType().Equals(obj.GetType()); var valueMatches = Id.Equals(otherValue.Id); return typeMatches &amp;&amp; valueMatches; &#125; public int CompareTo(object other) =&gt; Id.CompareTo(((Enumeration)other).Id); // Other utility methods ...&#125; 创建该类型的意图在于扩展由于 C# 语言原生 enum 类型的限制而无法应用的场景，例如，原生的 enum 类型仅支持单个值，并且无法通过简单的手段遍历枚举值。但这不是必须的，以下是一个 CardType 可枚举类型的实现:123456789101112public class CardType : Enumeration&#123; public static CardType Amex = new CardType(1, "Amex"); public static CardType Visa = new CardType(2, "Visa"); public static CardType MasterCard = new CardType(3, "MasterCard"); protected CardType() &#123; &#125; public CardType(int id, string name): base(id, name) &#123; &#125; public static IEnumerable&lt;CardType&gt; List() =&gt; Enumeration.GetAll&lt;CardType&gt;(); // Other util methods&#125; 在域模型中定义及实现验证在 DDD 中，验证规则可被视为「不变条件」，聚合的主要职责之一是在跨多个子实体的状态变化中维持「不变条件」，实体对象可能包含若干个「不变条件」，必须总是验证为真。举例来说，OrderItem 的 Quantity 值必须总是一个正整数，且总是包含有效的 ProductName 和 Price 值。聚合根对象必须确保这些对象的有效性，当不满足「不变条件」时应该发出通知或抛出异常。多数不易察觉的 Bug 都是由于对象处于「非预期」的状态导致的。 有效性验证通常在实体的构造器或更新状态的方法中实现，以下代码段展示了实体有效性验证最简单的手段——抛出异常:1234public void SetAddress(Address address)&#123; _shippingAddress = address?? throw new ArgumentNullException(nameof(address));&#125; 更多先进的实现手段可参考: Specification and Notification Patterns Martin Fowler. Replacing Throwing Exceptions with Notification in Validations Lev Gorodinski. Validation in Domain-Driven Design (DDD) 设计及实现领域事件在语义上，「域事件」和「集成事件」在行为上似乎是同一个概念——都表达了某个事件的发生。但它们的作用范围和协调目的都不一样。「域事件」仅仅是将消息推送至某个「域事件分发器」，而它可由 IoC 或其他方式实现。而「集成事件」则用于向其他系统广播刚刚提交的事务，消费方可能是某个微服务、有界上下文或外部应用程序。这意味着「集成事件」仅在实体成功持久化时发生，如果失败，对于其他系统来说，该操作就像没有发生过一样。 而「域事件」的作用范围是同一个域中某个聚合的操作需要引起另外的聚合执行额外的操作，这种由单个聚合引起的「副作用」应该由「域事件」承担，如下图所示:查看参考项目的源代码，当用户提交一个订单: Ordering.API 从外部接收一个请求，请求模型为 CreateOrderDraftCommand 类型 Controller 调用 Mediator 发送该请求 1234567[Route("draft")][HttpPost]public async Task&lt;IActionResult&gt; GetOrderDraftFromBasketData([FromBody] CreateOrderDraftCommand createOrderDraftCommand)&#123; var draft = await _mediator.Send(createOrderDraftCommand); return Ok(draft);&#125; CreateOrderDraftCommandHandler 处理该请求，创建 Order 对象，并返回一个 OrderDraftDTO 对象 12345678910public Task&lt;OrderDraftDTO&gt; Handle(CreateOrderDraftCommand message, CancellationToken cancellationToken)&#123; var order = Order.NewDraft(); var orderItems = message.Items.Select(i =&gt; i.ToOrderItemDTO()); foreach (var item in orderItems) &#123; order.AddOrderItem(item.ProductId, item.ProductName, item.UnitPrice, item.Discount, item.PictureUrl, item.Units); &#125; return Task.FromResult(OrderDraftDTO.FromOrder(order));&#125; Order.NewDraft() 方法返回一个 IsDraft = true 的 Order 对象，确认需要持久化之后，创建 OrderStartedDomainEvent 的实例，并添加至 Order 实体的 DomainEvents 集合属性，后者是一个 MediatR.INotification 的只读集合。Ordering.Infrastructure.MediatorExtension 的扩展方法 DispatchDomainEventsAsync 检测当前实体的 DomainEvents 发生变化时借由 Mediator 发布事件。 1234567891011121314151617181920public static async Task DispatchDomainEventsAsync(this IMediator mediator, OrderingContext ctx)&#123; var domainEntities = ctx.ChangeTracker .Entries&lt;Entity&gt;() .Where(x =&gt; x.Entity.DomainEvents != null &amp;&amp; x.Entity.DomainEvents.Any()); var domainEvents = domainEntities .SelectMany(x =&gt; x.Entity.DomainEvents) .ToList(); domainEntities.ToList() .ForEach(entity =&gt; entity.Entity.ClearDomainEvents()); var tasks = domainEvents .Select(async (domainEvent) =&gt; &#123; await mediator.Publish(domainEvent); &#125;); await Task.WhenAll(tasks);&#125; Ordering.API.Application.DomainEventHandlers.OrderStartedEvent 命名空间下我们看到了两个响应 OrderStartedDomainEvent 事件的 SendEmailToCustomerWhenOrderStartedDomainEventHandler 和ValidateOrAddBuyerAggregateWhenOrderStartedDomainEventHandler 处理器类型。 另外，可以在聚合根实体中订阅其子实体中的域事件。举例来说，OrderItem 实体在价格高于某个特定值或数量太多时发起事件，聚合根在收到这些事件后处理为全局计算或聚合计算。 重要的是理解事件通信并不直接在聚合中实现，而应由单独的域事件处理器(Domain Event Handler)来处理域事件，域事件的消费方是应用层和其他聚合，两者的数量且会随着时间不断增长，在设计时应尽可能考虑开闭原则和单一职责原则，基于域事件的通信方式可以更好的分离职责: 发送命令(例如，CreateOrder) 在命令处理器中接收命令 执行聚合的单一事务 如果产生副作用，广播域事件(例如，OrderStartedDomainEvent) 其他聚合或应用层响应域事件，例如: 验证或创建 Buyer 和 PaymentMethod 创建并广播一个相关的集成事件至其他微服务，或触发一个外部动作(如发送 Email) 处理其他副作用 如下图所示:与命令处理器不同的是，命令处理器只能被处理一次，而域事件可由一个或多个处理器响应，两者服务的目的不同，后者可以保证当业务功能增加时仅需增加更多的消费方而无需修改原有的部分。 实现域事件在 C# 中，域事件类型包含所有与该事件相关的数据，定义为简单的数据集类型，与 DTO 类型类似:1234567891011121314151617181920212223public class OrderStartedDomainEvent : INotification&#123; public string UserId &#123; get; &#125; public int CardTypeId &#123; get; &#125; public string CardNumber &#123; get; &#125; public string CardSecurityNumber &#123; get; &#125; public string CardHolderName &#123; get; &#125; public DateTime CardExpiration &#123; get; &#125; public Order Order &#123; get; &#125; public OrderStartedDomainEvent(Order order, int cardTypeId, string cardNumber, string cardSecurityNumber, string cardHolderName, DateTime cardExpiration) &#123; Order = order; CardTypeId = cardTypeId; CardNumber = cardNumber; CardSecurityNumber = cardSecurityNumber; CardHolderName = cardHolderName; CardExpiration = cardExpiration; &#125;&#125; 由于事件是过去发生的事情，所以定义域事件的类型必须是不可变类型，上述类型中的属性均为只读属性，构造器是唯一为这些属性赋值的地点。值得一提的是，如果需要对 DomainEvent 进行序列化和反序列化，则需要在这些属性中加入 private set。 发布域事件发布领域事件有两种方向的思潮，一种是当事件发生时立即推送至其对应的处理器，另一种是先将其添加至内存集合中，在提交事务之前或之后集中分发域事件，参考项目采用了第二种方法，还方法的好处可参考 A better domain events pattern。 决定在提交事务前后分发域事件与否非常重要，这意味着「副作用」是在事务边界之内还是之外。参考项目采用了延期集中分发事件的方式，实体首先将发生的事件添加至其 DomainEvents 集合，其定义在 Entity 基类中:12345678910111213141516public abstract class Entity&#123; //... private List&lt;INotification&gt; _domainEvents; public List&lt;INotification&gt; DomainEvents =&gt; _domainEvents; public void AddDomainEvent(INotification eventItem) &#123; _domainEvents = _domainEvents ?? new List&lt;INotification&gt;(); _domainEvents.Add(eventItem); &#125; public void RemoveDomainEvent(INotification eventItem) &#123; _domainEvents?.Remove(eventItem); &#125;//... Additional code&#125; 当事务提交至数据库时，所有的域事件会在这时进行分发，参考项目使用了 MediatR 和 EF Core:123456789public class OrderingContext : DbContext, IUnitOfWork&#123; public async Task&lt;bool&gt; SaveEntitiesAsync(CancellationToken cancellationToken = default(CancellationToken)) &#123; await _mediator.DispatchDomainEventsAsync(this); var result = await base.SaveChangesAsync(); &#125; // ...&#125; 这种方式也使得实体对发布事件的实现解除了耦合。 跨聚合单一事务还是多事务最终一致性跨聚合事务的一致性问题一直是业界争论的焦点，早期的 DDD 作者们主张将事务边界划分得越小越好，即单一事务仅与单个聚合相关，产生的任何副作用交由另外的事务，并由最终一致性确保状态正确。随着技术实现的发展，跨聚合事务的应用场景越屈合理化，特别是当某个聚合发布的域事件会引起其他聚合的状态改变，如果原始事务提交成功而改变其他聚合状态的事务提交失败，那么这两个聚合将产生不一致性。确保最终一致性将引入更多的代码复杂度，而像 EF Core 等类似的工具已经提供了跨数据库的分布式事务功能，从实现层面确保了跨聚合单一事务的可能性。意即，原始事务及其域事件产生的副作用事务同属一个 Scope，任何一步提交失败，整个 Scope 都将回滚。参考项目采用了这种实现方式。 映射事件至事件处理器分发事件完成之后，我们需要某种组件将事件推送至对应的事件处理器。一种方式是采用「消息队列」或「事件总线」，它们通常用于实现跨进程的异步通信，而对于域事件来说有点大材小用，因为域事件和域事件处理器属于同一个进程，只是实现在不同的层中。另一种方式是将域事件与处理器在 IoC 中注册，推送事件时动态解析处理器，如下图所示:参考项目采用了 MediatR 库来实现这一环节 域事件可以生成集成事件跨越服务边界值得提及的一点是，域事件处理器可以利用「事件总线」发布集成事件。 实现基础设施持久化层数据持久化组件提供了在有界上下文边界内访问数据的功能，它们包含了诸如「仓储」和「工作单元」等的实现类型。 每个聚合定义一个仓储应该为聚合或聚合根定义一个仓储，在 DDD 模式中，仓储是在持久化层面修改聚合的唯一通道。仓储与聚合是一对一关系，负责控制其不变条件与事务的持久化工作。如前文讨论的那样，查询可以借由另外的通道实现(如 CQRS)，因为查询不会更改系统的状态。 必须强调的是，每个聚合有且只能有一个对应的仓储，而不是为每个实体或每张数据库表创建仓储，下图展示了 Ordering 域下各个模型的关系:或者确切的说，仓储仅面向聚合根实体创建，在代码实现上可采用泛型仓储接口约束类型参数必须实现如上文提及过的 IAggregateRoot 接口，而具体的仓储实现可在基础设施层中定义，正如参考项目那样:123456789public interface IRepository&lt;T&gt; where T : IAggregateRoot&#123;&#125;public interface IOrderRepository : IRepository&lt;Order&gt;&#123;&#125;namespace Microsoft.eShopOnContainers.Services.Ordering.Infrastructure.Repositories&#123; public class OrderRepository : IOrderRepository&#123;&#125;&#125; 尽管论述了很多使用「仓储」所带来的好处，但它不是实现 DDD 的必要条件。Jimmy Bogard 指出，仓储隐藏了持久化机制的具体实现，不使用模拟仓储的原因在于始终要采用集成测试来覆盖测试代码，采用 CQRS 模式之后也意味着对采用仓储模式的需求减弱了。]]></content>
      <categories>
        <category>Architecture and Pattern</category>
      </categories>
      <tags>
        <tag>ddd</tag>
        <tag>architecture</tag>
        <tag>cqrs</tag>
        <tag>dotnet</tag>
        <tag>repository-pattern</tag>
        <tag>mediator-pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[跨微服务实现事件驱动的异步通信]]></title>
    <url>%2Farchitecture-event-driven-communication%2F</url>
    <content type="text"><![CDATA[本文索引: 问题场景 在微服务(集成事件)之间实现基于事件的通信 实现机制 定义集成事件 事件总线 定义事件总线接口 订阅事件 发布事件 在发布到事件总线时设计原子性和弹性 持久化集成事件 消息事件中的幂等性 问题场景正如实施微服务架构所面临的挑战所提到的，如何保证跨多个服务间的一致性，是一个显著的挑战。 在微服务(集成事件)之间实现基于事件的通信使用事件通信来实现跨多个服务的业务，借此在服务间保持最终一致性。最终一致性的事务由一系列分布式操作组成。在每个操作中，微服务更新业务实体并发布一个事件来触发下一个操作。同样以 eShopOnContainers 为例，下图展现了基于事件的异步通信过程: 实现机制eShopOnContainers 示例中展示的示例事件总线抽象和实现仅用作概念证明。一旦决定要进行异步和事件驱动的通信，应该选择最符合生产环境需求的服务总线产品。 EventBroker(消息代理): RabbitMQ、Azure 服务总线灯 ServiceBus(服务总线): NServiceBus、MassTransit 或 Brighter 在 RabbitMQ 和 Azure 服务总线之上运行。 通过在微服务之外发布「集成事件」来同步领域状态。当集成事件发布到多个「接收微服务」时，每个接收微服务中定义的相应处理程序将处理该事件。 定义集成事件eShopOnContainers 在 BuildingBlocks 中的 EventBus 项目定义了事件总线所有通用的类型，Events 目录下定义了 IntegrationEvent 类型:123456789101112131415161718192021public class IntegrationEvent&#123; public IntegrationEvent() &#123; Id = Guid.NewGuid(); CreationDate = DateTime.UtcNow; &#125; [JsonConstructor] public IntegrationEvent(Guid id, DateTime createDate) &#123; Id = id; CreationDate = createDate; &#125; [JsonProperty] public Guid Id &#123; get; private set; &#125; [JsonProperty] public DateTime CreationDate &#123; get; private set; &#125;&#125; 具体的集成事件在每个微服务的应用程序级定义，因为它们与其他微服务是解耦的。方式与服务器和客户端中的 ViewModel 的定义相当。不建议在多个微服务间共享一个通用的集成事件库，原因与不建议在多个微服务中共享通用的领域模型相同：微服务必须完全自治。 事件总线事件总线可以让微服务之间进行发布/订阅式通信，而不需要组件明确了解彼此。 如何实现发布者和订阅者之间的匿名性？一个简单的方法是让中间人负责所有沟通。事件总线就是这样的中间人。事件总线通常由两部分组成: 抽象或接口 一种或多种实现 只有当需要基本事件总线功能时，才使用自己的抽象(事件总线接口)。如果需要更丰富的服务总线功能，则应该使用商用服务总线提供的 API 和抽象，而非自己的抽象。 定义事件总线接口EventBus 项目下的 Abstraction 目录定义了 IEventBus 接口:123456789101112131415161718public interface IEventBus&#123; void Publish(IntegrationEvent @event); void Subscribe&lt;T, TH&gt;() where T : IntegrationEvent where TH : IIntegrationEventHandler&lt;T&gt;; void SubscribeDynamic&lt;TH&gt;(string eventName) where TH : IDynamicIntegrationEventHandler; void UnsubscribeDynamic&lt;TH&gt;(string eventName) where TH : IDynamicIntegrationEventHandler; void Unsubscribe&lt;T, TH&gt;() where TH : IIntegrationEventHandler&lt;T&gt; where T : IntegrationEvent;&#125; Publish 方法: 事件总线将集成事件广播给订阅了该事件的任何微服务，甚至是外部应用程序。该方法由发布事件的微服务使用。 Subscribe 方法（取决于不同参数，可以使用多个实现）由想要接收事件的微服务使用。这个方法有两个参数: 第一个是要订阅的集成事件(IntegrationEvent) 第二个参数是集成事件处理程序(或回调方法)，类型为 IIntegrationEventHandler&lt;T&gt;，当接收方微服务获取该集成事件消息时执行。 eShopOnContainers 中的一个自定义事件总线的实现基本上是使用 RabbitMQ API 库获得的(还有另一个基于 Azure 服务总线的实现)。该事件总线的实现使微服务能够订阅事件，发布事件并接收事件: EventBusRabbitMQ 类型实现了 IEventBus 接口:12345public class EventBusRabbitMQ : IEventBus, IDisposable &#123; // Implementation using RabbitMQ API //... &#125; 「发布微服务」和「订阅微服务」通过 DI 的方式在运行时将该实现类作为 IEventBus 的实现，以发布或订阅集成事件。 订阅事件使用事件总线的第一步是使微服务订阅想要接收的事件。下列代码显示了启动服务时(即在 Startup 类中)，为订阅所需事件而将特定的事件处理程序进行注册，这将发生在每个对这些事件感兴趣的「接收微服务」中。本例中 basket.api 微服务需要订阅 ProductPriceChangedIntegrationEvent 和 OrderStartedIntegrationEvent 消息:1234var eventBus = app.ApplicationServices.GetRequiredService&lt;IEventBus&gt;(); eventBus.Subscribe&lt;ProductPriceChangedIntegrationEvent, ProductPriceChangedIntegrationEventHandler&gt;(); eventBus.Subscribe&lt;OrderStartedIntegrationEvent, OrderStartedIntegrationEventHandler&gt;(); 上述代码运行后，「接收微服务」将通过 RabbitMQ 通道监听。当任何类型为 ProductPriceChangedIntegrationEvent 的消息到达后，将调用对应的事件处理程序并处理事件。 发布事件之后，「发布微服务」使用类似下列的代码发布集成事件。(这是一个不考虑原子性的简化示例。)每当事件必须跨多个微服务传播时，通常在从原始微服务提交数据或事务之后，就需要实现类似的代码。首先，事件总线实现对象将被注入控制器构造函数，如下代码所示:1234567891011121314151617[Route("api/v1/[controller]")] public class CatalogController : ControllerBase &#123; private readonly CatalogContext _context; private readonly IOptionsSnapshot&lt;Settings&gt; _settings; private readonly IEventBus _eventBus; public CatalogController(CatalogContext context, IOptionsSnapshot&lt;Settings&gt; settings, IEventBus eventBus) &#123; _context = context; _settings = settings; _eventBus = eventBus; // ... &#125;&#125; 随后从控制器中的方法中使用，如 UpdateProduct 方法:12345678910111213141516171819[Route("update")] [HttpPost] public async Task&lt;IActionResult&gt; UpdateProduct([FromBody]CatalogItem product) &#123; var item = await _context.CatalogItems.SingleOrDefaultAsync(i =&gt; i.Id == product.Id); // ... if (item.Price != product.Price) &#123; var oldPrice = item.Price; item.Price = product.Price; _context.CatalogItems.Update(item); var @event = new ProductPriceChangedIntegrationEvent(item.Id, item.Price, oldPrice); // Commit changes in original transaction await _context.SaveChangesAsync(); // Publish integration event to the event bus _eventBus.Publish(@event); // ... &#125;&#125; 在发布到事件总线时设计原子性和弹性考虑上述代码的关键部分:12345var @event = new ProductPriceChangedIntegrationEvent(item.Id, item.Price, oldPrice);// Commit changes in original transactionawait _context.SaveChangesAsync();// Publish integration event to the event bus_eventBus.Publish(@event); 如果服务在数据库更新之后崩溃，即崩溃发生在 await _context.SaveChangesAsync() 之后但在 _eventBus.Publish(@event) 之前。那么将导致领域状态已更新，但集成事件没有发布成功，整个系统状态可能会变得不一致。在探讨解决方案之前，首先了解: 强一致性: 即事务一致性，将多个操作放到单一事务处理，要么全部成功，要么全部失败。{asset_img } 最终一致性: 通过将某些操作的执行延迟到稍后的时间来执行。若前面的操作执行成功，后续操作将延后执行，若前面的操作失败，后续的操作就不会执行。 如果从微服务的角度看，每个微服务负责各自的业务逻辑，对于目录微服务来说，它的关注点是产品的更新是否成功。至于借助事件总线通过异步事件实现微服务间的通信，并不是其关注点。换句话说，产品的更新不应该依赖外部状态，在这里，外部状态就是事件总线的可用性。如果事件总线挂了，事件消息不能丢失，只要事件消息不丢，就还有机会挽救(重新发布消息)。 持久化集成事件eShopOnContainers 提到了以下 3 种模式以解决该问题的模式: 使用完整的事件溯源模式) 使用事务日志挖掘 使用发件箱模式。这是一个用于存储集成事件的事务表。 要保证事件消息不丢失，我们会第一时间想到持久化，eShopOnContainers 包含了一个名为 IntegrationEventLogEF 的项目，该项目定义了一系列用于持久化集成事件的通用类型，例如 IntegrationEventLogEntry 表示集成事件数据模型:1234567891011121314151617181920212223242526272829public class IntegrationEventLogEntry&#123; private IntegrationEventLogEntry() &#123; &#125; public IntegrationEventLogEntry(IntegrationEvent @event) &#123; EventId = @event.Id; CreationTime = @event.CreationDate; EventTypeName = @event.GetType().FullName; Content = JsonConvert.SerializeObject(@event); State = EventStateEnum.NotPublished; TimesSent = 0; &#125; public Guid EventId &#123; get; private set; &#125; public string EventTypeName &#123; get; private set; &#125; [NotMapped] public string EventTypeShortName =&gt; EventTypeName.Split('.')?.Last(); [NotMapped] public IntegrationEvent IntegrationEvent &#123; get; private set; &#125; public EventStateEnum State &#123; get; set; &#125; public int TimesSent &#123; get; set; &#125; public DateTime CreationTime &#123; get; private set; &#125; public string Content &#123; get; private set; &#125; public IntegrationEventLogEntry DeserializeJsonContent(Type type) &#123; IntegrationEvent = JsonConvert.DeserializeObject(Content, type) as IntegrationEvent; return this; &#125;&#125; 任何需要保证原子性的微服务都需要在本地持久化集成事件，并将更新领域状态与发布集成事件包含在同一个本地事务中。于是，新的步骤将演变为: 应用程序开始本地数据库事务 更新领域实体状态 将事件插入集成事件表 提交事务 这样，在持久化层面保证了所需的原子性，但实施发布事件的步骤有以下两种选择: 在提交事务后立即发布集成事件，并将其标记为已发布。当微服务发生故障时，可以通过遍历存储的集成事件(未发布)执行补救措施 将事件日志表用作一种队列。使用单独的线程或进程查询事件日志表，将事件发布到事件总线，然后将事件标记为已发布 第二种方式显然更为妥当，但为了简单起见，eShopOnContainers 实现了第一种方式。 消息事件中的幂等性幂等性意味着可以多次执行操作而不改变结果。在消息传递环境中传播事件时，如果可以多次传送事件而不改变「接收微服务」的结果，则事件是幂等的。在消息通信中我们需要确保操作是幂等的，或者能提供足够的信息，以确保可以检测到重复并丢弃，仅发送一个响应。 幂等消息可通过设计获得。例如，可以创建一个表示「将产品价格设置为 $25」而不是「将产品价格增加 $5」的事件。此时可以安全地处理第一种消息，无论处理多少次结果都一样。但即使在第一种情况下，可能也不想重复处理第一种事件，因为系统也可能发送了较新的价格变动事件，无序处理可能会导致覆盖新的价格。 让每个事件具有某种标识是种方便的做法，我们可以创建强制每个接收者对每个事件只处理一次的逻辑。更多关于消息幂等性可参考Journey 6: Versioning Our System。]]></content>
      <categories>
        <category>Architecture and Pattern</category>
      </categories>
      <tags>
        <tag>architecture</tag>
        <tag>microservices</tag>
        <tag>amqp</tag>
        <tag>event-driven-pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实施微服务架构所面临的挑战]]></title>
    <url>%2Farchitecture-microservice-challenges%2F</url>
    <content type="text"><![CDATA[参考资料: Github - eShopOnContainers 本文索引: 为什么需要微服务？ 微服务解决方案的优点: 微服务解决方案的缺点: 实施微服务架构所面临的挑战: 如何定义每个微服务的边界 如何创建从多个微服务中检索数据的查询 如何跨多个微服务实现一致性 如何设计跨微服务边界的通信 如何对服务实施版本策略？(TBD) 跨微服务的运行状况管理和诊断 总结 为什么需要微服务？微服务最大的好处，是它提供了长期的敏捷性。微服务可以基于多个可单独测试和部署的服务来创建应用，这些服务通常足够小且拥有独立的生命周期。 微服务解决方案的优点: 每个服务覆盖一个独立的业务区域，与其他区域解耦 每个微服务相对较小，易于管理和改进，特别是: 开发人员很容易理解并快速开始 诸如 Visual Studio 这样的 IDE 可快速加载较小的项目。 每个微服务都可独立于其他微服务进行设计、开发测试和部署，借此可获得敏捷性。 单独扩展应用程序的特定部分: 相对于单体应用必须作为整体来扩展，微服务可以只扩展特定部分，这样就能按需扩展真正需要更多处理资源或网络带宽的功能，而不是一起将本不需要扩展的其他功能区域也进行扩展。使用的硬件更少了，也意味着节约了成本。 多个开发团队可以分开工作 问题的隔离程度更高 方便使用最新技术 微服务解决方案的缺点: 分布式应用: 开发人员设计和构建服务时，分发应用程序的过程变得更复杂。例如，开发人员必须使用诸如 HTTP 或 AMQP 等协议实现服务间通信，这增加了测试和异常处理的复杂性，还增加了系统的延迟。 部署的复杂性: 具有数十个微服务并需要高可扩展性的应用程序(需要能为每个服务创建多个实例，并在多个主机间平衡这些服务)，意味着 IT 运维和管理变得更复杂。如果不使用面向微服务的基础架构(如编排引擎和调度器)，那么额外的复杂性可能需要比业务应用程序本身更多的开发工作。 原子事务: 多个微服务间的原子事务通常是不可能实现的。必须寻求可行的办法包含多个微服务间的最终一致性。 全局资源需求增加: 在许多情况下，当使用微服务方法替换单体应用程序时，新的微服务应用程序所需的全局资源数量将大于原本的单体应用程序对基础设施的需求。然而，一般来说考虑到资源成本较低，而且在单体应用演进过程中，与长期成本相比，能够将应用程序特定领域的能力扩大等优势，因此资源用量的增加对大规模、长期运行的应用程序来说，通常是一个很好的权衡。 客户端与微服务的直连通信问题: 当应用程序很大，包含很多微服务时，如果应用程序需要客户端与微服务之间进行直接通信，通常会面临挑战和局限。例如客户端的需求和每个微服务暴露的 API 可能不匹配。在某些情况下，客户端应用程序可能需要通过大量单独的请求来组成用户界面，这在互联网上可能是低效的。因此，客户端应用程序对后端系统的请求应尽可能最少。客户端和服务之间的这种直接通信造成的另一个问题: 难以重构。随着时间推移，开发人员可能会修改系统划分的方式。例如，可能会合并两个服务，或将一个服务拆分为两个或更多服务。但是如果客户端直接与服务通信，则执行此类重构可能会破坏与客户端应用程序的契约。 如何分割微服务: 最后，无论为微服务架构采取哪种方法，另一个挑战在于: 如何将应用程序分割成多个微服务。 实施微服务架构所面临的挑战:尽管采用微服务架构利大于弊，但仍有诸多挑战在真正实施之前需要考虑。它们是: 如何定义每个微服务的边界定义微服务边界可能是每位想要实施微服务遇到的第一项挑战。每个微服务必须是应用程序的一部分。但是，如何识别这些边界？ 首先，需要关注应用程序的逻辑域模型和相关数据，不同上下文中所用的术语和实体可能听起来很相似，但你可能会发现在特定上下文中，某个业务概念在另一个上下文中用于不同目的，甚至名称也不同。例如，用户在「会议管理」上下文中称为「用户」，在「订单和注册」上下文中称为「买家」，在「支付」上下文中则称为「付款方」等等。 多个应用程序上下文(各上下文具有不同域)之间的边界识别方法，也可用于识别各业务微服务及其相关域模型和数据的边界。始终尝试最大程度减少这些微服务之间的耦合度。 如何创建从多个微服务中检索数据的查询如何实现从多个微服务获取数据的查询，同时避免远程客户端和微服务之间不必要的通信。例如一个移动 App 需要一个页面来展示由购物篮、产品目录和用户身份微服务包含的用户信息。再比如一个复杂的报表系统涉及到位于多个微服务的多个表。适合的解决方案取决于查询的复杂性。但无论如何都需要一种方式来聚合信息，以提高系统的通信效率。最流行的解决方案如下: API 网关模式: 对于来自多个微服务(拥有不同数据库)的简单数据聚合，推荐方法是称为 API 网关的聚合微服务。然而使用这种模式时需要当心，它可能成为系统瓶颈，也可能违反微服务自治的原则。为了降低这些可能性，可以使用多个细粒度的 API 网关，每个网关主要面向系统的一个垂直切片业务领域。 CQRS 查询/读取表: 另一种聚合多个微服务数据的方案是物化视图模式 Materialized ViewPattern，这种方案会提前(在实际查询发生前准备好非规范的数据)生成包含多个微服务数据的只读表，并且这种表会使用适合客户端应用需求的格式。 中央数据库的「冷数据」: 对于可能不需要实时数据的复杂报告和查询，常用方法是将「冷数据」作为「热数据」(来自微服务的事务数据)导出到仅用于报告的大型数据库。该中央数据库系统可以是基于大数据的系统(如 Hadoop)、基于 Azure SQL 数据仓库的数据仓库，甚至是仅用于报告的单个 SQL 数据库(如果大小没有问题)。 注意，此集中式数据库仅用于不需要实时数据的查询和报告。作为事实来源的原始更新和事务必须位于微服务数据中。用于同步数据的方法有两种：使用事件驱动的通信，或使用其他数据库基础结构导入/导出工具。 如何跨多个微服务实现一致性每个微服务拥有的数据是该微服务专有的，并且只能通过其本身的微服务 API 访问。因此，面临的挑战是如何在保持多个微服务的一致性的同时实现端到端的业务逻辑。 「目录微服务」保存所有产品的相关信息，包括它们的库存。「订购微服务」管理订单，并且必须验证新订单是否超过可用目录产品库存。在该应用程序的单片版本中，订购子系统可简单地使用 ACID 事务来检查可用库存、在订单表中创建订单以及更新产品表中的可用库存。 但是，在基于微服务的应用程序中，订单和产品表属于其各自的微服务。如图所示，微服务不应包含其他微服务在其事务或查询中所拥有的数据库。 订购微服务不应直接更新产品表，因为产品表属于目录微服务。要更新目录微服务，订购微服务应只使用异步通信，如集成事件(消息和基于事件的通信)。需要在可用性和 ACID 一致性之间做出选择。大多数基于微服务的方案都需要高可用性和高可伸缩性，而非一致性。重要应用必须保持随时在线，开发人员可通过弱一致性或最终一致性的技术来做到强一致性。 这是大多数基于微服务的体系结构采用的方法。 此外，ACID 风格或两步提交事务不仅违背微服务原则，大多数 NoSQL 数据库(如 Azure Cosmos DB、MongoDB 等)不支持两步提交事务。然而，跨服务维护数据的一致性非常重要，这个挑战关系到当某些数据需要实现冗余时，如何跨微服务执行变更的问题，例如需要更新目录微服务和购物篮微服务中的产品名称或描述时。 如何设计跨微服务边界的通信假设客户端应用程序对单个微服务(如订购微服务)进行 HTTP API 调用。如果订购微服务在相同的请求/响应周期内转而使用 HTTP 调用其他微服务，这表示正在创建 HTTP 调用链。刚开始时，这可能听起来很合理。但是，如果继续进行，则需要考虑一些重要问题： 阻塞和低性能: 由于 HTTP 的同步本质，最初的请求在所有内部 HTTP 请求全部完成前不会获得响应结果。假设这样的请求量在逐步增长，同时某个中间微服务的 HTTP 调用被阻塞，结果就是性能受到影响，并且整体扩展性由于额外 HTTP 请求的增加遇到几何级增长的影响。 微服务将与 HTTP 耦合: 业务微服务不应与其他业务微服务耦合。理想情况下，它们不应「知道」其他微服务的存在。如果应用程序依赖于如例所示的耦合微服务，那么几乎不可能实现每个微服务的自治。 任何微服务引起的宕机: 如果实现由 HTTP 调用链接的微服务链，那么任一微服务宕机(最终所有微服务都可能宕机)，整个微服务链将挂掉。微服务系统应该设计成在部分宕机情况下尽可能地继续正常运行。即使客户端逻辑使用了越来越快和灵敏的重试机制，HTTP 调用链越复杂，实现基于 HTTP 的容错策略过程就越复杂。 生成基于微服务的应用程序时，重要的是集成微服务的方法。理想情况下，应尝试减少内部微服务之间的通信，微服务间的通信越少越好。但在许多情况下，必须以某种方式集成微服务，当需要执行此操作时，关键的规则是微服务间的通信应为「异步」。这并不代表必须使用特定协议(例如，异步消息传送与同步 HTTP)。这仅代表微服务之间的通信「应该只通过异步传播数据来完成，但不要依赖其他内部微服务作为初始服务的 HTTP 请求/响应操作的一部分。」 微服务通信通常分为两个轴: 同步还是异步 同步协议: HTTP 是同步协议。客户端发送请求并等待服务响应，这与客户端代码执行无关，客户端可能是同步(线程被阻止)或异步的(线程没有被阻止，并且响应最终会到达回调)。重要的是，协议 (HTTP/HTTPS) 是同步的，仅当客户端代码接收到 HTTP 服务器响应时，才可以继续其任务。 异步协议: AMQP 之类的其他协议（许多操作系统和云环境支持的协议）使用异步消息。客户端代码或消息发件人通常不会等待响应。 单个接收方还是多个接收方 单个接收方: 命令模式，具有单个接收者的基于消息的异步通信意味着存在点到点通信，即，仅向正在从该通道读取数据的一个使用者传递消息，并且该消息仅处理一次。但也有一些特殊情况。例如，在试图从故障中自动恢复的云系统中，可以多次发送相同的消息。由于网络或其他故障，客户端必须能够重试发送消息，并且服务器必须实现幂等操作，以便对特定消息仅处理一次。基于消息的单接收者通信特别适用于将异步命令从一个微服务发送到另一个微服务。 多个接收方: 发布/订阅模式，作为一种更灵活的方法，你可能还需要使用发布/订阅机制，以便其他订阅者微服务或外部应用程序能够收到发送者发送的通信。这样一来，以后无需修改发送者服务也可添加额外的订阅者。使用发布/订阅通信时，你可能会使用事件总线接口向任何订阅者发布事件。 如何对服务实施版本策略？(TBD) HTTP 服务: 使用将版本号嵌入 Url 的方式实现 REST 采用 Hypermedia 跨微服务的运行状况管理和诊断跨越多个独立服务将诊断事件关联在一起，以及处理机器时钟偏差让事件顺序更合理，这些方面有着不小的挑战。如同微服务间的交互需要统一的协议和数据格式，我们也需要通过标准来规定如何记录运行状况和诊断事件，最终保存在事件存储器中供查询查看。微服务方式下，关键在于不同团队必须采用统一的日志格式。应用中也需要通过一致的方式来查看诊断事件。 ASP.NET HealthChecks 在编排引擎或集群中通过多个节点运行多个服务的分布式应用中，要把分布的事件关联起来就成了一个挑战。微服务应用不应该尝试自己存储事件输出流或日志，也不需要管理集中存储的事件路由。它应该是透明的，这意味着每个进程只需要将事件流写入到标准输出，运行进程的底层基础执行环境会收集这些信息。例如 Microsoft.Diagnostic.EventFlow 就是这样的一种事件转发器，它会从多个源收集事件流然后发布到输出系统，包括开发环境用到的简单标准输出，或者云上的系统，例如 Application Insights、OMS（本地部署使用）和 Azure 诊断。另外还有大量第三方日志分析平台和工具可提供搜索、报警、报表和监控等功能，甚至可以实时进行，例如 Splunk 总结微服务实践涉及太多的细节，在后续的篇幅中，希望通过阅读更多的资料并结合自身实践，逐个攻破这些挑战。]]></content>
      <categories>
        <category>Architecture and Pattern</category>
      </categories>
      <tags>
        <tag>ddd</tag>
        <tag>architecture</tag>
        <tag>microservices</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cordova 的 Plugin 及创建自定义 Android Plugin]]></title>
    <url>%2Fcordova-create-custom-android-plugin%2F</url>
    <content type="text"><![CDATA[参考资料: Plugin Development Guide Create a Custom Cordova Plugin Android Plugin Development Guide Plugin.xml 本文索引: 添加 plugin 添加 Android 平台支持 Plugman 安装 Plugman 创建 Plugin 定义 Javascript 接口 本地实现 创建 Java 实现类 更新 plugin.xml 安装及更新 Plugin 调试 Plugin 调试 Javascript 源代码 调试 Android 源代码 添加 plugin为了让 web app 能够访问移动设备的本地功能，cordova 以 plugin 的方式粘合 web app 和移动设备本地 SDK。plugin 将移动设备本地 SDK 的功能以 Javascript API 的方式暴露给 web app。标准化的 plugin 大多以 npm 包的形式提供，可借助类似 cordova plugin search camera 的命令搜索相应的 plugin，而一些通用的 API 则被 cordova 内置集成，它们被称为 Core Plugin APIs。现在，我们将提供本地相机功能的 camera plugin 添加至 Cordova 快速开始中的初始项目:1$ cordova plugin search camera 取到准确的 plugin 名称之后，安装该 plugin:12345$ cordova plugin add cordova-plugin-cameraFetching plugin "cordova-plugin-camera@~2.1.0" via npmInstalling "cordova-plugin-camera" for androidInstalling "cordova-plugin-camera" for ios 可执行 cordova plugin ls 查看当前已安装的 plugin:1234$ cordova plugin lscordova-plugin-camera 2.1.0 "Camera"cordova-plugin-whitelist 1.2.1 "Whitelist" 添加 Android 平台支持首先为 cordova 项目添加 android 平台:12345$ cordova platform add androidInstalled platforms: android 7.1.2 browser 5.0.4 检查 config.xml 及 package.json 文件，确保其相应的配置已保存。 PlugmanPlugman 是一个用于管理 cordova plugin 的 npm 包，也是官方推荐的用来开发 plugin 的工具，关于 Plugman 的命令可参考 Using Plugman to Manage Plugins 安装 Plugman1$ npm install -g plugman 创建 Plugin导航至 Plugin 的目标目录，执行:1$ plugman create --name &lt;pluginName&gt; --plugin_id &lt;pluginID&gt; --plugin_version &lt;version&gt; [--path &lt;directory&gt;] [--variable NAME=VALUE] 上述命令表示，name，plugin_id，和 plugin_version 为必填项，path 为可选项。例如:1$ plugman create --name ServiceBridge --plugin_id service_bridge --plugin_version 0.0.1 --path ./plugins 该命令会在指定 ./plugins 下创建一个名为 ServiceBridge 的 plugin，并填充一系列初始化配置: 该命令生成了标准化的目录结构及 plugin.xml 和 www/ServiceBridge.js 两个文件。 plugin.xml 文件 plugin.xml 必须位于插件目录的顶层，为插件的描述文件，由 Plugman 生成的初始模板为: 12345678&lt;?xml version='1.0' encoding='utf-8'?&gt;&lt;plugin id="service-bridge" version="0.0.1" xmlns="http://apache.org/cordova/ns/plugins/1.0" xmlns:android="http://schemas.android.com/apk/res/android"&gt; &lt;name&gt;ServiceBridge&lt;/name&gt; &lt;js-module name="serviceBridge" src="www/serviceBridge.js"&gt; &lt;clobbers target="bridge" /&gt; &lt;merges target="bridge" /&gt; &lt;/js-module&gt;&lt;/plugin&gt; 其中 plugin 节点: id: 用于 npm 唯一标识该 plugin version: 指示当前 plugin 的版本号 name 节点: 阅读友好的 plugin 名称 js-module: 通常， plugin 都包含一个或多个 Javascript 文件，每个 js-module 节点对应一个 Javascript 文件，这使得 plugin 的使用者无需手动在自己的源代码文件中添加 &lt;script&gt; 节点。安装上述 plugin 后，www/serviceBridge.js 被拷贝至对应 platform 项目下的 www/plugins/service-bridge/serviceBridge.js，并在 www/cordova_plugins.js 库中添加一条 entry。在运行时，cordova.js 库使用 XHR 读取每个 Javascript 文件并在 Html 中添加相应的 &lt;script&gt; 节点。 src: 引用一个文件(相对于 plugin.xml 文件的相对路径) name: 表示模块名称的最后一个部分，可为任意值，仅当希望在该 Javascript 文件使用 cordova.require 引入插件的其他部分时起作用。一个 js-module 的模块名称通常为 {plugin-id}.{name}。上述例子的 js-module 的完整名称为 service-bridge.serviceBridge。 &lt;clobbers target=&quot;some.value&quot;&gt;: 指示 module.exports 将以 window.some.value 的对象注入至 window 对象，可以包含任意多个 clobbers 节点。(若 window 上不存在该对象，将自动创建） &lt;merges target=&quot;some.value&quot;&gt;: 指示模块将合并至 window.some.value，如果该值已经存在，将覆盖原始版本。同样，可以包含任意多个 merges 节点。(若 window 上不存在该对象，将自动创建） 一个空的 js-module 节点仍会加载，并且可以在其他模块中以 cordova.require 访问。 在 platform 节点下嵌套 js-module 表示该模块仅用于该 platform 下。 plugin.xml 的详细内容可参考 Plugin Specification 定义 Javascript 接口查看 www/serviceBridge.js 文件:12345var exec = require('cordova/exec');exports.coolMethod = function (arg0, success, error) &#123; exec(success, error, 'ServiceBridge', 'coolMethod', [arg0]);&#125;; 可进一步组织 Javascript 接口的编码风格，但在与本地 SDK 进行交互时总是需要调用 cordova.exec，其语法大致为:12345cordova.exec(function(winParam) &#123;&#125;, function(error) &#123;&#125;, "service", "action", ["firstArgument", "secondArgument", 42, false]); 这些参数表明: function(winParam){}: 执行成功时的回调函数 function(error){}: 执行失败时的回调函数 service: 在本地库中所要调用的服务，通常对应本地库的类型名称 action: 在本地库中所要执行的动作，通常对应本地库的方法名称 [/* arguments */]: 传递给本地库方法的参数数组 现在，修改 www/serviceBridge.js 文件，以定义 Javascript 接口:1234567var exec = require('cordova/exec');exports.mutiply = function (num1, num2, callback) &#123; exec(callback, function (err) &#123; console.log('something is wrong, ' + err); &#125;, 'ServiceBridge', 'multiply', [num1, num2]);&#125; 上述代码表明该 plugin 将一个 multiply 函数导出至 js-module，并提供了与本地库交互的功能。 本地实现对 Javascript 接口定义完成后，需要至少提供一种 platform 的本地实现，本文以 Android 平台为例。Android 插件基于 Cordova-Android 机制，最终由 Android 本地库的 WebView 加上一个 Java 类型提供实现。plugin 的本地 Java 类型由一个继承自 CordovaPlugin 的类型实现(需要重写父类的 execute 方法)。 创建 Java 实现类在 plugin 目录的 src/android 下创建 ServiceBridge.java 文件，并填充如下实现:123456789101112131415161718192021222324252627282930313233package com.sample.plugin;import org.apache.cordova.CordovaPlugin;import org.apache.cordova.CallbackContext;import org.json.JSONArray;import org.json.JSONException;import org.json.JSONObject;import io.cordova.hellocordova.R.string;/** * This class echoes a string called from JavaScript. */public class ServiceBridge extends CordovaPlugin &#123; @Override public boolean execute(String action, JSONArray args, CallbackContext callbackContext) throws JSONException &#123; if (action.equals("multiply")) &#123; String num1 = args.getString(0); String num2 = args.getString(1); this.multiply(num1, num2, callbackContext); &#125; return false; &#125; private void multiply(String num1Msg, String num2Msg, CallbackContext callbackContext) &#123; int num1 = Integer.parseInt(num1Msg); int num2 = Integer.parseInt(num2Msg); int result = num1 * num2; callbackContext.success(result); &#125;&#125; CordovaPlugin 类型位于顶部 import 的 org.apache.cordova.CordovaPlugin 包中，该类型的 execute() 方法接收 Javascript 接口中的 exec 方法的消息，返回值 bool 表明当前方法的执行结果，true 或 false 被分别解释为不同的返回类型并触发由 Javascript 接口传入的成功或失败的回调函数。 接下来，该方法查询传入参数的 action 的值，并将 callbackContext 一起传入私有方法 multiply，值得注意的是，callbackContext.error() 和 callbackContext.success() 将分别触发 Javascirpt 的失败和成功回调函数。 以上述 multiply 方法为例，当 Javascript 接口中执行:1cordova.exec(&lt;successFunction&gt;, &lt;failFunction&gt;, &lt;service&gt;, &lt;action&gt;, [&lt;args&gt;]); 时，方法将 WebView 中的请求封送至本地库，调用 service 下的 action 方法。本地库代码在 Plugin 中可由 .java 源代码或 .jar 包的形式存在。 更新 plugin.xmlJava 实现完成之后，更新 plugin.xml 文件声明:123456789101112131415161718&lt;?xml version='1.0' encoding='utf-8'?&gt;&lt;plugin id="service_bridge" version="0.0.1" xmlns="http://apache.org/cordova/ns/plugins/1.0" xmlns:android="http://schemas.android.com/apk/res/android"&gt; &lt;name&gt;ServiceBridge&lt;/name&gt; &lt;js-module name="serviceBridge" src="www/serviceBridge.js"&gt; &lt;clobbers target="bridge" /&gt; &lt;merges target="bridge" /&gt; &lt;/js-module&gt; &lt;platform name="android"&gt; &lt;source-file src="src/android/ServiceBridge.java" target-dir="com/sample/plugin/" /&gt; &lt;config-file target="res/xml/config.xml" parent="/*"&gt; &lt;feature name="ServiceBridge"&gt; &lt;param name="android-package" value="com.sample.plugin.ServiceBridge"/&gt; &lt;/feature&gt; &lt;/config-file&gt; &lt;/platform&gt;&lt;/plugin&gt; 在 js-module 之后加入了以下节点: platform: 标识一个 native 平台，不包含 platform 节点的 plugin 会被认为是 Javascript Only，可被安装至任意 platform name 标识具体的平台名称，该值必须为小写，且为以下可选值: amazon-fireos android blackberry10 ios wp8 source-file 元素: 指定可执行程序的源代码文件，并将被安装至相应的项目下。 src: 必须，相对于 plugin.xml 的路径，如果找不到指定文件，plugman 将报错并回滚安装 target-dir: 文件应该被拷贝的目录，相对于对应根目录，该特性主要服务于 Java-based 平台，一个位于 com.alnny.foo 包的文件，该值则必须为 com/alunny/foo 目录，对于源代码目录不敏感的平台，该值可被忽略。 config-file 元素: 代表一个期望被追加的 xml 配置文件，该元素仅表示希望追加的子元素内容，其子元素则为具体追加的内容，目前 xml 和 plist 文件。 target: 指示被追加的文件路径，相对于 Cordova 项目根目录，该值支持 * 通配符，plugman 将在所有符合条件的匹配项取第一个，如果目标文件无法找到，则 plugman 继续安装并忽略这些追加 parent: 以 XPath 指定希望搜索的父级目录，同样支持 * feature 元素: 指定被追加至目标 xml 文件的子元素，该元素代表了目标功能的声明。 name: 对应于 Javascript 接口中调用 exec 时的 service 参数，此处值为 ServiceBridge param: 节点的 value 值对应于 Java 类型的「完全限定名」。 安装及更新 Pluginplugin 开发完成之后，将其安装至当前 Cordova 项目的 Android 平台下:12plugman install --platform android --project platforms/android --plugin '&#123;full_path_your_plugin&#125;\plugins\ServiceBridge' 由于 plugin 暂时在本地开发，更新流程通过重装的方式实现，卸载插件:12$ plugman uninstall --platform android --project platforms/android --plugin '&#123;full_path_your_plugin&#125;\plugins\ServiceBridge' 调试 PluginCordova 是包含了所添加的 platform 的原生 app 项目的，使用 Android Studio 打开 platforms/android 目录，它被识别为一个有效的 Android 项目:在 Android Studio 中开始调试，选择一个 Android 模拟器，成功启动之后，即可开始调试: 调试 Javascript 源代码项目的 Javascript 部分可通过 Chrome Remote Debug 连接至 Android 模拟器远程调试，打开 Chrome 新的标签页，输入 chrome://inspect/#device，勾选 Discover network targets，加载片刻之后，运行中的安卓模拟器出现，点击 inspect 开始远程调试: 调试 Android 源代码在 Android Studio 中为 Java 源代码设置断点，即可开始调试:]]></content>
      <categories>
        <category>Hybrid</category>
      </categories>
      <tags>
        <tag>hybrid</tag>
        <tag>cordova</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cordova 快速开始]]></title>
    <url>%2Fcordova-get-started%2F</url>
    <content type="text"><![CDATA[参考资料: Create your first Cordova app Android Platform Guide 本文索引: 准备 安装 cordova cli 创建 cordova app 在 Android 上测试 cordova app 准备 设置环境变量 使用 merges 为单独的 platform 提供定制化内容 更新 cordova 及项目 准备确保以下工具集已安装好: nodejs 和 npm: cordova cli 是一个运行在 nodejs 上的 npm 包 git: 用于在安装过程中下载某些依赖 git 仓库的文件 安装 cordova cli1$ npm install -g cordova 创建 cordova app 导航至一个目标目录，执行 cordova create hello 导航至项目目录内: cd hello 添加支持的 platform: 可执行 cordova platform ls 查看当前已支持的 platform 及可支持的 platform，添加对 browser，ios，和 android 的支持 cordova platform add browser cordova platform add ios cordova platform add android 安装对应 platform 的 SDK: 要生成不同 platform 的 app，要求开发环境中必须包含编译该 platform 所需的 SDK，browser platform 无需任何特定的 SDK，以下列出常见 platform 编译所需环境的参考： Android: 参考 Android Platform Guide iOS: 参考 iOS Platform Guide Windows: Windows Platform Guide 初始化: 默认情况下，cordova create 创建的是基于 browser platform 的项目，可在 www/js/index.js 中的 onDeviceReady 扩展初始化逻辑 生成: 执行 cordova requirements [platform] 检查当前环境是否满足生成对应 platform 的要求，若不指定 platform，则检查所有已支持 platform 的编译要求 执行 cordova build [platform] 生成对应 platform，不指定 platform 则生成所有支持的 platform 在 Android 上测试 cordova app准备 JDK(Java Development Kit): 前往 JDK 官网 下载对应的开发套件，在 Windows 系统下需要设置 JAVA_HOME 环境变量至 JDK 的安装目录(参考这里) Gradle: 生成 Android 应用时必须的工具库，其依赖 JDK 或 JRE，参考安装指南在不同系统中安装 Gradle。在 Windows 系统下需要在 PATH 环境变量中指定 Gradle 的路径(参考这里)，安装完成后，检查版本: 1234$ gradle --version------------------------------------------------------------Gradle 4.10.2------------------------------------------------------------ Android SDK: Android Studio 集成了 Android SDK，可至官网下载并安装，Android Studio 安装完成后，使用其集成的 SDK Manager 安装以下必备的 SDK: Android Platform SDK Android SDK build-tools: 版本 19.1.0 或更高 Android Support Repository 注意: x86 的 Android Image 要求使用硬件加速，该功能不能与 Windows 系统上的 Hyper-V 共存，在安装 Intel Hardware Accelerated Execution Manager 之前确保 Hyper-V 已被禁用 设置环境变量当以上所有依赖的环境安装完成后，开始设置环境变量: JAVA_HOME 环境变量设置到 JDK 的安装目录 ANDROID_HOME 环境变量设置到 Android SDK 的安装目录 Android SDK 的 tools，tools/bin 及 platform-tools 目录添加至 PATH 环境变量 一切就绪之后，执行以下命令检查当前环境是否能够成功生成 Android App:1234567$ cordova requirements androidRequirements check results for android:Java JDK: installed 1.8.0Android SDK: installed trueAndroid target: installed android-28,android-27Gradle: installed D:\Program Files\Android\Android Studio\gradle\gradle-4.6\bin\gradle 生成 Android App:123456$ cordova build androidBUILD SUCCESSFUL in 2s46 actionable tasks: 1 executed, 45 up-to-dateBuilt the following apk(s): D:\projects.untracked\lightspeed\poc-webapp-cordova\platforms\android\app\build\outputs\apk\debug\app-debug.apk 在模拟器上测试 App:1$ cordova emulate android 或者:12345678$ cordova run android --emulatorBuilt the following apk(s): \\&#123;your-project-root-directory&#125;\platforms\android\app\build\outputs\apk\debug\app-debug.apkUsing apk: \\&#123;your-project-root-directory&#125;\platforms\android\app\build\outputs\apk\debug\app-debug.apkPackage name: io.cordova.hellocordovaINSTALL SUCCESSLAUNCH SUCCESS 如果手上有一台搭载 Android 系统的手机，执行 cordova run android 在真机上测试。 使用 merges 为单独的 platform 提供定制化内容cordova 使用 merges 目录为 platform 存储定制化内容，项目顶层目录下的 merges/{platform} 目录镜像了 www 的目录结构，将希望覆盖或额外添加的内容放置在 merges/{platform} 目录下。 更新 cordova 及项目更新 cordova:1$ (sudo) npm update -g cordova 更新 platform:12$ cordova platform update android --save$ cordova platform update ios --save]]></content>
      <categories>
        <category>Hybrid</category>
      </categories>
      <tags>
        <tag>hybrid</tag>
        <tag>cordova</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在 .NET Framework 中集成 CefSharp]]></title>
    <url>%2Fdotnet-cefsharp%2F</url>
    <content type="text"><![CDATA[参考文档: General Usage Display HTML in WPF and CefSharp Tutorial Part 1 本文索引: 快速开始 进程 Process 线程 Threads Initialize 和 Shutdown Initialize Shutdown 配置 CefSettings BrowserSettings IBrowser，IFrame 和 IBrowserHost 对象 Handlers 配置代理 请求上下文 高 DPI 显示器支持 Javascript 集成 从 .NET 中调用 Javascript 方法 从 .NET 中调用带有返回结果的 Javascript 方法 将一个 .NET 类型暴露给 Javascript 异步 Javascript Binding API CefSharp.BindObjectAsync CefSharp.DeleteBoundObject CefSharp.RemoveObjectFromCache CefSharp.IsObjectCached 集成示例 快速开始创建一个新的 WPF 项目，目标框架为 .NET Framework 4.5.2，本项目将使用 CefSharp 3 库，该库仅支持 x86 和 x64 应用程序，这意味着项目必须指定编译目标，不支持 Any Cpu。创建项目后，首先打开配置管理器，Solution -&gt; Configuration Manager:由默认 Debug 配置创建新的 x86 和 x64 的编译配置:完成配置创建后，引入 CefSharp.Wpf Nuget 包:现在，保存所有更改并关闭 Visual Studio，因为 CefSharp 需要完全重启以加载其依赖项。重启打开 Visual Studio 项目，编译。 进程 ProcessCEF 运行时包含多个进程 browser 进程: 主进程，负责创建窗口，渲染和网络访问，该进程大部分情况下等同于「宿主应用程序」所在的进程，且执行大部分逻辑。 render 进程: 渲染和与 Javascript 交互(如 JS 对象绑定)由另一个 render 进程处理，进程模型将会为每一个单独的 Origin([scheme] + [domain]) 开辟一个 render 进程。 plugin 进程: 负责处理诸如 Flash 等插件 gpu 进程: 处理渲染加速等 线程 Threads不同级别的进程可管理多个线程，browser 进程包含了以下线程: UI 线程: browser 进程的主线程，默认情况下 CefSharp 使用 setting.MultiThreadedMessageLoop = true 设置，这使得 CEF 的 UI 线程与宿主应用程序的 UI 线程使用不同的线程。 IO 线程: 在 browser 进程中负责处理 IPC 和网络消息 File 线程: 在 browser 进程中负责与「文件系统」交互 Renderer 线程: render 进程的主线程 Initialize 和 ShutdownInitializeInitialize 方法仅允许每个应用程序调用一次，该方法用于初始化底层 CEF 库，可以显式或隐式的调用该方法: 隐式调用: 首次创建 ChromiumWebBrowser 实例时，将检查 CEF 是否已被初始化，如果没有，则使用默认配置调用初始化方法 显式调用: 当希望指定自定义配置时，可显式调用 CEF.Initialize(CefSettings settings) 方法 ShutdownChromiumWebBrowser 的 WPF 和 Winform 的实现都在对应的 Exit 事件中默认调用了 Shutdown 方法。要禁用这一行为，可在任一 ChromiumWebBrowser 实例创建之前设置 CefSharpSettings.ShutdownOnExit = false。 Initialize 和 Shutdown 都必须在应用程序的主线程中调用，如果在另外的线程中调用它们，应用程序将会挂起。 在 CefSharp.OffScreen 应用中，在应用程序退出前必须显式调用 Cef.Shutdown() 方法。 配置CefSettingsCefSettings 覆盖了应用程序级别的配置，一些常见的配置包括: BrowserSubprocessPath: 启用子进程的路径，通常不建议更改 MultiThreadedMessageLoop: 默认为 true，也可以设置为 false 并将 Cef 集成至现有应用程序的消息泵中，参考 https://github.com/cefsharp/CefSharp/issues/1748 CommandLineArgsDisabled: 设置为 true 以禁用使用标准的 Chromium 命令行参数控制浏览器行为 CachePath: 缓存数据在本机上存放的路径，若为空，则使用临时缓存和内存缓存。仅当该设置不为空时，HTML5 数据库(如 localStorage)才会被持久化 Locale: 传给 Blink 的本地化信息，en-US 为默认值，可由命令行参数 lang 控制 LogFile: Debug 日志使用的持久化目录与文件名。./debug.log 为默认值。可由命令行参数 log-file 控制 LogSeverity: 类似于 LogLevel，仅当等于或高于该级别的日志将会记录，可由 log-severity 命令行参数控制，可接收 verbose、info、warning、error、error-report 和 disabled 值。 ResourceDirPath: 资源路径，可由 resources-dir-path 命令行参数控制 LocalesDirPath: 本地化信息路径，可由 locales-dir-path 命令行参数控制 RemoteDebuggingPort: 可在 1024 - 65535 之间取值，用以启用远程调试，可由另一个 CEF 或谷歌浏览器访问，可由 remote-debugging-port 命令行参数控制。 BrowserSettingsBrowserSettings 覆盖 ChromiumWebBrowser 实例级别的配置，具体参考 BrowserSettings 类型 IBrowser，IFrame 和 IBrowserHost 对象IBrowser 和 IFrame 对象用于向浏览器发送命令及从回掉函数中接收状态信息，每一个 IBrowser 对象都至少包含一个 IFrame 对象代表顶层窗口。即，如果一个浏览器窗口加载了两个 &lt;iframe&gt; 元素将会包含 3 个 IFrame 对象(一个顶层 IFrame 和两个 &lt;iframe&gt;)。 在一个 IBrowser 对象中加载 url:1browser.MainFrame.LoadUrl(url); IBrowserHost 代表更底层的浏览器方法，例如: Print() ShowDevTools() CloseDevTools() StartDownload(string url) HandlersCefSharp 提供了一系列 Handler 对象，这些对象以 .NET 实现封装了浏览器的常见行为和事件。例如，当需要知道一个页面是否加载完成时，可侦听 LoadingStateChanged 事件。多数 Handler 的方法都提供了异步实现，所有 Handler 都遵循一个实现模式: 返回 bool 的方法意味着询问你是否需要自行处理，返回 false 表示使用默认实现，返回 true 表示由开发人员提供自定义实现。IWebBrowser 定义了以下常见的 IXXXHandler: IDownloadHandler: 下载文件，进度通知，暂停，取消等 IRequestHandler: 处理导航、重定向、资源加载通知等 IDialogHandler: 文件对话框通知 IDisplayHandler: 地址栏变更，状态信息，控制台信息，全屏模式更改通知等 ILoadHandler: 加载状态信息、事件，弹出框通知信息 ILifeSpanHandler: 弹出框弹出及关闭事件 IKeyboardHandler: 键盘事件 IJsDialogHandler: javascript 消息框/弹出框 IDragHandler: 拖拽事件 IContextMenuHandler: 定制右键菜单 IFocusHandler: 焦点相关通知 IResourceHandlerFactory: 拦截资源请求相关 IGeolocationHandler: 地理位置请求相关 IRenderProcessMessageHandler: 从 render 进程发送的自定义 CefSharp 消息相关 IFindHandler: 与查找通知相关 通常，使用定制化的 Handler 需要在创建 ChromiumWebBrowser 之后立即对相应的 Handler 赋值:1browser.DownloadHandler = new DownloadHandler(); 各个 Handler 的具体用法参见 Handlers 配置代理CEF 遵循使用同样的命令行命令来设置代理，如果代理有认证要求，可通过 IRequestHandler.GetAuthCredentials() 方法提供。 请求上下文请求上下文(RequestContext)用于隔离 IBrowser 实例，包括可提供单独的缓存路径、单独的代理配置、单独的 Cookie 管理器及其他相关设置。RequestContext 有以下关键点: 默认情况下，提供一个全局 RequestContext，由多个 IBrowser 实例共享设置 可在运行时通过 Preferences 更改某些设置，这种情况下不要使用命令行工具 Winform 在创建 IBrowser 实例之后立即设置 RequestContext；OffScreen 则须将 RequestContext 作为构造函数参数传入；WPF 则在 InitialComponent() 方法之后设置 Plugin 加载通知通过 IRequestContextHandler 接口处理 设置 RequestContextSettings.CachePath 以持久化 Cookie，localStorage 等数据 高 DPI 显示器支持如果应用程序经常显示为黑屏，则很有可能需要开启「高 DPI」支持。要启用「高 DPI」支持，需要在对应应用程序的 app.manifest 文件中加入相应的节点以通知 Windows 该程序支持「高 DPI」， WinForm: 加入 app.manifest 并在第一时间调用 Cef.EnableHighDPISupport() WPF: 加入 app.manifest OffScreen: 加入 app.manifest app.manifest 类似于以下内容:12345&lt;asmv3:application&gt; &lt;asmv3:windowsSettings xmlns="http://schemas.microsoft.com/SMI/2005/WindowsSettings"&gt; &lt;dpiAware&gt;true/PM&lt;/dpiAware&gt; &lt;/asmv3:windowsSettings&gt;&lt;/asmv3:application&gt; Javascript 集成从 .NET 中调用 Javascript 方法Javascript 方法仅能在一个 V8Context 中执行，IRenderProcessMessageHandler.OnContextCreated 和 IRenderProcessMessageHandler.OnContextReleased 为 Javascript 代码的执行划定了一个清晰的边界。通常: Javascript 在 Frame 级别执行，每个页面至少包含一个 Frame IWebBrowser.ExecuteScriptAsync 方法保留下来用于向后兼容，该方法可作为快速执行 Javascript 方法的入口 OnFrameLoadStart 事件触发时 DOM 还没有加载完成 IRenderProcessMessageHandler.OnContextCreated 和 IRenderProcessMessageHandler.OnContextReleased 仅在主 Frame 上触发。 123456789101112131415161718192021222324252627282930313233browser.RenderProcessMessageHandler = new RenderProcessMessageHandler();public class RenderProcessMessageHandler : IRenderProcessMessageHandler&#123; // Wait for the underlying JavaScript Context to be created. This is only called for the main frame. // If the page has no JavaScript, no context will be created. void IRenderProcessMessageHandler.OnContextCreated(IWebBrowser browserControl, IBrowser browser, IFrame frame) &#123; const string script = "document.addEventListener('DOMContentLoaded', function()&#123; alert('DomLoaded'); &#125;);"; frame.ExecuteJavaScriptAsync(script); &#125;&#125;//Wait for the page to finish loading (all resources will have been loaded, rendering is likely still happening)browser.LoadingStateChanged += (sender, args) =&gt;&#123; //Wait for the Page to finish loading if (args.IsLoading == false) &#123; browser.ExecuteJavaScriptAsync("alert('All Resources Have Loaded');"); &#125;&#125;//Wait for the MainFrame to finish loadingbrowser.FrameLoadEnd += (sender, args) =&gt;&#123; //Wait for the MainFrame to finish loading if(args.Frame.IsMain) &#123; args.Frame.ExecuteJavaScriptAsync("alert('MainFrame finished loading');"); &#125;&#125;; 从 .NET 中调用带有返回结果的 Javascript 方法如果希望调用一个带有返回结果的 Javascript 方法，使用 Task&lt;JavascriptResponse&gt; EvaluateScriptAsync(string script, TimeSpan? timeout)，Javascript 异步执行并最终返回一个 JavascriptResponse 类型的实例，包含错误消息，执行结果和是否成功的标志。1234567891011// Get Document Heightvar task = frame.EvaluateScriptAsync("(function() &#123; var body = document.body, html = document.documentElement; return Math.max( body.scrollHeight, body.offsetHeight, html.clientHeight, html.scrollHeight, html.offsetHeight ); &#125;)();", null);task.ContinueWith(t =&gt;&#123; if (!t.IsFaulted) &#123; var response = t.Result; EvaluateJavaScriptResult = response.Success ? (response.Result ?? "null") : response.Message; &#125;&#125;, TaskScheduler.FromCurrentSynchronizationContext()); 返回结果的类型仅支持基元类型，如 int，bool，string 等，目前还没有一个合适的方法将 Javascript 类型映射为一个 .NET 类型，但可借助 JSON.toStringify() 返回 JSON 字符串的形式来组织复杂类型，之后在 .NET 中利用 JSON.NET 将该字符串反序列化为相应的类型。 将一个 .NET 类型暴露给 JavascriptJavascript 绑定(JSB)实现了 Javascript 和 .NET 之间的通信，目前该方法提供了异步和同步版本的实现 异步 Javascript Binding API 利用 Native Chromium IPC 在 browser 进程和 render 进程之间传递数据，非常快速 仅支持 .NET 方法，属性的 Get/Set 不能以异步模型完成绑定 方法可返回基元类型，结构和复杂类型，这些类型仅属性被传递自 Javascript，可将其看作 DTO 通过 IJavascriptCallback 接口支持 Javascript 回调函数 异步模型返回一个标准的 Javascript Promise CefSharp 提供了 Javascript 对象 CefSharp 以支持 JSB，CefSharp.BindObjectAsync() 方法返回一个 Promise 对象，并在绑定对象可用时解析该对象，绑定的对象在全局上下文(window 对象的属性)创建。 CefSharp.BindObjectAsyncCefSharp.BindObjectAsync(objectName, settings) 绑定对象:123async function bindBridgeObject()&#123; await CefSharp.BindObjectAsync(objectName, settings);&#125; settings 由以下两个属性: NotifyIfAdlreadyBound: 若为 true 则触发 .NET IJavascriptObjectRepository.ObjectBoundInJavascript 事件，默认值 true IgnoreCache: 若为 true，则忽略本地缓存 返回一个 JavaScript Promise 对象。 CefSharp.DeleteBoundObjectCefSharp.DeleteBoundObject(objectName)，删除匹配名称匹配的绑定对象:1CefSharp.DeleteBoundObject("boundAsync"); 返回 true/false CefSharp.RemoveObjectFromCacheCefSharp.RemoveObjectFromCache(objectName)，从缓存中移除匹配名称的绑定对象:1CefSharp.RemoveObjectFromCache("boundAsync"); CefSharp.IsObjectCachedCefSharp.IsObjectCached(objectName) 检查指定名称的对象是否被缓存:1CefSharp.IsObjectCached("boundAsync") === true; 返回 true/false 集成示例 在 .NET 中创建一个将要暴露给 Javascript 的类型: 123456789101112131415public class BoundObject&#123; public class AsyncBoundObject &#123; public void Error() &#123; throw new Exception("This is an exception coming from C#"); &#125; public int Div(int divident, int divisor) &#123; return divident / divisor; &#125; &#125;&#125; 将上述类型的实例注册至 IBrowser.JavascriptObjectRepository: 12345678910111213// set ConcurrentTaskExecution to true if you want do concurrent jobs at one time.CefSharpSettings.ConcurrentTaskExecution = true;browser.JavascriptObjectRepository.ResolveObject += (sender, e) =&gt;&#123; var repo = e.ObjectRepository; if (e.ObjectName == "bridge") &#123; var boundObject = new ServiceBridge(); var bindingOptions = new BindingOptions(); repo.Register("bridge", boundObject, isAsync: true, options: bindingOptions); &#125;&#125;; 在 Javascript 中调用 CefSharp.BindObjectAsync() 方法解析绑定对象: 123456 await CefSharp.BindObjectAsync("boundAsync");boundAsync.div(16, 2).then(function (actualResult)&#123; alert("Calculated value from calling .NET Object: " + actualResult);&#125;); 在 .NET 中接收绑定成功事件:123456browser.JavascriptObjectRepository.ObjectBoundInJavascript += (sender, e) =&gt;&#123; var name = e.ObjectName; Debug.WriteLine($"Object &#123;e.ObjectName&#125; was bound successfully.");&#125;;]]></content>
      <categories>
        <category>Hybrid</category>
      </categories>
      <tags>
        <tag>dotnet</tag>
        <tag>hybrid</tag>
        <tag>chrome</tag>
        <tag>cefsharp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OAuth 2.0 和 OpenID Connect]]></title>
    <url>%2Fsecurity-oauth2-and-openid-connect%2F</url>
    <content type="text"><![CDATA[参考资料: OAuth 2.0 Debugger OpenID Connect Debugger Youtube Video - OAuth 2.0 and OpenID Connect What the Heck is OAuth 本文索引: 前言 OAuth、OIDC 和 IdentityServer4 三者的关系 OAuth 角色定义 OAuth Tokens Access Token Refresh Tokens Authorization Grant OAuth EndPoints 授权通信通道 Front Channel Back Channel OAuth Flows Implicit Flow Authorization Code Flow Client Credential Flow Resource Owner Password Flow Device Flow 安全提醒 OAuth 不是认证协议 Auth 2.0 的伪认证 Open ID Connect 前言工作中经常听到关于 OAuth2 的讨论，但很难用只言片语将这一整套体系解释清楚。本文希望通过查阅资料和开发实践，阐明 OAuth2、OIDC 和 IdentityServer4 三者关于 what、why、和 how 的问题。 OAuth、OIDC 和 IdentityServer4 三者的关系假设有一个这样的需求: 客户端程序需要访问资源服务器的 API，又不希望每次访问都带上用户名密码做一次认证。面对这样的需求，不同的开发人员有自己的考虑，可能的实现多种多样。在经过长期沉淀和提炼之后，先驱们总结出了在不同场景下「委托授权」的最佳实践，然后为这一套最佳实践制定出一套规范 - OAuth。 OAuth 标准化了「委托授权」涉及的各个参与方、数据和 EndPoint，其目的在于为实现者提供一套统一的参考标准。由于时代原因，OAuth 1.0 已经不适合现代 Web 技术的使用场景，所以本文中谈到的 OAuth 均指 OAuth 2.0。OAuth 先于 OIDC 诞生，两者均为规范(Specifications)，OAuth 对应 RFC6749，OIDC 对应 OpenID Connect Core 1.0 incorporating errata set 1，而 IdentityServer4 为 OIDC 在 .NET 平台 官方授权的实现类库。 OAuth 角色定义 Resource Owner: 资源数据的拥有者，绝大多数情况下指用户，例如，我是 Facebook 帐号数据的拥有者 Resource Server: 受保护资源的服务方，通常以 API 形式向外界暴露资源数据，例如，Facebook 的 User Profile 服务 Client: 想要访问 Resource Owner 托管在 Resource Server 数据的第三方应用程序 Public Clients: 暴露在公开的分发渠道中的应用程序，诸如 Web App、Mobile App 和 IoT 设备 Confidential Clients: 受信任的机密应用程序，自存储 secret。它们没有公开暴露在互联网中，无法轻易被反向工程 Authorization Server: 授权服务方，管理 Resource Owner 身份信息和授权列表的服务 一个简单的 OAuth 流程如下所示: OAuth TokensOAuth 规范定义了两种 Token: Aceess Token 和 Refresh Token。 Access TokenAccess Token 是为 Public Client 用于短期(数小时或数分钟)访问受保护资源(Resource Server)的凭证。由于其相对较短的生存期，可以无需为它们设计撤销方案，等待其自动过期即可。 Refresh Tokens当 Resource Owner 撤销某 Client 应用程序的访问权限时，实际是撤销了其 Refresh Token，这意味着当用户再次授权 Client 访问权限时，Client 将使用新的 Refresh Token，是一种强制过期措施。而每一次通过 Refresh Token 获得的都是一枚新的 Access Token。 OAuth 规范中没有对 Token 定义具体内容，它可以是任何格式。由于 JWT 的广泛使用，很容易将这里的 Token 与 JWT 对等起来，在后文的介绍中将区分它们。 Authorization GrantAuthorization Grant 是「授权许可」的泛化名称，表示 Authorization Server 在授权用户之后返回给 Client 的许可载体，Client 可借由该载体进一步向 Authorization Server 换取 Access Token。该载体通常以 code 表示，为一段随机生成的字符串，有效期非常短。 OAuth EndPointsOAuth 规范为 Authorization Server 定义了标准化的 Endpoint 用于不同的场景: /oauth2/authorize: Authorize Endpoint，认证用户并征求用户授权，返回 Authorization Grant /oauth2/token: Token Endpoint，分发 Refresh Token 和 Access Token，当 Access Token 过期后，可利用 Refresh Token 申请新的 Access Token /oauth2/introspect: 用于检视某个 Token 是否仍然有效 /oauth2/revoke: 用于撤销 Refresh Token 关于 OAuth 一个显著的争论是，开发人员不得不管理 Refresh Token。这也是开发人员偏爱 API Keys 的原因，虽然 API Keys 方便很多，但任何客户端都必须保存 API Keys，这加大了安全风险。 授权通信通道OAuth 中将「委托授权」在各个流程中涉及的步骤分成了前后两步: Front Channel 和 Back Channel。 Front ChannelFront Channel 表示发生在开放的互联网中的部分，典型的场景是由「用户代理程序」发起的部分。以浏览器为例，其流程如下: Resource Owner 委托 Client 访问 Resource Server Client 被重定向至 Authorization Server 的 Authorize Endpoint Authorization Server 认证 Resource Owner，展示对话框征求用户授权 Resource Owner 认证通过，并同意授权后，Authorization Server 返回 Authorization Grant 并通过浏览器重定向至 Client 指定的 redirect_uri。 首先来看 Request:1234GET https://accounts.google.com/o/oauth2/auth?scope=gmail.insert gmail.send&amp;redirect_uri=https://app.example.com/oauth2/callback&amp;response_type=code&amp;client_id=812741506391&amp;state=af0ifjsldkj 请求的查询字符串参数中: scope: 表示欲访问资源的预定义资源集，此处为 Gmail 的 API redirect_uri: 指示 Authorization Server 在完成授权后应该重定向的地址，该值必须与 Client 注册时提供的地址一致 response_type: 指示请求的 OAuth Flow client_id: 标识 Client，同样须与 Client 注册时的值一致 state: 用于减轻跨站请求伪造的验证数据 接下来是 Response:123HTTP/1.1 302 FoundLocation: https://app.example.com/oauth2/callback?code=MsCeLvIaQm6bTrgtp7&amp;state=af0ifjsldkj code: 代表 Authorization Grant 的字面值 state: 将 request 中的 state 原封不动的传回，以供 Client 应用程序验证请求来源 Back ChannelFront Channel 的工作完成之后。Back Channel 开始，Client 接收到由 Authorization Server 的重定向请求后，取得 code，接着使用 code、ClientId 及 Client Credential 向 Authorization Server 请求换取 Access Token 及 Refresh Token(可选)。Client 再以 Access Token 访问受保护的资源。 Request 的源数据为:12345POST /oauth2/v3/token HTTP/1.1Host: www.googleapis.comContent-Type: application/x-www-form-urlencodedcode=MsCeLvIaQm6bTrgtp7&amp;client_id=812741506391&amp;client_secret=&#123;client_secret&#125;&amp;redirect_uri=https://app.example.com/oauth2/callback&amp;grant_type=authorization_code grant_type: 授权许可的类型，代表了一种 OAuth Flow，此案例中为 authorization_code，这是典型的 OAuth Flow Response:123456&#123; "access_token": "2YotnFZFEjr1zCsicMWpAA", "token_type": "Bearer", "expires_in": 3600, "refresh_token": "tGzv3JOkF0XG5Qx2TlKWIA"&#125; Response 的 Body 部分为 JSON 格式，描述了 Token 的信息。 值得注意的是，access_token 和 refresh_token 不一定是 Jwt。 OAuth FlowsImplicit FlowImplicit Flow 又称为简化流程，因为没有任何后台服务参与使用 Authorization Grant 换取 Access Token 的流程，整个过程由 Browser 直接与 Authorization Server 通信。 Implicit Flow 常见于 SPA 应用程序，Access Token 由 Authorization Server 直接返回给浏览器，并且不支持 Refresh Token，它假定 Resource Owner 和 Public Client 运行在同一设备上。由于所有流程发生在浏览器，它是最脆弱的一种流程。 Authorization Code Flow简称为 Code Flow，也是 OAuth 推崇的方案，该 Flow 同时采用了 Front Channel 和 Back Channel。它常见于 Web App 的场景。Client 应用程序通过 Front Channel 向 Authorization Server 申请 Authorization Code，再通过 Back Channel 用 Authorization Code 换取 Access Token。它假定 Resource Owner 和 Client 应用程序运行在不同的设备上，Access Token 始终不会传输到「用户代理应用程序」。 Client Credential FlowClient Credential Flow 适用于 server-to-server 的场景。在这种场景中，Client 须是 Confidential Client，利用 Client Credential 作为 Client 的凭证完成授权流程，整个过程全部发生在 Back Channel，可使用对称或非对称加密算法对 Client Credential 进行加密。 Resource Owner Password Flow这是一种过时的流程，已不再推荐使用。这种 Flow 将用户的帐号密码通过「用户代理应用程序」向 Authorization Server 请求 Access Token。通常情况下它不支持 Refresh Token 并假定 Resource Owner 和 Public Client 运行在同一设备。 Device Flow用于类似 TV 等硬件设备，或仅仅运行一个 Cli 的程序，直接与 Authorization Server 通信取得一个 code，再用 code 换取 Access Token 的流程。 安全提醒上述所有这些 Flow 都不同程度地涉及了 OAuth 规范中定义的角色，应该采用哪种 Flow 取决于 Client 的类型，但有以下几点值得注意: 使用 state 参数验证完整性以减轻 CSRF(Cross-Site Request Forgery)) 攻击 启用白名单验证用于重定向的 Url 使用 ClientId 绑定特定的 Client 与指定的 Grant Type 和 Token 类型 确保 Confidential Clients 的 Secret 不会泄露 OAuth 规范的 Token 并不会与终端用户绑定，它可以像 Session Cookie 一样被传递，任何人都能将其拷贝并用在 Authoriazaion Header 中。OAuth 将授权策略与身份认证解耦，它可以实现细粒度与粗粒度授权的融合，并且代替传统 Web App 的访问管理机制。同时，OAuth 对访问受保护资源 API 提供了限制和撤销机制，确保特定 Client 只能可访问受限的 API。 OAuth 不是认证协议OAuth 是一套授权流程的框架并非协议。它关注的重点是如何委托 Authorization Server 进行授权，而不是认证。OAuth 的官方文档没有提到有关用户的操作，所有 Flow 的目的都是为了取得一个可以访问受保护资源 API 的 Access Token。 Auth 2.0 的伪认证Facebook Connect 和 Twitter 最早使用 Access Token 向一个 /me 的 Endpoint 取得用户数据，该 Endpoint 并没有在 OAuth 的规范中定义，这种方式被称为伪认证。 Open ID Connect为了解决伪认证以非规范化的方式被滥用，OAuth 框架的一部分、Facebook Connect 以及 SAML2.0 被合并为 OpenID Connect(OIDC)，OIDC 在 OAuth 2.0 基础上扩展了一个经过签名的 ID Token，以及一个 UserInfo Endpoint 用于获取用户数据。OIDC 还标准化了针对身份信息的 scope 和 claim，例如 profile、email、address 和 phone。除此之外，OIDC 将注册、发现等功能作为组件纳入规范之中。与 OAuth 的 Request 相比，其 scope 可接受新的值，如 openid 和 email:123456GET https://accounts.google.com/o/oauth2/auth?**scope=openid email**&amp;redirect_uri=https://app.example.com/oauth2/callback&amp;response_type=code&amp;client_id=812741506391&amp;state=af0ifjsldkj 以及在 Authorization Grant 向 Authorization Server 换取 Token 后的 Response 中新增了 ID Token:1234567&#123; "access_token": "2YotnFZFEjr1zCsicMWpAA", "token_type": "Bearer", "expires_in": 3600, "refresh_token": "tGzv3JOkF0XG5Qx2TlKWIA", **"id_token": "eyJhbGciOiJSUzI1NiIsImtpZCI6IjFlOWdkazcifQ..."**&#125; ID Token 是一个 JWT(JSON Wbe Token)，JWT 非常小巧，易于传输，由 3 部分组成: header: 包含签名所使用的算法 body: 包含代表用户身份信息的 claim signature: 用于完整性验证的签名信息 OIDC Flow 涉及以下步骤: 发现 OIDC 元数据 发起一种 OAuth Flow 来取得 ID Token 和 Access Token 取得用于 JWT 签名的 Key 并动态注册 Client 应用程序(可选) Client 基于 JWT 的日期与签名离线验证 ID Token 利用 Access Token 按需获取用户数据]]></content>
      <categories>
        <category>Cryptography</category>
      </categories>
      <tags>
        <tag>security</tag>
        <tag>oauth</tag>
        <tag>jwt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[向 Let's Encrypt CA 申请通配符证书]]></title>
    <url>%2Fsecurity-cert-wildcard-from-letsencrypt%2F</url>
    <content type="text"><![CDATA[本文索引: 前言 申请通配符证书 更新通配符证书 自动更新通配符证书 使用 acme.sh 替代 certbot ACME 客户端(TBD) 前言近期，Let&#39;s Encrypt 开放了通配符数字证书申请。通配符数字证书实现了单个证书绑定多个子域名。为了实现通配符证书，Let’s Encrypt 对 ACME 协议的实现进行了升级，只有 v2 协议才支持通配符证书。用户可自行查看客户代理软件是否支持 ACME v2 版本。官方主推的 Certbot 也需要升级到 0.22.0 版本之后才支持通配符证书。 通配符证书目前仅支持 dns-01 方式的 Challenge: dns-01: 申请人被要求将一串随机字符串以 TXT 记录添加至目标域名。 不同的 DNS 提供商可能提供了对应的「插件」，可能需要单独安装，certbot 第三方 DNS 插件可在此页面查看。如果你注册的域名提供商(例如阿里云)没有提供官方的 DNS 插件，那么只能手动完成验证。 申请通配符证书以下以 *.frosthe.net 为例，使用 manual 插件回应 Challenge。1$ certbot certonly -d *.frosthe.net --manual --preferred-chanllenge dns --server https://acme-v02.api.letsencrypt.org/directory 该命令表明: 仅为 *.frosthe.net 获取通配符证书，无需安装 使用 manual 插件 使用 dns 方式回应 Challenge 告知 certbot 采用 Let&#39;s Encrypt ACME v2 协议的 API 服务器 接下来，命令行显示窗会询问申请人当前主机的 ip 地址将被记录，是否接收，输入 y:12345678- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -NOTE: The IP of this machine will be publicly logged as having requested thiscertificate. If you&apos;re running certbot in manual mode on a machine that is notyour server, please ensure you&apos;re okay with that.Are you OK with your IP being logged?- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -(Y)es/(N)o: y 下一步 certbot 将要求申请人手动添加一条 TXT 的解析:123456789- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -Please deploy a DNS TXT record under the name_acme-challenge.frosthe.net with the following value:h9MFbboNRKqN4_8iDlu4dpIBd9UrXKqRrmP62ZHGhJ8Before continuing, verify the record is deployed.- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -Press Enter to Continue 现在，登录 frosthe.net 域名注册商的后台管理界面，按照上述要求添加一条如下图的解析记录:确认无误后，回车，得到如下信息:12345678910111213IMPORTANT NOTES: - Congratulations! Your certificate and chain have been saved at: /etc/letsencrypt/live/frosthe.net/fullchain.pem Your key file has been saved at: /etc/letsencrypt/live/frosthe.net/privkey.pem Your cert will expire on 2019-03-30. To obtain a new or tweaked version of this certificate in the future, simply run certbot again. To non-interactively renew *all* of your certificates, run "certbot renew" - If you like Certbot, please consider supporting our work by: Donating to ISRG / Let's Encrypt: https://letsencrypt.org/donate Donating to EFF: https://eff.org/donate-le 操作完成，可至对应的目录获取证书以作用后。 更新通配符证书certbot renew 试图加载当前管理的所有证书的配置信息更新证书，certbot renew 更新阿里云托管的域名还存在一些问题没有解决。目前更新证书使用同样的 certbot certonly 子命令完成，必须手动完成 challenge:12345678910111213141516171819202122232425262728293031323334353637383940414243$ certbot certonly -d *.frosthe.net --manual --preferred-challenge dns --server https://acme-v02.api.letsencrypt.org/directorySaving debug log to /var/log/letsencrypt/letsencrypt.logPlugins selected: Authenticator manual, Installer NoneCert is due for renewal, auto-renewing...Renewing an existing certificatePerforming the following challenges:dns-01 challenge for frosthe.net- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -NOTE: The IP of this machine will be publicly logged as having requested thiscertificate. If you're running certbot in manual mode on a machine that is notyour server, please ensure you're okay with that.Are you OK with your IP being logged?- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -(Y)es/(N)o: y- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -Please deploy a DNS TXT record under the name_acme-challenge.frosthe.net with the following value:dhlr5daZbfwlgkjTSVHTPQXY2bWEr3VuBUHKegAofj4Before continuing, verify the record is deployed.- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -Press Enter to ContinueWaiting for verification...Cleaning up challengesIMPORTANT NOTES: - Congratulations! Your certificate and chain have been saved at: /etc/letsencrypt/live/frosthe.net/fullchain.pem Your key file has been saved at: /etc/letsencrypt/live/frosthe.net/privkey.pem Your cert will expire on 2019-06-29. To obtain a new or tweaked version of this certificate in the future, simply run certbot again. To non-interactively renew *all* of your certificates, run "certbot renew" - If you like Certbot, please consider supporting our work by: Donating to ISRG / Let's Encrypt: https://letsencrypt.org/donate Donating to EFF: https://eff.org/donate-le 自动更新通配符证书由于通配符证书仅支持 dns 方式的验证，而这种方式要求申请人在其域名管理后台添加新的 TXT 记录，除了某些官方列出的域名提供商以外，其他域名托管商(例如阿里云)的申请人需要外挂脚本来自动化这一过程，参考 Pre and Post Validation Hooks。 使用 acme.sh 替代 certbot ACME 客户端(TBD)]]></content>
      <categories>
        <category>Cryptography</category>
      </categories>
      <tags>
        <tag>security</tag>
        <tag>https</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[向 Let's Encrypt CA 申请单域名证书]]></title>
    <url>%2Fsecurity-cert-from-letsencrypt%2F</url>
    <content type="text"><![CDATA[参考资料: How its works - Let’s Encrypt Getting certificates(and choosing plugins) 本文索引: 前言 使用 Certbot 管理 Let’s Encrypt 颁发的数字证书 安装 Certbot 获取证书 安装证书 自动更新证书 删除证书 前言基于上一篇文章的介绍，本篇将介绍使用官方推荐的 ACME 客户代理软件Certbot 为 www.frosthe.net 申请 HTTPS 证书。 使用 Certbot 管理 Let’s Encrypt 颁发的数字证书certbot 在各个 *NIX 系统的发行版本都提供了对应的版本，以下以 Ubuntu 16.04 LTS 为例，为 www.frosthe.net 申请单域名证书。 在不支持通配符证书之前，Let&#39;s Encrypt 支持两种证书: 单域名证书: 证书仅包含一个域名 SAN 证书: 证书可包含多个域名(Let&#39;s Encrypt 限制为 20)，例如，一个证书可覆盖 www.example.com、www.example.cn、auth.example.com 等。 本文仅介绍单域名证书的申请。 安装 Certbot按照官方文档给出的 Ubuntu 16.04 LTS 系统的指引，执行以下命令:12345$ sudo apt-get update$ sudo apt-get install software-properties-common$ sudo add-apt-repository ppa:certbot/certbot$ sudo apt-get update$ sudo apt-get install certbot 获取证书certbot 支持一系列「插件」，这些插件主要服务于两种用途: 确认用户对域名的管理权限 dns 插件: 要求用户添加给定 DNS 记录来确认域名管理权 webroot 插件: 要求用户在站点根目录下新增给定资源来确认域名管理权 manual 插件: 手动插件，意即，需要手动操作以完成 challenge 将证书自动安装至指定 Web 服务器: Apache 插件: Nginx 插件: Haproxy 插件: Plesk 插件: 如果使用 certbot certonly 子命令，将以「交互模式」来选择需要使用哪种「插件」来获取证书，该模式有助于理解证书申请过程，但不便于自动化，以下以 certbot certonly 命令及 webroot 插件为 www.frosthe.net 申请数字证书:1234567891011121314151617$ sudo certbot certonlyHow would you like to authenticate with the ACME CA?- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -1: Spin up a temporary webserver (standalone)2: Place files in webroot directory (webroot)- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -Select the appropriate number [1-2] then [enter] (press &apos;c&apos; to cancel): 2Plugins selected: Authenticator webroot, Installer NoneStarting new HTTPS connection (1): acme-v02.api.letsencrypt.orgPlease enter in your domain name(s) (comma and/or space separated) (Enter &apos;c&apos;to cancel): www.frosthe.netObtaining a new certificatePerforming the following challenges:http-01 challenge for www.frosthe.netInput the webroot for www.frosthe.net: (Enter &apos;c&apos; to cancel): 到这里申请人收到 Let’s Encrypt 的挑战，要求申请人指定 www.frosthe.net 域名的 webroot，在进行下一步之前，需要完成以下两件事: 在 frosthe.net 的域名提供商控制台添加一条 DNS 记录将 www 记录值指向当前 Web Server 的 IP 地址。 配置 Web Server 使其能够响应 http 请求，这里我使用了 nginx:1234567server &#123; listen 80; listen [::]:80; server_name www.frosthe.net; root /var/www/html; index index.html;&#125; 需要指出的是，选用 webroot 插件必须保证主机的 80 端口是可访问的，因为 certbot 没有提供选项指定目标主机的端口号 接下来，回到刚才的 certbot 流程当中:123456789101112131415161718Please enter in your domain name(s) (comma and/or space separated) (Enter 'c'to cancel): www.frosthe.netObtaining a new certificatePerforming the following challenges:http-01 challenge for www.frosthe.netInput the webroot for www.frosthe.net: (Enter 'c' to cancel): /var/www/htmlWaiting for verification...Cleaning up challengesIMPORTANT NOTES: - Congratulations! Your certificate and chain have been saved at: /etc/letsencrypt/live/www.frosthe.net/fullchain.pem Your key file has been saved at: /etc/letsencrypt/live/www.frosthe.net/privkey.pem Your cert will expire on 2018-12-17. To obtain a new or tweaked version of this certificate in the future, simply run certbot again. To non-interactively renew *all* of your certificates, run "certbot renew" 执行 sudo certbot certificates 可以看到 www.frosthe.net 域名的证书已经申请成功:123456789$ sudo certbot certificates- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -Found the following certs: Certificate Name: www.frosthe.net Domains: www.frosthe.net Expiry Date: 2018-12-17 11:52:22+00:00 (VALID: 89 days) Certificate Path: /etc/letsencrypt/live/www.frosthe.net/fullchain.pem Private Key Path: /etc/letsencrypt/live/www.frosthe.net/privkey.pem- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 为了便于理解，上述过程为全手动操作的「交互模式」，可用选项指定这些值:1$ certbot certonly -d www.frosthe.net --webroot 安装证书成功获取证书之后，还没有任何地方使用它，在浏览器中尝试访问 https://www.frosthe.net 将会报错。certbot 同样提供了一系列「插件」以支持在成功获得证书之后自动安装到对应的 Web Server 配置，例如，nginx 插件，现在手动安装证书，编辑 nginx 的配置文件:12345678910111213server &#123; listen 80; listen [::]:80; server_name www.frosthe.net; root /var/www/html; index index.html; listen 443 ssl; listen [::]:443 ssl; ssl_certificate /etc/letsencrypt/live/www.frosthe.net/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/www.frosthe.net/privkey.pem;&#125; 再次尝试在浏览器中访问 https://www.frosthe.net，如预期一般显示了页面，查看该站点的证书文件，得到以下信息: 上述过程可由 certbot 的 nginx 插件自动安装，目前 certbot 通过在 webroot 下放置文件来自动验证域名拥有者:1$ sudo certbot -d www.frosthe.net --authenticator webroot --installer nginx 插件与 certbot 是分离的 package，在使用指定的插件以前，必须先通过 apt-get install 来安装相应的插件，具体可参考这里 自动更新证书由 Let&#39;s Encrypt 颁发的数字证书有效期仅为 90 天，原因可参考这里。过期之后 HTTPS 将失效。certbot 提供了 renew 子命令以更新证书有效期，可首先使用 sudo certbot --dry-run 进行测试:12345678910111213141516171819202122232425262728$ sudo certbot renew --dry-run- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -Processing /etc/letsencrypt/renewal/www.frosthe.net.conf- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -Cert not due for renewal, but simulating renewal for dry runPlugins selected: Authenticator webroot, Installer NoneStarting new HTTPS connection (1): acme-staging-v02.api.letsencrypt.orgRenewing an existing certificatePerforming the following challenges:http-01 challenge for www.frosthe.netWaiting for verification...Cleaning up challenges- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -new certificate deployed without reload, fullchain is/etc/letsencrypt/live/www.frosthe.net/fullchain.pem- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -** DRY RUN: simulating 'certbot renew' close to cert expiry** (The test certificates below have not been saved.)Congratulations, all renewals succeeded. The following certs have been renewed: /etc/letsencrypt/live/www.frosthe.net/fullchain.pem (success)** DRY RUN: simulating 'certbot renew' close to cert expiry** (The test certificates above have not been saved.)- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 最后，可将该命令以一条 crontab 的方式加入任务管理器，以定期执行更新，注意，如果 certbot 是以 root 用户安装的，则需要首先切换到 root。1234$ (sudo) su -$ crontab -e0 5 * * 1 certbot renew 删除证书执行 certbot delete 来执行删除证书的功能，该命令将列出已安装的证书，按提示选择目标证书:12345678910111213$ (sudo) certbot deleteSaving debug log to /var/log/letsencrypt/letsencrypt.logWhich certificate would you like to delete?-------------------------------------------------------------------------------1: www.frosthe.net-------------------------------------------------------------------------------Press 1 [enter] to confirm the selection (press 'c' to cancel): 1-------------------------------------------------------------------------------Deleted all files relating to certificate www.frosthe.net.------------------------------------------------------------------------------- 执行 certbot delete --cert-name www.frosthe.net 以快速删除证书:1$ (sudo) certbot delete --cert-name www.frosthe.net]]></content>
      <categories>
        <category>Cryptography</category>
      </categories>
      <tags>
        <tag>security</tag>
        <tag>https</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Let's Encrypt 证书颁发机构]]></title>
    <url>%2Fsecurity-how-letsencrypt-works%2F</url>
    <content type="text"><![CDATA[参考资料: How its works - Let’s Encrypt 本文索引: 背景 证书申请流程 域名认证 证书管理 证书申请 证书废止 背景某网站主体拥有 www.example.com 域名的管理权限，为了让该网站启用 HTTPS，网站主体必须首先从「证书颁发机构(CA, Certificate Authority)」获得「数字证书」。传统的 HTTPS 证书完全由人工审核，且大多数 CA 都是收费的。 Let’s Encrypt 是一个免费签发 HTTPS 证书的非盈利 CA，其目标是推动 HTTPS 协议的普及，并通过其自定的 ACME(Automatic Certificate Management Environment) 协议让申请证书的流程完全自动化。 证书申请流程以 www.example.com 为例，申请 HTTPS 证书，通常覆盖以下两个步骤： 域名认证: 网站主体必须向 CA 证明其对 www.example.com 拥有管理权。 证书管理: 网站主体向 CA 申请、更新或撤销 www.example.com 的 HTTPS 证书。 域名认证在传统 CA 签发流程中，用户首先注册帐户，然后向帐户中添加宣称拥有管理权的域名。在 Let&#39;s Encrypt 签发证书的流程中，申请人使用一个实现了 ACME 协议的客户代理软件(官方推荐为 Certbot)与 Let&#39;s Encrypt CA(下文中的 CA 均代指 Let&#39;s Encrypt) 通信: 申请人客户代理软件首先向 CA 传递自己的「公钥」以供 CA 唯一标识申请人，然后询问 CA 如何向其证明对 www.example.com 域名的管理权 CA 向申请人提出若干种 Challenge 选项，这些 Challenge 通过其实现方式要求申请人证明对 www.example.com 的管理权，例如: 请向 www.example.com 添加一条给定随机值的 DNS 记录，或 请在 https://www.example.com/ 下添加一条给定随机值的资源文件 同时，CA 会向申请人提供一条 nonce 并要求申请人使用其「私钥」进行签名，以证明申请人确实是「密钥对」的持有方，下图展示了展示了这个过程: 申请人可按需选择上述任何一种 Challenge 并以其「私钥」对 nonce 进行签名后，告知 CA 以等待验证，下图展示了这个过程 如果签名及 Challenge 均验证通过，CA 将认可申请人对 www.example.com 域名拥有管理权，并关联该「密钥对」为 www.example.com 域名的已授权「密钥对」。 证书管理一旦申请人提供的「密钥对」得到 CA 的授权，就意味着申请人获得了为 www.example.com 管理证书的权限。包括申请，更新和撤销证书。实现这些操作均通过签名「证书管理消息」来完成。 证书申请要为 www.example.com 申请证书，客户代理软件构造一条 PKCS#10 的 CSR(Certificate Signing Request) 请求，该 CSR 请求 CA 为 www.example.com 域名颁发数字证书并将一个给定的「公钥」与该证书关联。CSR 中同时会包含一条使用对应「私钥」签名的消息。并且客户代理软件将整个 CSR 消息以前文所述的「授权密钥对」中的「私钥」进行签名。 上述中提及的「授权密钥对」和 CSR 中关联的「公钥」可能分属于两份「密钥对」 这样，CA 同时接收到 CSR 以及整段 CSR 签名后的消息。CA 用「授权密钥对」中的「公钥」验证该签名，如果验证通过，CA 将 www.example.com 域名与 CSR 中提供的「公钥」关联，并颁发证书，最后返回给客户代理软件。 证书废止证书的废止过程与申请类似，客户代理软件向 CA 发送一条 CRR(Certificate Revocation Request) 消息。过程与 CSR 类似，可参考下图:CA 完成验证之后，发布证书废止信息至 OCSP，以通知「证书检验方」(如浏览器)该证书已撤销。]]></content>
      <categories>
        <category>Cryptography</category>
      </categories>
      <tags>
        <tag>security</tag>
        <tag>cryptography</tag>
        <tag>https</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[X.509 数字证书]]></title>
    <url>%2Fsecurity-all-about-certificates%2F</url>
    <content type="text"><![CDATA[数字证书标准 - X.509X.509 是一种定义「公钥证书」格式的标准，X.509 证书包含一个「公钥」和一个主体标识(主机名称，机构或个人)，由 CA(Certificate Authority) 签名或自签名，一旦证书由受信任的 CA 签名或其他方法进行了验证，持有该证书的机构即可信任其包含的「公钥」，进而与另一方建立安全通信，或验证由其对应的私钥签名的文档。 除了证书本身功能，X.509 还附带了证书吊销列表和用于从最终对证书进行签名的证书签发机构直到最终可信点为止的证书合法性验证算法 数字证书载体数字证书又称为公开密钥证书(Public key certificate)，用来证明公开密钥拥有者的身份。该文件包含了: 公钥信息 拥有者的身份信息(Subject) 数字证书认证机构(Issuer)对这份文件的数字签名 「证书持有方」凭借此文件，可向计算机系统或其他用户表明身份，「证书检验方」通过查看其「签发机构」来检验该证书是否有效，如果检验方信任该签发机构，就代表信任证书上的密钥，双方便可凭借公钥加密进行安全的通信。 数字证书编码格式X.509 证书目前有以下两种编码格式: PEM - Privacy Enhanced Mail，以”—–BEGIN…”开头，”—–END…” 结尾，内容以 BASE64 编码。Apache 和 *NIX 服务器偏向于使用这种编码格式。 DER - Distinguished Encoding Rules，二进制格式，不可读。Java 和 Windows 服务器偏向于使用这种编码格式。 扩展名除了 .pem 及 .der 之外，不同的系统或程序对数字证书文件载体定义了自己的扩展名，它们除了格式不同之外，内容也有差别，但大多数都能相互转换: .crt: 多见于 *NIX 系统 PEM 编码 .cer: 多见于 Windows 系统 DER 编码 .key: 通常用于存放单个 key，非证书，可能是 PEM 编码或 DER 编码。 .csr: Certificate Signing Request，即证书签名请求，并非证书，而是向 CA 发出的证书申领请求，其核心内容包含一个「公钥」及其他主体信息，在生成该请求时，也会生成相应的「私钥」。 .pfx/p12: Predecessor of PKCS#12，对 *NIX 服务器来说,一般 .crt 和 .key 是分开存放在不同文件中，但 Windows 的 IIS 则将它们存在一个 .pfx 文件中(该文件包含了证书及私钥)，.pfx 通常会设置一个「提取密码」，.pfx 使用 DER 编码。 .jks: Java Key Storage，这是 Java 的专利，跟 OpenSSL 关系不大，Java 提供了一个 keytool 工具可以将 .pfx 转换为 .jks。 编码的转换以 PEM 和 DER 编码的 「X.509 证书」，「Key」 以及「CSR」 都可以通过 OpenSSL 进行互转，例如:12345678# 将 X.509 证书由 PEM 转换为 DER 编码格式$ openssl x509 -in cert.crt -outform der -out cert.der# 将 X.509 证书由 DER 转换为 PEM 编码格式$ openssl x509 -in cert.crt -inform der -outform pem -out cert.pem# 将 RSA 公钥由 PEM 转换为 DER 编码格式$ openssl rsa -in pubkey.pem -outform der -out pubkey.der# 将 CSR 由 PEM 转换为 DER 编码格式$ openssl req -in request.csr -outform der -out request-der.csr Web HTTPS 的工作原理Web HTTPS 是典型的使用数字证书建立安全通信的应用场景，在此场景中，Web 服务器是「证书持有方」，浏览器是「证书检验方」，对 Web 服务器签发证书的机构为「签发机构」，双方在建立安全的通信连接前，首先要进行以下通信，以求互相信任，证书以文件的形式存储在服务器端。 Client 向 Server 发起 TLS 握手消息 Client Hello，包含期望的 TLS 协议版本，Cipher Suite 列表和一个 client random 的字符串 Server 回应 Client 一条 Server Hello 的消息，包括 SSL 证书，选定的 Cipher Suite 和一个 server random 的字符串，该证书包含 Web 服务器的「公钥」。 Client 将 Server 的证书与本地受信 CA 列表确认，检查其是否有效(包括是否过期，是否被撤销，是否与域名匹配) 如果检查结果有效，Client 从证书中提取 Server 的「公钥」，生成一个临时的「对称密钥」，再使用「公钥」加密「对称密钥」，随后将「密文」发送给 Server。 Server 收到「密文」并用其「私钥」解密得到「对称密钥」，之后，便使用「对称密钥」对返回值进行加密 随后，Client 和 Server 全程使用临时「对称密钥」进行通信 使用 Chrome 访问 https://www.google.com，点击地址栏左侧的「绿色锁」按钮，再点击「证书」按钮，便可查看 www.google.com 所使用的数字证书，其中包括 Version, Issuer, Valid From, Valid To, Subject, Publick Key 等细节:]]></content>
      <categories>
        <category>Cryptography</category>
      </categories>
      <tags>
        <tag>security</tag>
        <tag>cryptography</tag>
        <tag>ssl-certificate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[加解密笔记及 .NET 实现]]></title>
    <url>%2Fsecurity-encryption%2F</url>
    <content type="text"><![CDATA[参考资料: RFC3602 规范 Security Best Practices: Symmetric Encryption with AES in Java and Android Cryptographic Services 加密的意义加密技术首要考虑的关注点在于: 保密: 确保通信的数据不能被第三方读取 数据完整: 确保数据在通信过程中不能被第三方纂改 认证: 验证数据来源，防止第三方伪造数据 密码学基础概念 对称加密: 加解密双方使用同一个密钥对消息进行加解密， 非对称加密 密文哈希: 哈希算法将一组任意大小的二进制数据变成一组固定大小的二进制数据，且无法实施逆向工程 消息认证码: 消息认证码 Message Authentication Code(Mac) 是提供给消息接收方以验证消息来源及确保消息完整性的额外信息 数字签名 AES(Advanced Encryption Standard) CBC(Cipher Block Chaining)原理: 加解密双方使用同一个密钥(secret key)加解密信息，CBC 将明文按固定字节大小切割，得到的每一块称为一个 Block，每个 Block 将前一个密文 Block 与当前 Block 进行 XOR 运算。这样，每一个 Block 都依赖前序所有的 Block。而第一个 Block 使用一个相同长度的随机生成的 Block(初始化向量 IV(Initialization Vector))进行 XOR 运算。鉴于被加密消息不一定能够被切割为 Block 长度的整数倍，于是引入「补齐 Padding」算法在尾部进行填充，具体来说，其加密经历以下过程: plainText 被分割为 length / block-size 个 block，如果最后一个 block 不足 block-size，使用 Padding 补齐 随机生成一个 IV 与首个 block 进行 XOR 运算得到 cipherText 上一个 cipherText 与下一个 plainText 进行 XOR 运算得到 cipherText 通常每份明文加密前都会随机生成 IV，以防止多次加密后得到相同的结果 AES 支持 128 位，192 位及 256 位大小的密文块 因为 IV 的长度总是与 Block 的长度相同，在传输或持久化数据时，常见的做法是将 IV 直接作为前缀 Prepend 到密文前面 在过程中 Key 的长度与 Block 的长度没有直接关系，只会影响循环加密的次数，128 位的密钥有 10 个加密循环，192 位密钥有 12 个加密循环，256 位密钥有 14 个加密循环 具体参考 RFC3602 规范 .NET 提供了以下类型实现对称加密算法: AesManaged (.NET Framework 3.5 时引入) DESCryptoServiceProvider HMACSHA1 (This is technically a secret-key algorithm because it represents message authentication code that is calculated by using a cryptographic hash function combined with a secret key) RC2CryptoServiceProvider RijndaelManaged TripleDESCryptoServiceProvider 消息认证码(MAC, Message Authentication Code)对称加密本身并不能验证加密数据的完整性，第三方可能拦截加密的密文然后替换掉其中某些字节发送给接收方。数据加密完成之后，基于密文使用 MAC 算法得到一个 MAC 值，然后将该值以合适的方式附加到密文上。常用的 MAC 算法有 HMAC(Hash-based Message Authentication Code)。 MAC 的作用与数字签名类似，唯一的区别在于加密方和解密方使用相同的 Key，虽然确保了数据完整性，但也意味着消息将被处理两次，同样的，接收方在收到数据后也将处理两次。 公钥加密(Public-key Encryption)Public/Private 密钥对加密双方使用一个非对称密钥对 - 公钥和私钥，数据由公钥加密后只能由私钥解密，而数据由私钥签名的则只能由公钥验证，公钥可以是公开的，但私钥必须保密。 现假设 A 和 B 想要通信，A 负责生成密钥对，那么 A 将其公钥发送给 B，B 使用公钥对通信信息加密，后将密文发送给 A，A 用其私钥解密密文。在此情景中，如果 A 将公钥发送给 B 时被攻击者拦截，同时攻击者将后续的密文一并拦截，但持有公钥和密文是无法解密信息的。另外，B 在收到公钥后，如何验证收到的的确是 A 的私钥？A 将一段消息使用某种哈希算法得到签名，再将签名使用私钥加密，B 接到签名信息和消息后，使用公钥解密密文得到签名信息，再使用相同的哈希算法处理收到的消息，B 通过对比两个签名的哈希值来判断消息是否被篡改。 信息流向始终是 B 流向 A，如果 A 想要向 B 发送消息，必须使用相同的方法得到 B 的公钥。所以，通常使用非对称加密传输对称加密的密钥和 IV，通信的双方使用对称加密对信息加密。 .NET 提供了以下类型实现公钥加密算法: DSACryptoServiceProvider RSACryptoServiceProvider ECDiffieHellman (基类) ECDiffieHellmanCng ECDiffieHellmanCngPublicKey (基类) ECDiffieHellmanKeyDerivationFunction (基类) ECDsaCng 数字签名数字签名用于验证发送方的身份，对称加密也提供支持数字签名。首先，A 使用某种哈希算法处理一条消息得到字面为哈希值的「消息摘要」，然后 A 使用私钥将消息摘要加密，密文的字面值则称为「数字签名」。B 收到消息和数字签名后，使用 A 的公钥解密该数字签名得到「消息摘要」，然后使用相同的哈希算法对收到的消息进行处理，如果得到的哈希值与解密后的「消息摘要」一致，那么 B 便可以认为该消息的确来源于 A 且未被篡改。 要验证数据被某个发送方签名，接收需要得知以下信息: 发送方的公钥 数字签名(消息载体经过哈希处理后被发送方以私钥进行加密之后的密文) 被签名的数据(哈希处理之前的消息载体) 发送方使用的哈希算法 .NET 提供了以下类型实现数字签名算法: DSACryptoServiceProvider RSACryptoServiceProvider ECDsa (基类) ECDsaCng 哈希值哈希算法将一组任意大小的二进制数据变成一组固定大小的二进制数据，且无法实施逆向工程。哈希值是数据的数字化形式。通信的双方可以利用哈希值确保数据完整性，A 将消息和消息的哈希值一起发送给 B，B 收到消息后使用相同的哈希算法得到消息的哈希值，然后与收到的消息进行比对，如果比对无误，则可确保消息未被更改。然后，任何第三方都可以给 B 发送消息和消息哈希值，B 无法简单通过哈希值知道发送方的身份。通常，数字签名和哈希一起使用。 .NET 提供了以下类型实现哈希算法: HMACSHA1 MACTripleDES MD5CryptoServiceProvider RIPEMD160 SHA1Managed SHA256Managed SHA384Managed SHA512Managed 数字证书数字证书又称为公开密钥证书(Public key certificate)，用来证明公开密钥拥有者的身份。该文件包含了: 公钥信息 拥有者的身份信息(Subject) 数字证书认证机构(Issuer)对这份文件的数字签名 拥有者凭借此文件，可向计算机系统或其他用户表明身份，证书的检验方通过查看其签发机构来检验该证书是否有效，如果检验方信任该签发机构，就代表信任证书上的密钥，凭借公钥加密与拥有者进行安全的通信。数字证书详情参考X.509 数字证书 生成随机数随机数生成与加密的多个操作都有关，加密密钥需要尽可能的随机，.NET 提供了 RNGCryptoServiceProvider 类型来实现随机数生成。]]></content>
      <categories>
        <category>Cryptography</category>
      </categories>
      <tags>
        <tag>security</tag>
        <tag>cryptography</tag>
        <tag>netframework</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在树莓派上通过 Docker 搭建 Seafile 私有云服务]]></title>
    <url>%2Fhomeserver-setup-seafile-on-raspberry-pi%2F</url>
    <content type="text"><![CDATA[参考资料: Deploying Seafile with MySQL Config Seahub with Nginx Enabling Https with Nginx Start Seafile at System Bootup 本文索引: 背景 Seafile 简介 数据模型 Seafile 组成 使用 Docker 搭建 Seafile 服务 设置开机启动 Seafile 使用各平台客户端 迁移数据 背景手机和 Mac 里存的照片和视频越来越多，而 iCloud 的免费存储空间只有 5GB，更重要的是，国行 iCloud 上了云上贵州。于是萌生了在家里搭建私有云盘的想法。搭建私有云主要解决了以下几个问题: 突破 iCloud，百度网盘等的容量限制，自己想买多大的硬盘都可以 将个人数据隐私与任何第三方隔离，不用担心数据被第三方 Spy 提升上传下载的速度，如果用过百度网盘，都懂的。 seafile 是目前发现的口碑最好的开源私有云项目，完备的官网文档和配套的各平台的客户端，决定一试。 Seafile 简介seafile 由以下组件组成: ccnet 守护进程: ccnet 客户端和 ccnet 服务端，网络服务进程，客户端与服务端数据通信的通道 seafile 守护进程: 数据服务守护进程 seahub: Web UI 服务器，seafile 服务器包含了一个轻量的 Python Http 服务器 gunicorn。seahub 以 gunicorn 应用程序运行。 FileServer: 由于 gunicorn 处理大文件非常吃力，FileServer 用于处理 Seahub 源文件上传与下载的功能。 Controller: 监控 ccnet 与 seafile 守护进程，在适当的时候重启它们。 下图展示了 seafile 桌面客户端与服务端同步文件的过程: 下图展示了移动客户端与服务端同步文件的过程: 数据模型seafile 内部使用一种类似于 git 的数据模型，由 Repo，Branch，Commit，FS 和 Block 组成。 Repo: 也被称作 Library，每个 repo 都包含一个 uuid，以及诸如「描述」，「创建者」和「密码」等特性 Branch: 与 git 不同，只有两种预定义的 branch: local 和 master。在浏览器中，针对 Repo 的改动会推送到服务端的临时分支，然后合并至 master 分支。在 PC 客户端，针对 Repo 的改动会: 首先提交到 local 分支 master 分支从服务端下载，合并至 local 分支 local 分支上传至服务端 服务端 master 分支以 fast-forward 合并至 local 分支。 Commit: 与 Git 一致 FS: 有两种类型的 FS 对象: SeafDir Object 和 Seafile Object。SeafDir Object 代表一个目录，Seafile Object 代表一个文件。 Block: 一个文件被分割至数个不定长度的 Block 中，系统使用 Content Defined Chunking 算法将文件切分至 Block。平均来说，一个 Block 大小约为 1MB。 Seafile 组成依赖于 SQLite 或 Mysql 数据库，Ccnet，Seafile 和 Seahub 均需要单独的数据库。 使用 Docker 搭建 Seafile 服务seafile docker 针对 x86 和 amd64 架构都推出了官方的 Docker Image，网友从官方 Repo 分叉了 arm 架构的 Docker Image Repo，确保 Docker 引擎安装好之后，执行以下命令:12345678docker run -d --name seafile \-e SEAFILE_SERVER_HOSTNAME=&#123;your-domain-name&#125; \-e SEAFILE_ADMIN_EMAIL=&#123;your-admin-email&#125; \-e SEAFILE_ADMIN_PASSWORD=&#123;your-admin-password&#125; \-v /mnt/sda1/seafile:/shared \-p 8000:80 \-p 8443:443 \seafileltd/seafile:pi --name 的值可自行修改，它会作为 container 的别名，-v 代表映射的本地目录，此例为 /mnt/sda1/seafile，包括所有配置信息和数据，最好指定一个大容量硬盘的挂载目录。SEAFILE_SERVER_HOSTNAME 的值将直接应用到系统设置的 URL 两个参数中，如下图: SERVICE_URL: Internet 上 Seahub 的基础地址，如果是非 80，443 等默认端口号，则需要带上，例如此处的 https://cloud.frosthe.net:8443 FILE_SERVER_ROOT: 文件服务器根地址，用于向客户端提供上传和下载文件的地址，通常为 {SERVICE_URL}/seafhttp，端口问题同上，https://cloud.frosthe.net:8443/seafhttp Seafile 的 Docker Image 包含了 Nginx 实例，直接由外部主机访问树莓派的 8000 或 8443 端口即可 至此，访问 seafile 在 LAN 下的 URL 即可开始使用: 通过外网访问 Seafile 的设置属于另外一个 topic，可参考 电信宽带的正确使用姿势 和 通过 DDNS 实现稳定内网穿透 两篇文章 设置开机启动 Seafile创建 service.unit 文件，此处以 seafile.service 为例:123456789101112131415[Unit]Description=Seafile ServiceAfter=mnt-sda1.mount[Service]Type=forkingExecStart=/home/pi/seafile-server/seafile-server-latest/seafile.sh startExecStop=/home/pi/seafile-server/seafile-server-latest/seafile.sh stopStandardOutput=inheritStandardError=inheritRestart=on-failureUser=pi[Install]WantedBy=multi-user.target 注意，因为使用到了外部存储单元，故在 After 一项处填写了 mnt-sda1.mount，意即在 sda1 挂载成功之后再启动该服务。 之后，复制该文件至 systemd 配置目录下:1$ sudo cp seafile.service /etc/systemd/system/seafile.service 使用 systemctl start 和 systemctl stop 测试服务，紧接着启用服务托管:1$ sudo systemctl enable seafile.service 此部分参考了树莓派官方文档 使用各平台客户端移步官方给出的下载地址下载想要的客户端，值得一提的是，iOS 客户端可以通过设置页面同步照片: 迁移数据假设先前为 seafile 指定的目录空间不足了，需要迁移至更多空间的目录，先停止或删除 seafile 的 Docker container:12$ docker stop seafile$ docker rm seafile 移动原先指定的目录至新的目录:1$ rsync -avH [seafile-data-source-path] [seafile-data-destination-path] 数据量越大，迁移时间越长。数据迁移完成后，重新执行 docker 命令并指向新的映射目录即可。]]></content>
      <categories>
        <category>Home Server</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>raspberry-pi</tag>
        <tag>seafile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[家庭数字化系统 - 准备树莓派]]></title>
    <url>%2Fhomeserver-setup-raspberry-pi%2F</url>
    <content type="text"><![CDATA[参考资料: Docker Comes to Raspberry Pi 本文目录: 背景 硬件准备 软件准备 安装及配置系统镜像 为树莓派 Raspbian 系统安装 Docker 引擎 安装 Docker 引擎 背景作为一名技术宅，自然是希望自己家里的「数字化系统」越 fancy 越好，但考虑到腰包里毛爷爷的数量，不得不搜寻物美价廉的方案来实现一些「非刚需，但 Nice to Have」的需求，这些需求包括但不限于: 局域网多设备的文件共享 7 * 24小时无人值守的下载器 绕过第三方云存储的私有云同步方案 家庭媒体中心的搭建 家庭智能设备的网关系统 笔者打算针对上述罗列的内容单辟一个系列，以一篇一个主题覆盖其中所有的细节。如果你也有以上列表中的一项或多项需求，不妨继续往下看。 硬件准备为了达成这一愿景，需要在基础设施上投入一些成本，其中最重要的是家庭服务器。我们对家庭服务器的期待至少有: 性能稳定，功耗低，价格低廉。如今爆火的树莓派非常符合家庭小型服务器的要求，网络上关于树莓派的文章很多，这里不再赘述。 假设我们手上已经有了一台树莓派(2 代以上的版本都可以)，还需要准备以下设备: 网线 * 1 Micro SD 卡 * 1，容量大于 8 GB Micro SD 读卡器 * 1 键盘 * 1 HDMI 线 * 1 显示器 * 1 USB 电源线 * 1 软件准备 Raspbian Stretch Lite 系统镜像 -&gt; 下载地址 Etcher 映像烧录软件 -&gt; 下载地址: 将树莓派系统镜像烧录至 Micro SD 卡的工具软件 官方提供了 3 个版本的系统镜像，本文为了尽量保持简单，选择最为精简的版本 Raspbian Stretch Lite，此镜像是基于命令行工具的版本，本系列文章均基于命令行工具版本的系统镜像介绍，如果对命令行界面不熟悉，可以选择另外两个自带桌面 GUI 的版本 安装及配置系统镜像 使用 Etcher 将 Raspbian Stretch Lite 烧录至 Micro SD 卡中 将 Micro SD 卡插入树莓派 将网线，电源线，HDMI 线和键盘与树莓派相连 树莓派开机，第一次启动大概需要 1-2 分钟 使用预设用户/密码为 pi/raspberry 登录系统 键入 sudo raspi-config 进行如下设置: -&gt; 1 Change User Password，修改 pi 用户登录密码 -&gt; 2 Network Options -&gt; N1 Hostname，更改 Hostname -&gt; 2 Network Options -&gt; N2 Wi-fi，设置家庭局域网的 Wifi，不管是使用无线还是有线网络，确保树莓派与家庭中的其他设备位于同一个局域网即可 -&gt; 5 Interfacing Options -&gt; P2 SSH，启用 SSH，对于使用命令行或需要通过其他主机远程管理树莓派的需求，这一步是必须的 配置完成后，重启树莓派 在 PC 上使用 SSH 客户端软件(如 PuTTY 等)远程登录树莓派 (可选)为了防止 IP 地址过期，可通过路由器管理界面给树莓派分配静态的 IP 地址 至此，树莓派的准备工作就完成了，其网络拓扑如下: 为树莓派 Raspbian 系统安装 Docker 引擎 之所以将这一步纳入树莓派的准备工作中，是因为笔者发现在实际使用过程中，几乎所有常见的服务都发布了其相应的 Docker 镜像。对容器化不熟悉的朋友可以参考 iOS 对 App 的管理思路: 每个 App 都从统一的入口(App Store)下载，在单独的隔离环境运行，卸载时也不会出现诸如 Windows 上大量残余文件需要手动清理的问题。 对计算机(特别是服务器)的管理和维护是非常乏味的工作，相信各位在使用 Windows 系统时或多或少都有过系统盘空间越来越少，系统使用起来越来越卡顿的经验。而服务器是以高可用性为宗旨的，如何最大程度的降低维护成本是管理服务器的首要考量。Docker 解决了不同的服务在部署时由于依赖问题而污染宿主机的问题。使得安装和部署某个服务在单独的隔离环境中进行，简化了流程，也更加清晰。 安装 Docker 引擎树莓派官网提供了安装 Docker 引擎的脚本，下载安装脚本并执行:123456789101112131415161718192021222324252627282930313233$ curl -sSL https://get.docker.com | shClient: Version: 18.05.0-ce API version: 1.37 Go version: go1.9.5 Git commit: f150324 Built: Wed May 9 22:24:36 2018 OS/Arch: linux/arm Experimental: false Orchestrator: swarmServer: Engine: Version: 18.05.0-ce API version: 1.37 (minimum version 1.12) Go version: go1.9.5 Git commit: f150324 Built: Wed May 9 22:20:37 2018 OS/Arch: linux/arm Experimental: falseIf you would like to use Docker as a non-root user, you should now consideradding your user to the "docker" group with something like: sudo usermod -aG docker piRemember that you will have to log out and back in for this to take effect!WARNING: Adding a user to the "docker" group will grant the ability to run containers which can be used to obtain root privileges on the docker host. Refer to https://docs.docker.com/engine/security/security/#docker-daemon-attack-surface for more information. 将 pi 用户加入 docker 群组1$ sudo usermod -aG docker pi 如提示所说，用户 pi 加入群组后需要再次登录以生效 再次以 pi 用户登录树莓派，执行 docker -v，看到版本号即表示安装成功:123$ docker -vDocker version 18.05.0-ce, build f150324 至此，树莓派准备就绪，可以开始部署各种应用服务了。]]></content>
      <categories>
        <category>Home Server</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>raspberry-pi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[智慧家庭 - 外网远程访问家庭服务器中的 Home Assistant 实例]]></title>
    <url>%2Fsmarthome-enable-remote-access-to-ha%2F</url>
    <content type="text"><![CDATA[配置从外网访问 HA安装好 HA 之后，我们发现访问 Web UI 的 url 不需要任何用户认证，如果你打算将其暴露到互联网并通过外网访问自己的 HA，这等同于裸奔，任何互联网用户都能够控制你家的 HA。 为 HA 网页 UI 设置密码HA 支持为其设置访问密码的功能，可通过 http 节点下进行配置，首先在 config 文件夹下找到 secrets.yaml，编辑该文件:12345$ sudo nano /etc/home-assistant/config/secrets.yaml# Use this file to store secrets like usernames and passwords.# Learn more at https://home-assistant.io/docs/configuration/secrets/http_password: &#123;your_password_here&#125; 同时，在 configuration.yaml 中的 http 节点下指定该项的引用:1234567$ sudo nano /etc/home-assistant/config/configuration.yamlhttp: # Secrets are defined in the file secrets.yaml api_password: !secret http_password ip_ban_enabled: true login_attempts_threshold: 5 ip_ban_enabled 和 login_attempts_threshold 分别表示启用密码试错机制。然后重启 HA 服务:1$ docker container restart home-assistant 为 Home Assistant 配置 Nginx 代理将 Web UI 设置于 Nginx 之后有诸多好处，其中一项便是为其配置 Http SSL，关于 Nginx 的细节本文不赘述，此处假定 ha.example.com 为 Web UI 的虚拟主机名称:123456789101112131415161718192021$ sudo nano /etc/nginx/sites-available/ha.example.commap $http_upgrade $connection_upgrade &#123; default upgrade; &apos;&apos; close;&#125;server &#123; listen 8123; listen [::]:8123; server_name ha.example.com; location / &#123; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection $connection_upgrade; proxy_pass http://localhost:8123; &#125;&#125; 保存，创建该站点配置文件的符号链接，重启 Nginx:12$ sudo cp -s /etc/nginx/sites-available/ha.example.com /etc/nginx/sites-enabled/ha.example.com$ sudo systemctl reload nginx 为 HomeAssistant 应用 HTTPS即便使用了 API 密码，在不安全的通信连接中该信息仍然可能泄漏，要为站点应用 HTTPS，首先需要一个从世界知名 CA 获取的 SSL 数字证书，关于如何申请证书请参考「通过 Let’s Encrypt 申请 SSL 数字证书」。假设已经为 ha.example.com 申请了 SSL 数字证书，并且相关文件位于 /etc/nginx/ssl/ 下，编辑站点的 Nginx 配置文件，具体参考「NGINX with subdomain」。12345678910111213141516171819202122232425262728server &#123; listen 443 ssl; server_name ha.example.com; ssl on; ssl_certificate /etc/nginx/ssl/ha.example.com/ha.example.com-bundle.crt; ssl_certificate_key /etc/nginx/ssl/ha.example.com/ha.example.com.key; ssl_prefer_server_ciphers on; location / &#123; proxy_pass http://localhost:8123; proxy_set_header Host $host; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection "upgrade"; &#125; location /api/websocket &#123; proxy_pass http://localhost:8123/api/websocket; proxy_set_header Host $host; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection "upgrade"; &#125;&#125;]]></content>
      <categories>
        <category>Smart Home</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>raspberry-pi</tag>
        <tag>smart-home</tag>
        <tag>home-assistant</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[智慧家庭 - 通过 Amazon Alexa 控制连接至 HomeAssistant 的智能设备]]></title>
    <url>%2Fsmarthome-control-via-alexa%2F</url>
    <content type="text"><![CDATA[参考资料: Home Assistant Cloud HAASKA HA - Alexa/Amazon Echo 本文索引: 前言 通过 Home Assistant Cloud 实现 配置 Home Assistant Cloud 创建 Home Assistant Cloud 账号 激活 Alexa Home Assistant Skill 通过 HAASKA 实现(TBD) 准备 HAASKA 配置 Amazon AWS 通过 Emulated Hue Bridge 的方式实现 原理 实现 前言要使用 Amazon Alexa 控制接入 HomeAssistant 的智能设备，有以下可能的办法: Home Assistant Cloud: 官方推崇的方式，通过启用 Alexa 的 HomeAssistant Skill，结合 Home Assistant Cloud 服务可实现开箱即用的集成，不差钱的可选择这种方案 HAASKA(Home Assistant Alexa Skill Adaptor): 社区的开源项目，用 python 编写适用于 Alexa Skill 的 AWS Lamba 函数包，实现了 Home Assistant Smart Home API 和 Alexa Smart Home Skill API 之间的桥梁作用，需要一系列进阶的配置，动手能力的强可选用此方案。 Emulated Hue Bridge: 纯本地方式，将 Alexa-based 设备作为 Emulated Hue Bridge 网关接入 HA，通过 Hue API 与 HA 中的设备进行交互，最简单的方案，但功能非常有限 接下来将分别展示这些方案的实现过程。 通过 Home Assistant Cloud 实现配置 Home Assistant CloudHome Assistant Cloud 是由 NABU CASA 提供的云服务，可试用 31 天。 创建 Home Assistant Cloud 账号进入 HA 的 Configuration Tab，点击 Create Account 注册完成后，在相同的界面登录，进入到管理界面: 激活 Alexa Home Assistant Skill进入 Alexa Skills 列表，搜索 Home Assistant，点击激活，之后登录刚刚注册的 Home Assistant Cloud 账号。 之后，在 HA 的 configuration.yaml 中进行配置:123456789101112131415cloud: alexa: filter: include_entities: - light.yeelight_ct2_7c49eb1551e8 include_domains: - switch exclude_entities: - switch.outside entity_config: light.yeelight_ct2_7c49eb1551e8: name: Lamp description: The lamp with a green cover switch.stairs: display_categories: LIGHT 以上 cloud 节点是配置如何向 Alexa 暴露 HA 中的实体，与之前讨论的 homekit 组件配置方法类似，具体可参考: Alexa via Home Assistant Cloud。 完成之后重启 HA，对 Alexa 说一声 “Alexa, turn on the lamp.” 试试看。 通过 HAASKA 实现(TBD)由于 Amazon 对 Alexa Skill 的限制条件(例如只能使用 HTTPS)，要通过 HAASKA 实现通过 Alexa 控制 HomeAssistant，需要确保以下条件得到满足: Home Assistant 实例的版本高于 0.78 路由器可配置端口转发 Home Assistant 必须以 HTTPS 向外暴露: Amazon 的要求 如果家中的 WAN 不是静态 IP 地址，则需要配置 DDNS 成为 Amazon 开发者并创建一个 AWS 账号: HAASKA 将使用 AWS Lamba 服务，AWS 支持每月 100 万免费请求。 准备 HAASKA可直接至 Release 页面下载 HAASKA 的 Zip 包。接着，在 configuration.yaml 文件中添加以下组件的配置节:1234api:alexa: smart_home: 然后导航至 HomeAssistant 的 UI 界面上的 Profile 页面，在底部的 Long-Lived Access Tokens 中创建一个长生存期的 Access Token:完成之后，记录下返回的 Token 以作后用，它形如:1eyJ0eXAiOiJKV1QiLCJhbGciOi...... 配置 Amazon AWS首先导航至 Login with Amazon Console，点击 Create a New Security Profile: 通过 Emulated Hue Bridge 的方式实现原理这种办法是使用 HA 的 Emulated Hue Bridge 组件暴露 Hue API，让 Alexa-based 设备误以为 HA 是一个 Philips Hue Hub。 实现编辑 configuration.yaml 配置文件:123# Amazon Alexaemulated_hue: host_ip: 192.168.1.140 保存更改，重启 HA 服务1$ docker container restart home-assistant 重新使用 Echo -&gt; Start Home 查找设备，即会将所有与 HA 关联的设备列出。]]></content>
      <categories>
        <category>Smart Home</category>
      </categories>
      <tags>
        <tag>smart-home</tag>
        <tag>home-assistant</tag>
        <tag>alexa</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[智慧家庭 - 使用 HA 的 Device Tracker 组件实现「在家检测」]]></title>
    <url>%2Fsmarthome-ha-device-tracker%2F</url>
    <content type="text"><![CDATA[本文索引: 前言 iOS 用户的专有追踪平台 使用 ios 组件 使用 iCloud 组件 使用 MQTT Broker 组件追踪设备 为 HA 添加第三方 MQTT Broker 为 Device Tracker 组件添加 MQTT Platform 为手机安装 OwnTracks 发送位置变化消息 前言HA 提供了 Device Tracker 组件用于追踪设备，该组件支持众多 Platform，不同的 Platform 通过不同的手段实现设备位置变化的检测，它们包括但不限于: ios: iOS 设备用户的可选 Platform，可通过 HomeAssistant iOS App 向 HA 上报位置信息。 Bluetooth Tracker Platform 和 Bluetooth LE Tracker Platform: 通过蓝牙近距离通信技术，HA 主机与蓝牙设备之间的握手以确定设备是否在家，要求 HA 的主机和设备均支持蓝牙硬件 MQTT(Message Queue Telemetry Transport) Broker Platform: 设备向 MQTT Broker 发布位置变化信息，Device Tracker 向 MQTT Broker 拉取位置变化信息实现。要求移动设备安装能够向 MQTT 服务发送消息的 App。如果使用 HA 内置的 MQTT Server，则 HA 的 iOS App 已集成了发送消息的功能。 OpenWrt Platform: 通过路由器 OpenWrt 系统的 DHCP 服务进行检测，要求设备与路由器必须位于同一网络 Nmap Platform: 通过 Nmap 扫描接入同一 LAN 中各个设备的 IP 地址实现，同样要求设备与 HA 主机处于同一网络 iCloud Platform: Apple 设备通过 Find My iPhone 功能持续向 iCloud 报告位置数据，Device Tracker 向 iCloud 拉取位置变化数据。要求设备必须开启 Find My iPhone 并在 Device Tracker 组件中提供 iCloud 的用户名和密码。 可结合多个不同的 Platform 一起使用，Device Tracker 将以最近报告的 Platform 作为参考。如果设备被标记为「在家」，将不会在地图上显示。一旦一个新的设备以某种 Platform 被 device_tracker 组件捕获，则会在 known_devices.yaml 中创建一条该设备的记录，以 DeviceID 标识，并支持以下参数: name: 设备的友好名称 mac: 设备的 MAC 地址，每设备唯一，要使用诸如 Nmap 或 SNMP 等 network device tracker 时必须为设备指定 MAC 地址 picture: 指定一张用于快速辨识设备的图片地址，可新建一个与 configuration.yaml 同级的 www 目录并将图片放于该目录下，然后使用 /local/{picture-file-name} 来引用该图片，也可直接使用网络 Url icon: 为设备指定图标 gravatar: 设备主人的 Email 地址，如果设置该值，将覆盖 picture 参数 track: 根据 Platform 不同可指定 yes/on/true 值，均表示该设备需要被追踪，否则它的位置和状态将不会更新 hide_if_away: 根据 Platform 不同可指定 yes/on/true 值，均表示如果设备「不在家」将隐藏 consider_home: 该设备「离开家」之后等待多少时间以将该设备标记为「不在家」，单位为秒，该值将重写 platform 级别的 consider_home 值 例如，以下节点表示一台设备:1234567pangoiphonese: hide_if_away: false icon: mac: name: Pango.iPhone SE picture: track: true iOS 用户的专有追踪平台HA 社区为 iOS 设备的用户提供了特有的 device_tracker platform。 使用 ios 组件用到的组件: ios Location 由于 iOS App 需要连接至家庭服务器的 HA 实例，所以 iOS 组件要求 HA 实例能够以某种方式被外网访问，具体可参考 ddns 和 port forwarding。 Home Assistant 0.42.4 自开始支持 iOS 版 App，iOS 用户可在 App Store 下载 Home Assistant App 配置连接到自家的 Home Assistant 的服务器，该 App 以 Web App 加载 HA 的实例，并实现了上报位置信息，通知等功能。首先在 App Store 下载 App，填写配置界面相关信息: 设备 ID 代表 HA 在 known_devices.yaml 中识别该设备的 ID 要实现和 HA 服务端的通信，还需要在 configuration.yaml 中启用 ios 组件:1ios: 启用 ios 组件意味着同时启用 device tracker、zeroconf 和 notify 组件: 使得 HA 接收由 iOS App 发送的位置信息 HA 将通知推送至 App， HA 接收 iOS 设备的 sensor 信息重启 HA 实例，之后 iOS App 便会在适当的时刻向指定服务器报告当前设备的信息。由于 Apple 报告位置信息的时机没有对外公开，手机在家时 iOS App 也会时不时向服务器报告位置，为了解决这个问题，在 zones.yaml 文件中禁用 iOS 设备追踪:123456- name: Home latitude: xx.xxxxxx longitude: yy.yyyyyy radius: 250 icon: mdi:account-multiple track_ios: false 使用 iCloud 组件iOS 用户的另一个选择是使用 iCloud Platform，可在 configuration.yaml 文件中添加如下节点:1234device_tracker: - platform: icloud username: &#123;your-apple-id&#125; password: &#123;password-for-your-apple-id&#125; iCloud Platform 提供了以下参数: username: Apple Id，必填 password: Apple Id 的密码，必填 account_name: 自定义名称 max_interval: 当 Apple 设备静止时使用的位置更新间隔时间，以分钟为单位，默认值为 30 分钟。。当设备移动时，位置更新时间为 1 分钟一次。 gps_accuracy_threshold: 位置变化触发更新的阈值，以米为单位，默认值为 1000 米。这意味着当 gps 变化小于 1000 米时，device_tracker 将不会更新设备的状态。 设置好 iCloud Platform 之后，重启 HA，此时面板中将出现一个 Configurator 询问要使用该 Apple Id 下关联的哪一个设备作为受信任的设备:点击 CONFIGURE 按钮，弹出以下对话框，输入代表设备的索引值(此处为 0)，点击 Confirm，等待接收短信验证码:受到手机验证码之后，再次点击 Configurator 的 CONFIGURE 按钮，填入验证码:等待 HA 与 iCloud 通信完成之后，HA 的面板中会出现代表该设备的 sensor，设置完成。Apple 对这种认证的有效期通常为 2 个月，2 个月之后需要重新认证。 使用 MQTT Broker 组件追踪设备MQTT 是基于 TCP/IP 定义的专用于 IoT 的通信协议，采用轻量级的订阅/发布消息传输。HA 提供了支持 MQTT Broker 组件，HA 实例和移动设备无需直接通信，而是借助 MQTT Broker 作为通信桥梁。HA 也支持了运行内置的 MQTT 消息代理。要使用内置的 MQTT 组件，在 configuration.yaml 中加入以下配置:1mqtt: 该组件提供了以下参数: broker: MQTT Broker 服务所在主机的 IP 地址或主机名，可选 port: MQTT Broker 服务连接所使用的端口，可选，默认值为 1883 client_id: HA 访问 MQTT Broker 服务时所使用的客户端 ID，字符串类型，可选，默认值随机生成 keep_alive: 发送 keep_alive 消息的时间间隔，单位为秒，可选，默认值为 60 username: 访问 MQTT Broker 服务的用户名，可选 password: 与 username 对应的密码，可选 protocol: 使用的协议版本，可选值为 3.1 或 3.1.1，默认使用 3.1.1，如果服务不支持则使用 3.1 certificate: 证书文件的物理路径，可选为 HA 添加第三方 MQTT Broker官方推荐使用第三方服务商以确保稳定性，此处选择 CloudMQTT 作为 MQTT Broker，其 Cat Plan(免费) 最大支持 5 个并行连接。创建完帐号后，登录到后台，创建专用用户 ha 及密码，在 ACLs 面板下选中 Topic，选择 ha 用户，topic 输入 #: 在 HA 的 configuration.yaml 中引入 MQTT Broker 组件并填入以下参数:123456mqtt: broker: CLOUTMQTT_SERVER // address for the server port: CLOUDMQTT_PORT // SSL Port certificate: auto // load corresponding certificate username: CLOUDMQTT_USER // ha user password: CLOUDMQTT_PASSWORD // password for ha 配置好 mqtt broker 之后，重启 HA 实例，可在其 Web UI 上发现一个新的按钮，并通过发送相应的消息来测试该功能: 为 Device Tracker 组件添加 MQTT PlatformDevice Tracker 组件支持 MQTT Platform 平台(MQTT Device Tracker)，在 configuration.yaml 中加入以下配置信息:12345device_tracker: - platform: mqtt devices: iphone_se: 'location/iphone_se' iphone_6p: 'location/iphone_6p' 配置好 mqtt platform 之后，被追踪的设备需要以某种方式向远端 mqtt broker 发送消息，否则 HA 将无消息可拉取。官方推荐了 owntracks platform 作为 iOS/Android 设备的消息推送方案，HA 服务端也需要开启 owntracks 组件以设置相关的配置，于是，修改上面的配置用 owntracks platform 代替 mqtt platform:12device_tracker: - platform: owntracks owntracks platform 支持一些额外的参数: max_gps_accuracy: 设置上报位置信息的最大变化阈值，以过滤在某些情况下的 GPS 错误数据上报，避免造成副作用。可选，默认值 200 waypoints: OwnTracks App 用户可定义 WayPoints 区域，与 HA 的 Zone 类似，用户可选择在 App 端导出 WayPoints 而 HA 可将其映射为 Zone。可选，默认值为 true secret: Payload 加密密钥，当使用第三方或公共 MQTT 服务商时可能希望对发送的位置数据进行加密。可选，默认值为空，该参数要求 HA 主机安装了 libsodium 库 mqtt_topic: HA 订阅 MQTT Broker 的消息模板。可选，默认值为 owntracks/# events_only: 仅拉取地图区域的进入与离开信息，不关注移动设备的位置变更信息。可选，默认值为 false region_mapping: 配置 OwnTracks 定义的 Region 与 HA 实例定义的 Zone。字典结构，可选 为手机安装 OwnTracks 发送位置变化消息OwnTracks 是一个免费开源的位置数据共享 App，支持以 HTTP 或 MQTT 协议向指定服务端发送位置数据。从 App Store 或 Android 应用市场下载 OwnTracks，此处以 iOS 为例，点击左上角的 i -&gt; Settings，填入在 CloudMQTT 实例上获取的配置信息:解释为文本版的配置信息为:123456789101112Mode: MQTTTrackerID: &#123;tracker-id&#125;DeviceID: &#123;device-model&#125;Host: &#123;your-mqtt-broker-instance-address&#125;Port: &#123;ssl-port&#125;WebSockets: disabledProto: 4TLS: enabledUserID: &#123;my-username-for-iOS-device&#125;Authentication: enabledPassword: &#123;password-for-my-username&#125;Secret encryption key:]]></content>
      <categories>
        <category>Smart Home</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>raspberry-pi</tag>
        <tag>smart-home</tag>
        <tag>home-assistant</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[智慧家庭 - 通过 Siri 控制连接至 HomeAssistant 的智能设备]]></title>
    <url>%2Fsmarthome-control-via-siri%2F</url>
    <content type="text"><![CDATA[参考资料: Github - Homebridge Github - Home Assistant Plugin Github - HomeBridge Docker HomeKit - HomeAssistant 本文索引: 背景 通过 HomeKit 组件实现 注意事项 通过 HomeBridge 及其插件实现(老方法) 安装 NodeJs(Optional) 安装 Homebridge 安装 HA 插件 配置 config.json 配置开机启动 Homebridge 背景比起 Alexa ，通过 Siri 联通 HA 的优势在于: 支持中文语音 至少有一台 iOS 设备就可以实现，无需购买 Echo 系列的产品 Siri 通过 HomeKit 与 Apple Home 通信，HomeKit 扮演了 Apple Home 数据库的角色。只要 HomeAssistant 中暴露的实体能够被 HomeKit* 识别就可以由 Siri 进行控制。从 HA 0.64 开始就内置了 homekit 组件，不再需要单独运行 HomeBridge 及其 HomeAssistant 插件来实现。 通过 HomeKit 组件实现首先安装必要组件:1$ sudo apt-get install libavahi-compat-libdnssd-dev 找到 configuration.yaml 文件，添加以下配置信息:123456789homekit: auto_start: true filter: include_entities: - light.lamp entity_config: light.lamp: name: 台灯 homekit 组件支持以下参数: auto_start: 指示 HomeKit Server 是否应该在 HomeAssistant Core 启动完成后重新启动，可选，默认值为 true port: 自定义 HomeKit Server 暴露的端口，可选，默认值为 51827 name: 指定 HomeKit 的名称，同一网络中单个 HomeAssistant 实例必须唯一，可选，默认值为 Home Assistant Bridge ip_address: 显式指定 IP 地址，仅当 Home Assistant 的默认值不起作用时有用，可选 safe_mode: 仅当配对出现问题时设置该值，可选，默认为 false filter: 定义被暴露/隐藏的 HomeAssistant 实体: include_domains: 需要包含的域，可选 include_entities: 需要包含的实体，可选 exclude_domains: 需要排除的域，可选 exclude_entities: 需要排除的实体，可选 entity_config: 针对实体的单独定义 &lt;entity_id&gt;: 实体的引用 name: 在 HomeKit 中用以显示的名称，可选，HomeKit 在首次运行时会缓存名称，当设备发生任何变化时，需要先移除并重新添加 code: 仅针对闹钟设备 arm / disarm 或智能锁设备 lock / unlock 有效，可选 feature_list: 仅针对 media_player 实体有效，以字典形式添加的功能列表，可选 feature: 添加至实体的功能名称，必填，有效值为 on_off、play_pause、play_stop 和 toogle_mute。且 media_player 实体必须这些功能才能生效 type: 仅针对开关(switch) 实体有效。表示在 HomeKit 中的开关类型，可选。有效值有 faucet、outlet、shower、sprinker、switch 和 value，默认值为 switch。HomeKit 在首次运行时会缓存类型，当设备发生任何变化时，需要先移除并重新添加。 保存，重启 HA，将在主页面看到一个新的 Card: 确保 iOS 设备与 HA 及智能设备处于同一 wifi 网络，打开 iOS 上的 Home App 点击「添加配件」 选择「没有代码或无法扫描」 输入上图所示的 PIN Code 弹出未认证配件时点击「仍然添加」 添加完成后的配件如下图所示: 现在，通过 iOS 设备呼出 Siri，让 TA 关闭台灯，即可生效。 注意事项 homekit 组件使用 accessory id(aid) 将连接至 HomeAssistant 的实体 entity_id 绑定起来，homekit 组件使用 aid 来识别设备。因此，一旦改变某个连接至 HomeAssistant 的设备的 entity_id，所有在 Home App 中针对该设备的改动都将丢失。 单个 HomeKit 最多包含 100 个附件 内置的 homekit 组件无法持久化 Home Assistant Bridge 桥接设备，但已被添加至该桥接设备的配件会被持久化，这是 HomeKit 本身的问题。为了解决这个问题，可引入一个 Automation - 当 HomeKit 所依赖的实体设置完成后启动 HomeKit。做法如下: 首先禁用 homekit 组件的自动启动: 12homekit: auto_start: false 定义用于启动 homekit 组件的 Automation: 123456automation: - alias: 'Start HomeKit' trigger: - platform: event event_type: light.lamp.network_ready action: homekit.start 也可以使用一种更加泛化的判定方式，在 HomeAssistant 启动 5 分钟后再启动 homekit 组件: 12345678automation: - alias: 'Start HomeKit' trigger: - platform: event event_type: homeassistant_start action: - delay: 00:05 # Waits 5 minutes - service: homekit.start 通过 HomeBridge 及其插件实现(老方法)HomeBridge 是一个发布在 npm 中的包，依赖 NodeJs，并且有各种各样的插件以支持不同的网关系统。 安装 NodeJs(Optional)首先安装 NodeJs:12345678910111213141516171819202122232425262728$ sudo curl -sL https://deb.nodesource.com/setup_10.x | sudo -E bash -## Run `sudo apt-get install -y nodejs` to install Node.js 10.x and npm## You may also need development tools to build native addons: sudo apt-get install gcc g++ make## To install the Yarn package manager, run: curl -sL https://dl.yarnpkg.com/debian/pubkey.gpg | sudo apt-key add - echo &quot;deb https://dl.yarnpkg.com/debian/ stable main&quot; | sudo tee /etc/apt/sources.list.d/yarn.list sudo apt-get update &amp;&amp; sudo apt-get install yarn$ sudo apt install -y nodejsReading package lists... DoneBuilding dependency treeReading state information... DoneThe following NEW packages will be installed: nodejs0 upgraded, 1 newly installed, 0 to remove and 45 not upgraded.Need to get 13.4 MB of archives.After this operation, 66.7 MB of additional disk space will be used.Get:1 https://deb.nodesource.com/node_10.x stretch/main armhf nodejs armhf 10.9.0-1nodesource1 [13.4 MB]Fetched 13.4 MB in 6s (2,042 kB/s)Selecting previously unselected package nodejs.(Reading database ... 38984 files and directories currently installed.)Preparing to unpack .../nodejs_10.9.0-1nodesource1_armhf.deb ...Unpacking nodejs (10.9.0-1nodesource1) ...Setting up nodejs (10.9.0-1nodesource1) ...Processing triggers for man-db (2.7.6.1-2) ... 安装 Homebridge通过 npm 安装 HomeBridge 包:12345$ sudo npm install -g --unsafe-perm homebridgemake: Leaving directory '/usr/lib/node_modules/homebridge/node_modules/ed25519-hap/build'+ homebridge@0.4.44added 40 packages from 35 contributors in 54.124s 现在执行 homebridge 命令，表示安装成功了。123$ homebridgeconfig.json (/home/pi/.homebridge/config.json) not found.No plugins found. See the README for information on installing plugins. 安装 HA 插件不带插件的 Homebridge 没有任何用1234$ sudo npm install -g homebridge-homeassistant+ homebridge-homeassistant@3.1.0added 53 packages from 60 contributors in 17.553s 配置 config.json在创建 config.json 之前，Homebridge 不会做任何事，config.json 放置在 ~/.homebridge 目录下:123456789101112131415161718192021222324$ cd ~/.homebridge$ sudo nano config.json&#123; "bridge": &#123; "name": "Homebridge", "username": "CC:22:3D:E3:CE:30", "port": 51826, "pin": "031-45-154" &#125;, "platforms": [ &#123; "platform": "HomeAssistant", "name": "HomeAssistant", "host": "http://127.0.0.1:8123", "password": "YOURPASSWORD", "supported_types": ["automation", "binary_sensor", "climate", "cover", "device_tracker", "fan", "group", "input_boolean", "light", "lock", "media_player", "remote", "scene", "script", "sensor"$ "default_visibility": "visible", "logging": false, "verify_ssl": false &#125; ]&#125; HomeBridge 以被 HomeKit 识别的组件向其暴露，bridge 对象用于向 HomeKit 描述其组件自身的信息，包括用作显示名称的 name，用作唯一标识的 Mac 地址 username，端口号及 pin，该 pin 用于与 HomeKit 进行配对。platforms 是一个数组，代表配置的多种插件信息，这里仅安装了 HA 的插件，配置对象的信息均与 HA 有关，包含了诸如 host，api-password，支持的 entity 类型等，具体可参考 Github Repo。 配置完成后，重新启动 Homebridge:1$ homebridge 打开 iOS 系统自带的 Home App 扫描屏幕上的二维码，取得 HomeAssistant 中暴露的 Entity(HA 中将所有接入网关的设备称为一个 Entity)并试试控制它们。然后再用「Hey, Siri」来控制试试。 配置开机启动 Homebridge 粘贴默认配置信息: 123456789$ sudo nano /etc/default/homebridge # Defaults / Configuration options for homebridge# The following settings tells homebridge where to find the config.json file and where to persist the data (i.e. pairing and others)HOMEBRIDGE_OPTS=-U /var/homebridge# If you uncomment the following line, homebridge will log more # You can display this via systemd&apos;s journalctl: journalctl -f -u homebridge# DEBUG=* 创建 systemd service 文件: 1234567891011121314151617$ sudo nano /etc/systemd/system/homebridge.service[Unit]Description=Node.js HomeKit Server After=syslog.target network-online.target[Service]Type=simpleUser=homebridgeEnvironmentFile=/etc/default/homebridgeExecStart=/usr/bin/homebridge $HOMEBRIDGE_OPTSRestart=on-failureRestartSec=10KillMode=process[Install]WantedBy=multi-user.target 创建专用于执行该服务的用户和群组: 1sudo useradd --system homebridge 创建 homebridge 配置目录并拷贝配置文件 12$ sudo mkdir /var/homebridge$ sudo cp ~/.homebridge/config.json /var/homebridge/ 将其他必要文件夹拷贝至该目录: 1$ sudo cp -r ~/.homebridge/persist /var/homebridge 更改该目录的权限: 1$ sudo chmod -R 0777 /var/homebridge 创建 system service 链接并启动服务: 123$ sudo systemctl daemon-reload$ sudo systemctl enable homebridge$ sudo systemctl start homebridge 检查服务启动状态及查看日志: 123$ sudo systemctl status homebridge$ journalctl -f -u homebridge]]></content>
      <categories>
        <category>Smart Home</category>
      </categories>
      <tags>
        <tag>smart-home</tag>
        <tag>home-assistant</tag>
        <tag>homebridge</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[智慧家庭 - 完善 HomeAssistant 的常见基础配置]]></title>
    <url>%2Fsmarthome-ha-basic-configuration%2F</url>
    <content type="text"><![CDATA[本文索引: 启用认证系统 配置 Zone 信息 为 HA 主机添加系统监控组件 启用认证系统相关组件: Authentication Authentication Providers HA 以 auth_provider 的方式支持不同种类的认证，在 configuration.yml 中的 homeassistant 节点下添加:123homeassistant: auth_providers: - type: &#123;auth provider type&#125; 截至 0.80 版本，HA 支持 3 种 auth_provider: home assistant auth provider: 默认的认证提供器，类似于用户管理系统，type 名称为 homeassistant trusted network: 安全网络，例如，配置家庭局域网不受认证系统的限制，type 名称为 trusted_networks legacy api password: 该功能主要是为了向前兼容 api_password 认证功能 一个完整的例子为:1234567891011homeassistant: auth_providers: - type: homeassistant - type: trusted_networks - type: legacy_api_passowrdhttp: api_password: !secret http_password trusted_networks: - 127.0.0.1 - 192.168.1.0/24 上面的例子同时支持 3 种认证，可根据需要选择认证种类。根据官方的说法，legacy_api_passowrd 认证会在未来的版本中移除，且 trusted_networks 的配置信息将从 http 模块移动到认证系统下。 值得注意的是，使用 trusted_networks 认证时，multi-factor authentication 模块将不会参与认证过程。另外，如果在同一机器使用反向代理服务器(如 nginx)向外暴露 HA，那么任何来自 WAN 并由反向代理服务器转发至 HA 的请求都会被认为处于可信任网络中，详情参考这篇文章以及 Nginx。 配置 Zone 信息相关组件: Zone Zone 组件用于划分自定义地图区域，这些区域可作为其他组件的参考信息，例如 Device Tracker 可根据 Zone 来判断一个移动设备是否位于某区域内。首先在 configuration.yaml 根配置中启用 Zone 组件，并指定从 zones.yaml 文件中提取具体 Zone 信息:1zone: !include zones.yaml 新建 zones.yaml 文件，并定义 Zone 如下:1234567891011- name: Home latitude: &#123;latitude-of-your-home&#125; longitude: &#123;longitude-of-your-home&#125; radius: 250 icon: mdi:account-multiple- name: Office latitude: &#123;latitude-of-your-office&#125; longitude: &#123;longitude-of-your-office&#125; radius: 250 icon: mdi:briefcase 一条 Zone 节点提供以下参数: name: 指定该 Zone 的名称，可选 latitude: 指定 Zone 的纬度，必填 longitude: 指定 Zone 的经度，必填 radius: 覆盖半径，以米为单位，可选，默认值为 100 米 icon: 指定 Zone 的图标，mdi 的标准名称，可至 https://materialdesignicons.com/ 参考查询 passive: 指示是否仅使用 Zone 组件用于自动化并从 Web 前端隐藏，默认为 false 经纬度信息因使用的 Map 组件不同而异，HA 默认采用的 Map 是 OpenStreetMap，可至 Google Map 查询经纬度。如果不分配任何 Zone 配置节，HA 将使用根配置中指定的经纬度信息绘制一个默认的 Home Zone。 为 HA 主机添加系统监控组件相关组件: Fast.com System Monitor 在 sensors.yaml 文件中包含 System Monitor 组件:1234567891011- platform: systemmonitor resources: - type: disk_use_percent arg: / - type: memory_use_percent - type: processor_use - type: network_in arg: eth0 - type: network_out arg: eth0 - type: last_boot 注意，读取的磁盘信息需要相应的 UNIX 用户权限 引用实体的 ID 可在 Web UI 的 States 面板找到: 在 groups.yaml 创建一个群组以展示这些信息:12345678system_monitor: entities: - sensor.processor_use - sensor.memory_use_percent - sensor.disk_use_percent_ - sensor.network_in_eth0 - sensor.network_out_eth0 - sensor.last_boot 最后，在 customize.yaml 中修改某些实体的自定义信息:12group.system_monitor: friendly_name: System Monitor 最终的效果如下图:]]></content>
      <categories>
        <category>Smart Home</category>
      </categories>
      <tags>
        <tag>smart-home</tag>
        <tag>home-assistant</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[智慧家庭 - 认识 Home Assistant 的配置系统]]></title>
    <url>%2Fsmarthome-ha-configuration-system%2F</url>
    <content type="text"><![CDATA[本文索引: 前言 YAML 使用环境变量 使用缺省值 包含其他文件 基本配置信息 向 HA 添加设备 风格1: 将所有实体以父级类聚 风格2: 单独定义每个设备 群组 自定义实体特性 前言HA 是由「组件」堆砌出的系统，官方提供了海量的组件及其用法的介绍，其中涵盖了使 HA 成为「家庭大脑」的方方面面，一个「组件」大致由两部分组成: 组件模块: 组件功能的核心逻辑 配置信息: 组件由外部加载的必要信息，可能包括 platform 信息，第三方服务的 key 等等 以下代码展示了一个 notify 组件，并采用 pushbullet platform 所有定义的配置信息:1234notify: platform: pushbullet api_key: "o.1234abcd" name: pushbullet 组件描述了功能的抽象含义，platform 指定可提供该功能的具体实现 HA 将所有「组件」通过配置信息定制，因此，配置信息成了描述整个 HA 的数据源，虽然 HA 社区正致力于实现通过 Web UI 来配置所有内容，但了解其数据模型对于解决问题及理解其运作方式非常有好处。HA 的配置信息会随着接入系统的设备增多而包含越来越多的信息，为了将不同类别的配置信息分开管理，官方推荐的做法是把根配置文件 configuration.yaml 下的不同节点以不同文件的形式进行管理，例如，默认的配置文件就包含了: configuration.yaml automations.yaml customize.yaml groups.yaml scripts.yaml … 由于配置信息会随时间增大，社区还推荐将配置文件夹作为 Git Repository 与远端进行同步，以防止数据丢失，并可跟踪修改历史。 不应将敏感信息文件纳入版本管理，请将 secrets.yaml 文件等包含敏感数据的配置文件添加至 .gitignore 中。 YAMLHA 使用 YAML 语法定义配置信息，几乎每种组件都定义了单独的配置节，YAML 语法需要注意以下细节: 以 - 开头表示集合元素 以 : 分割代表键值映射 默认使用两个空格代表一级缩进，Tab 不能用于缩进 使用环境变量以 !env_var {VAR_NAME} 从系统环境变量中取得值:12http: api_password: !env_var PASSWORD 使用缺省值配置信息可包含缺省值，例如:12http: api_password: !env_var PASSWORD &#123;default_password&#125; default_password 代表缺省值 包含其他文件可将同一类别的配置分割到单独的文件中以提高可读性，例如:1lights: !include lights.yaml 基本配置信息首先编辑 configuration.yaml 的基本配置信息:123456789101112homeassistant: # Location required to calculate the time the sun rises and sets latitude: &#123;latitude-for-your-home&#125; longitude: &#123;longitude-for-your-home&#125; # Impacts weather/sunrise data (altitude above sea level in meters) elevation: &#123;elevation-for-your-home&#125; # metric for Metric, imperial for Imperial unit_system: metric # Pick yours from here: http://en.wikipedia.org/wiki/List_of_tz_database_time_zones time_zone: America/Los_Angeles # Name of the location where Home Assistant is running name: My Awesome Home 向 HA 添加设备默认情况下，Discovery 组件开启，HA 会自动查找同一网络中的设备与服务。通常，每种「实体(entity)」都需要在 configuration.yaml 文件中进行手动配置，HA 支持两种风格来组织它们。 风格1: 将所有实体以父级类聚例如:123456789101112131415sensor: - platform: mqtt state_topic: "home/bedroom/temperature" name: "MQTT Sensor 1" - platform: mqtt state_topic: "home/kitchen/temperature" name: "MQTT Sensor 2" - platform: rest resource: http://IP_ADDRESS/ENDPOINT name: "Weather"switch: - platform: vera - platform: tplink host: IP_ADDRESS mqtt 和 rest 都属于 sensor 类别，将他们作为集合元素排列至 sensor 节点之下是以「类别」作为父级进行类聚。 风格2: 单独定义每个设备为了区分不同的实体，必须在其后跟上数字或名称，并且保持唯一:123456789101112131415161718192021sensor bedroom: platform: mqtt state_topic: "home/bedroom/temperature" name: "MQTT Sensor 1"sensor kitchen: platform: mqtt state_topic: "home/kitchen/temperature" name: "MQTT Sensor 2"sensor weather: platform: rest resource: http://IP_ADDRESS/ENDPOINT name: "Weather"switch 1: platform: veraswitch 2: platform: tplink host: IP_ADDRESS 以类别 名称单独定义实体，此处定义的 entity name 会转换为以 _ 分隔的 entity_id，例如 Living Room 会转换为 living_room。 群组一旦设置好设备，便可对它们进行「逻辑分组」，每个群组由其名称和一组「实体 ID」组成，「实体 ID」可在 Web UI 的 Developer Tools 面板的 Set State 页面找到: 可由以下两种风格定义群组:123456789group: # 数组风格 living_room: entities: light.table_lamp, switch.ac # 集合风格 bedroom: entities: - light.bedroom - media_player.nexus_player 自定义实体特性不同类别的「实体」提供了一组通用的 attribute 用于实现定制化，这些值包括但不限于: friendly_name: 在 UI 中显示的名称 homebridge_name: 在 HomeBridge 中显示的名称 hidden: 是否在 HA 中隐藏实体，true 为隐藏，默认值为 false homebridge_hidden: 是否在 HomeBridge 中隐藏实体，true 为隐藏，默认值为 false emulated_hue_hidden: 是否在 emulated_hue 中隐藏实体，true 为隐藏，默认值为 false entity_picture: 指定一个图片的 url 与实体关联 icon: 从 MaterialDesignIcons.com(Cheatsheet) 选择的任何图标，前缀为 mdi:，示例值为 mid:home assumed_state: 为「开关」类别指定预设状态，如果设置为 false，将得到默认的开关图标，默认值为 true device_class: 实体类别，该值将决定 UI 的显示图标及状态，但不会影响测量单位，默认值为 None，暂时有以下实体支持该值: Binary Sensor: 具体参考 Binary Sensor Sensor: 具体参考 Sensor Cover: 具体参考 Cover unit_of_measurement: 测量单位，未指定测量单位的传感器将显示离散值，默认值为 None initial_state: 为自动化设置初始状态，on 或者 off 定制化特性可在配置目录的 customize.yaml 中指定1234light.yeelight_ct2_7c49eb1551e8: friendly_name: Lampsensor.yr_symbol: friendly_name: Wether HA 社区开发团队正在致力于实现通过 Web UI 来完成所有信息的配置，例如，Customize 的 UI 入口如下:]]></content>
      <categories>
        <category>Smart Home</category>
      </categories>
      <tags>
        <tag>smart-home</tag>
        <tag>home-assistant</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[智慧家庭 - 架设 HomeAssistant]]></title>
    <url>%2Fsmarthome-setup-ha-on-raspberrypi%2F</url>
    <content type="text"><![CDATA[参考资料: HA Installation on Docker HA Http HA Nginx 本文索引: Home Assistant 简介 前提条件 安装 Home Assistant 拉取 HomeAssistan Docker Image 开机启动 HA Container 更新 HA Home Assistant 简介Home Assistant(以下简称 HA) 是一个开源的智能家居网关项目，它可以将市面上所有支持的智能硬件设备整合到一起进行统一管理，并提供了默认的 Web UI。HA 社区开发了海量组件以支持市面上主流的设备，在 IoT 中扮演了大脑的角色。在家庭服务器上架设 HA 有多种实现方式，官方也制作了对应的系统镜像 Hass.io，并推荐使用「树莓派3B+」作为其宿主机器。 前提条件为了验证预期效果，最好提前准备好以下设备: 一台安装了 Raspbian 系统的树莓派 3B+，安装指南可参考「准备树莓派 3b+」 任何支持 HA 的智能设备一台，本文选用了 「Yeelight LED 智能灯」。 安装 Home Assistant通过 Docker Image 安装及更新一种服务免去了为该服务准备依赖环境的繁琐步骤，HA 官方推出了对应的 Docker Image 且支持树莓派的 CPU 架构，本文主要介绍通过 Docker 安装 HomeAssistant。如果你不喜欢 Docker，可以参考 Install Home Assistant 以其他方式安装。 拉取 HomeAssistan Docker Image使用 Docker 安装 HA 是非常简单的，官方提供了支持 Raspberry Pi 3 的 Docker Image 和「安装指南」:1$ docker run -d --name="home-assistant" -v /path/to/your/config:/config -v /etc/localtime:/etc/localtime:ro --net=host homeassistant/raspberrypi3-homeassistant 参数 /path/to/your/config:/config 映射 container 的 /config 至本地主机的物理路径，此处我选择了 ~/.homeassistant。如果希望安装指定版本的 Image，参考「HA 在 Docker Hub 上的 Tag 列表」选择版本，例如 0.69.1:12345678910111213141516171819202122232425262728293031$ docker run -d --name="home-assistant" -v ~/.homeassistant:/config -v /etc/localtime:/etc/localtime:ro --net=host homeassistant/raspberrypi3-homeassistantUnable to find image 'homeassistant/raspberrypi3-homeassistant:0.69.1' locally0.69.1: Pulling from homeassistant/raspberrypi3-homeassistant95d54dd4bdad: Pull complete72bf7d76c392: Pull complete9620ed938a4f: Pull completea16372392f2e: Pull completecd5a28710c58: Downloading [===================================&gt; ] 2.695MB/3.766MB9b376789f5cb: Downloading [====&gt; ] 1.49MB/16MB428cd24e8c1b: Download complete3e7ded663f3a: Downloading [=&gt; ] 45.59kB/2.24MB5ad200a39e9a: Waiting47c50281d4f4: Waiting34a35918edbb: Waitingff968d62969e: Waiting88d8e837fc65: Waiting0048f1b252d1: Waitingfe24e50f4c0c: Waiting8a894406a1f7: Waitingc521d5fa0262: Waitingb87db931bad3: Waitingfaa8f2005c47: Waiting0316d5cde9e4: Waitingaca6725ed6a1: Waiting# ...Docker 正从远程拉取所需的 image...Digest: sha256:76d8f1dee1d372fee469f688275854865e12ca662d4090800bb1a3ea5cefdf0fStatus: Downloaded newer image for homeassistant/raspberrypi3-homeassistant:0.69.1c360dbc77bede87b4eae2210d7b2df11c80f13a5acb227feaf53b3b8554ef2cd 安装完成后，HomeAssistant 的 container 已经开始运行:1234$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESc360dbc77bed homeassistant/raspberrypi3-homeassistant:0.69.1 "/usr/bin/entry.sh p…" 5 minutes ago Up 5 minutes home-assistant 查看刚刚指定的配置文件目录，出现了以下文件及目录:123456789101112$ ls -l .homeassistant-rw-r--r-- 1 root root 2 May 21 03:42 automations.yaml-rw-r--r-- 1 root root 1800 May 21 03:42 configuration.yaml-rw-r--r-- 1 root root 0 May 21 03:42 customize.yamldrwxr-xr-x 2 root root 4096 May 21 03:42 deps-rw-r--r-- 1 root root 0 May 21 03:42 groups.yaml-rw-r--r-- 1 root root 106 May 21 03:43 home-assistant.log-rw-r--r-- 1 root root 126976 May 21 04:11 home-assistant_v2.db-rw-r--r-- 1 root root 0 May 21 03:42 scripts.yaml-rw-r--r-- 1 root root 157 May 21 03:42 secrets.yamldrwxr-xr-x 2 root root 4096 May 21 03:43 tts config 目录(此处为 ~/homeassistant/)下的 configuration.yaml 是配置文件的入口点，其他由 yaml 为扩展名的配置文件均是为了实现独立管理而单独分离出来的文件，可在 configuration.yaml 文档中找到如下入口载入这些配置文件:1234customize: !include customize.yamlgroup: !include groups.yamlautomation: !include automations.yamlscript: !include scripts.yaml 8123 是 Web UI 的默认端口，尝试在浏览器中输入 http://{ip-address-to-raspberry}:8123 访问，得到如下结果: HA 会自动查找接入同一 wifi 网络中的智能设备，是因为 configuration.yaml 中默认配置了 Discovery 组件:12# Discover some devices automaticallydiscovery: 接入 HA 的设备无需打开相应的 App 进行绑定。 开机启动 HA Container一切正常之后，每次重启树莓派必须手动执行 docker container start [Container ID]/NAME 的方式来启动 HA 服务，我们需要将其做成服务或加入开机启动脚本，编辑 /etc/rc.local 文件:123$ sudo nano /etc/rc.localdocker container start home-assistant 该脚本文件具体可参考 RC.LOCAL 重启树莓派，HA 开机启动成功，至此，一个基本款的家庭 HA 搭建就完成了。 更新 HAHA 目前仍然在快速迭代中，对应的 Docker Image 也会同步放出。要更新以 Docker Container 运行的 HA 实例，只要重新拉取最新版本的 Image 即可:12345$ docker stop home-assistant$ docker pull homeassistant/raspberrypi3-homeassistant$ docker container rm home-assistant$ docker run -d --name="home-assistant" -v /path/to/your/config:/config -v /etc/localtime:/etc/localtime:ro --net=host homeassistant/raspberrypi3-homeassistant 只要保持 container 的 name 一致，已添加至开机启动脚本中的代码在更新完 Image 之后无需更改。]]></content>
      <categories>
        <category>Smart Home</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>raspberry-pi</tag>
        <tag>smart-home</tag>
        <tag>home-assistant</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过 DDNS 实现稳定内网穿透]]></title>
    <url>%2Fhomeserver-perform-ddns%2F</url>
    <content type="text"><![CDATA[本文索引: 内网穿透 实现原理 前提条件 实现 在路由器中配置端口转发 内网穿透ISP 运营商会为每户家庭宽带分配一个公网 IP 地址，位于互联网上的主机通过该 IP 地址，再由路由器映射到内网某台提供服务的主机上，就实现了内网穿透。然而，由于 ISP 运营商分配到家庭宽带的公网 IP 地址是动态变化的，那么每次公网 IP 地址变化之后都需要动手更改目标 IP 地址，才能继续访问家中的服务。DDNS(动态域名解析) 技术解决了这个问题。 实现原理通过在内网某台主机(本文以树莓派为例)上不断检测本地 WAN 的公共 IP 地址变化，并不断向指定的域名更新记录。这样，当从外网通过域名解析主机时，将始终指向同一个主机。 前提条件为了实现 DDNS，至少应该准备: 可远程管理的注册域名: 本文以阿里云万网域名为例 路由器具备端口转发功能 确保本地网络的公网 IP 可由外网访问，这一条主要是针对国内某些 ISP 将家庭宽带挂到某个大局域网下面，具体参见电信宽带的正确使用姿势 实现国内市场上有诸如花生壳，国外市场上有诸如 DuckDns 的 DDNS 服务商，他们为用户提供二级域名使用权和相应的客户端软件用以更新 DNS 记录。为了争取最大的自由度，本文将绕过第三方通过开源手段来实现。 假设我在阿里云(也可能是腾讯云，重要的是其提供相应的域名管理 API)注册了 example.com，阿里云负责提供全网都可访问该域名的 dns 服务。Git Clone 或下载 DDNS 至树莓派。 123$ git clone https://github.com/NewFuture/DDNS$ cd DDNS$ python ./run.py 详细使用方法参考 DDNS Github Repo。 在路由器中配置端口转发路由器没有能力或并不知道从外网入站的网络访问需要什么样的服务，它需要将入站请求转发至提供该种服务的内网主机，并映射相应的端口号。 由于众所周知的原因，国内 ISP 屏蔽了家庭网络的 80 及 443 端口，如果需要提供 http(s) 服务，需要选择其他端口。]]></content>
      <categories>
        <category>Home Server</category>
      </categories>
      <tags>
        <tag>network</tag>
        <tag>router</tag>
        <tag>ddns</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[电信宽带的正确使用姿势]]></title>
    <url>%2Fhomeserver-setup-isp-device%2F</url>
    <content type="text"><![CDATA[本文索引: 前言 获取光猫超级管理员权限 由光猫拨号改为路由器拨号 将电信光猫设为桥接模式 在路由器中设置拨号上网 确认公网 IP 地址正确可用 前言99 或 199 块钱一个月接入的电信宽带，除了其基础的 100M 或 300M 带宽上网之外，还可以做很多事 获取光猫超级管理员权限首先，将任意一台 PC 直连光猫 LAN 口，打开浏览器，输入 http://192.168.1.1 ，用 useradmin 账号登陆(密码位于光猫背面贴纸)。将地址栏中的连接 http://192.168.1.1/cgi-bin/content.asp 改为 http://192.168.1.1/cgi-bin/telnet.asp，进入如下的界面：勾选 Telnet 设置: 启用，点击确定。 接下来打开 Windows 的 cmd 或 MacOS 的 Terminal，以 telnet 连接光猫:123456$ telnet 192.168.1.1tc login:# 用户名 admin# 密码 1234 要求输入登录密码，其默认用户名和密码为 admin 和 1234，登录后输入以下命令:1$ cat /tmp/ctromfile.cfg 将打印出来的所有内容保存至本地本文编辑器，搜索 telecomadmin，找到对应行的密码行:123&lt;Entry0username="telecomadmin"web_passwd="&#123;password-for-telecomadmin&#125;"/&gt; web_passwd 即为 telecomadmin 用户的密码 由光猫拨号改为路由器拨号电信提供的光猫虽然已经自带路由功能，但出于商业目的，功能仍然极其有限，所以很多家庭都会购买单独的路由器，以实现更高级的功能，例如「内网穿透」、「全局科学上网」以及「自动下载机」等等。在此之前，我们希望路由器充当家庭网络的「网关」，以获取正确的公网 ip 地址。 将电信光猫设为桥接模式使用 telecomadmin 登录电信光猫:在「网络」-&gt; 「宽带设置」标签页，选定指定 Internet 的「连接名称」(此处为 5_INTERNET_B_VID_1025)，将「模式」由 Route 改为 Bridge:我们想要使用路由器作为 DHCP 的服务器，光猫仅仅负责传输宽带，保存更改后，把光猫的 LAN 口与路由器的 WAN 口相连，再把路由器的 LAN 接入任意 PC 的以太网口，此时路由器替代光猫成为了「网关」，默认情况下，网关的 ip 地址为 192.168.1.1，而 PC 会由路由器 DHCP 服务分配一个该网段下的 ip 地址，例如 192.168.1.200。 在路由器中设置拨号上网在浏览器中访问 192.168.1.1，此时访问的已是路由器厂商提供的 Web 管理界面了，进入到相应的页面，找到 WAN 口的设置，填入电信宽带上网用的用户名和密码: 如何设置无线网络此处不赘述 确认公网 IP 地址正确可用完成上一步操作之后，PC 应该已经可以正常上网了，在百度中输入 ip 得到一个公网 ip 地址，在路由器管理界面中，查看当前 WAN 口获取到的 ip 地址:从百度获取的 ip 地址是从外网检测到的 ip 地址，WAN 口的 ip 地址是由电信分配的 ip 地址，两者可能会不一样，WAN 口获取的 ip 地址可能是某个大区域的子网 ip 地址，虽然不影响上网，但无法实现「内网穿透」等功能。如果遇到类似情况，拨打 10000 号申诉通常都会解决。有了正确的公网 ip 地址，才能实施下一步的内网穿透功能。]]></content>
      <categories>
        <category>Home Server</category>
      </categories>
      <tags>
        <tag>network</tag>
        <tag>router</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在树莓派上构建 NAS 存储系统]]></title>
    <url>%2Fhomeserver-setup-nas-on-raspberry-pi%2F</url>
    <content type="text"><![CDATA[参考资料: R-Pi NAS Emergency Mode due to fstab 本文索引: 背景 准备工作 软件部分 硬件部分 传统方式架设 Samba 服务 更新本地包: 安装 Samba 服务 备份原始 smb.conf 文件 配置 smb.conf 创建用于访问 Samba 的用户 解决 Windows 系统下无法访问 Share 目录的问题 背景树莓派由于其能耗低、稳定性好的优点，非常适合跑 7*24 小时的长时服务，家庭 NAS 服务器是一个比较常见的需求，那么用树莓派来跑 NAS 服务再合适不过了。 准备工作要实现家庭 NAS 服务，硬件和软件设备都需要做准备。 软件部分软件部分指的是实现网络传输和共享的服务程序，可基于以下文件传输协议之一实现网络共享: SMB: Server Message Block NFS: Network File System FTP: File Transfer Protocol SFTP: Secure File Transfer Protocol 无论采用哪种协议进行文件共享，都需要有相应的软件服务的实现，本文采用实现了 SMB 协议的 Sabma 服务。 硬件部分NAS 存储系统主要依赖于高容量的附加存储设备(即硬盘)，可以依据自己的需求投入相应的成本，或直接使用树莓派本身的 SD 卡存储。楼主使用了从旧笔记本电脑上拆机所得的两块硬盘，再买了一个硬盘阵列盒组了个 RAID 1 实现，其中涉及到的硬件有: 2.5 英寸 500GB HDD * 2 2.5 英寸双盘位磁盘阵列盒 * 1 当然，可以仅使用一块硬盘 + 外置硬盘盒实现，树莓派本身没有 SATA 口，只能通过 USB 接入外置硬盘，并且目前最新的 3b+ 型号上仍然是 USB2.0 接口。 传统方式架设 Samba 服务为简单起见，以演示 Samba 服务搭建为目标，本文以 home/pi/downloads 为目标共享目录作为演示，挂载外接存储设备可参考这里。 更新本地包:树莓派 Raspbian 系统的镜像已经包含了 Samba 的包，执行:1$ sudo apt update 安装 Samba 服务执行以下命令将安装 Samba 服务及其依赖的所有程序:1$ sudo apt install samba samba-common-bin 备份原始 smb.conf 文件安装完成后，使用 root 用户权限编辑 /etc/samba/smb.conf 来配置服务，但在此之前，先备份原始配置文件:1$ sudo cp /etc/samba/smb.conf /etc/samba/smb.conf.default 配置 smb.conf使用喜欢的文件编辑器(树莓派内置了 nano)打开配置文件，并在文件的最下方插入以下内容:12345678910[Share]Comment = Pi shared folderPath = /pi/home/downloadsBrowseable = yesWriteable = Yesonly guest = nocreate mask = 0777directory mask = 0777Public = yesGuest ok = yes 这表示可通过以 Samba 用户(见下文)或 Guest 身份读取、写入、或执行 /mnt/shared 目录下的内容，如果不想允许 Guest 身份访问，注释掉 Guest ok 一项即可。 关于 smb.conf 的更多选项可自行参考这里 希望在 Windows 系统的网络(Network)下看见树莓派主机，需要设置 [global] 节点下的 wins support = yes 执行 testparm 以检查刚刚的更改没有造成错误:1234567891011121314151617181920212223242526$ testparm[global] log file = /var/log/samba/log.%m max log size = 1000 syslog = 0 panic action = /usr/share/samba/panic-action %d usershare allow guests = Yes map to guest = Bad User obey pam restrictions = Yes pam password change = Yes passwd chat = *Enter\snew\s*\spassword:* %n\n *Retype\snew\s*\spassword:* %n\n *password\supdated\ssuccessfully* . passwd program = /usr/bin/passwd %u server role = standalone server unix password sync = Yes dns proxy = No wins support = Yes idmap config * : backend = tdb [Share] comment = Pi shared folder path = /mnt/shared create mask = 0777 directory mask = 0777 guest ok = Yes read only = No 创建用于访问 Samba 的用户多数情况下，我们不希望任何人在不认证的情况下就随意访问局域网内的 Samba 服务，但又不想为此创建专门的用户帐户(这将增加管理成本)，可告知 Samba 对已有 UNIX 用户授权并设置专属于 SMB 的密码:1234$ sudo smbpasswd -a piNew SMB password:Retype new SMB password: 接下来，重启 Samba 服务:12345$ sudo /etc/init.d/samba restartor$ sudo systemctl restart smbd.service 解决 Windows 系统下无法访问 Share 目录的问题由于使用 pi 用户作为访问共享目录的凭证，但 Windows 系统会默认以当前登录 Windows 的本地帐号作为访问共享目录的用户，这会导致无法访问共享目录。为了解决这个问题，需要清除 Windows 记住的网络共享目录的登录凭证。 查看 Windows 当前记住的所有网络共享主机映射，Windows 针对单个 host 记录一条映射: 1234567$ net use Status Local Remote Network-------------------------------------------------------------------------------OK \\192.168.1.140\Share Microsoft Windows NetworkOK \\raspberrypi3b\share Microsoft Windows Network 清除这些映射记录: 12345678910$ net use * /dYou have these remote connections: \\192.168.1.140\Share \\raspberrypi3b\shareContinuing will cancel the connections.Do you want to continue this operation? (Y/N) [N]: yThe command completed successfully. Win + E 在 Explorer 中映射网络驱动器，并在弹出的认证对话框中输入先前创建的 pi 帐号及密码:]]></content>
      <categories>
        <category>Home Server</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>raspberry-pi</tag>
        <tag>nas</tag>
        <tag>samba</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[路由器基础服务详解 - DHCP, DNS, NAT]]></title>
    <url>%2Fhomeserver-router-basic-services%2F</url>
    <content type="text"><![CDATA[本文索引: 前言 DHCP DNS NAT 前言大多数家庭网络，通过一个家庭网关将本地局域网(LAN - Local Area Network，下称 LAN)与广域网(WAN - Wide Area Network，下称 WAN)连接起来，本篇文章将介绍实现这一功能涉及到的一系列软件和硬件基础设施。 家庭网关通常指间于广域网和局域网起桥梁作用的设备:我们最熟悉的家庭网关设备就是路由器，其最基本的功能，是在 LAN 和 WAN 之间路由数据。但在多数时候，它还兼顾了其他对 LAN 有用的功能: DHCP: 提供 LAN 主机 IPv4 地址的服务 DNS: 响应 LAN 主机的名称查询 NAT(Network Address Translation): 将公网 IPv4 地址映射至 LAN 主机 IPv4 地址 DHCPDHCP(Dynamic Host Configuration Protocol) 是一种用于动态分配 IP 地址至 LAN 主机的协议。它为家庭主机用户或网络管理员省去了手动为每台主机配置 IP 地址的工作。同时，它维护一个 IP 地址池，当一台主机与 LAN 断开连接，它之前占用的 IP 地址将回到该池，并在有新的设备连接至 LAN 时重新分配。以 DHCP 获取 IP 地址的过程包含 4 个阶段，其被称为 DORA - discovery, offer, request 和 acknowledgement。如下图所示: 首先，客户主机广播一条 DHCP DISCOVER 消息 DHCP 服务器收到此消息，以一条 DHCP OFFER 单播消息回应，该消息包至少包含一个可用的 IP 地址，或包含网关地址和 DNS 服务器地址。如果 LAN 中有多个 DHCP 服务器，客户主机可能收到多条 OFFER 消息。 客户主机用一条 DHCP REQUEST 消息回复一条 OFFER 消息，该 REQUEST 消息将在 LAN 中广播，如果有其他 DHCP 服务器也发布过 OFFER 消息，在接收到此条 REQUEST 消息后将视为该客户主机已拒绝该 OFFER。 收到 REQUEST 消息的 DHCP 服务器将以一条 ACK 消息发布确认信息。 上述 4 个步骤完成之后，客户主机将被分配一个带有有效期的 IP 地址，在 IP 地址过期之后，客户主机将以一定间隔发布 REQUEST+ACK 消息以续期该 IP 地址。当客户主机与 LAN 断开连接时，将会发送一条 RELEASE 消息以告知 DHCP 服务器放弃该 IP 地址的使用。 通常，家庭网关设备会内置 DHCP 服务，并允许用户指定可分配 IP 地址的范围以及其他一些选项: DNS网络中的主机需要以阅读友好的名称来区分它们，而不是通过 IP 地址(IP 地址太难让人记住)，DNS(Domain Name System) 是一个存储名称 - IP 地址映射记录的系统，并提供查询功能(域名解析)。 许多家庭网关设备同时扮演了 DNS 服务器的角色，用以家庭主机以域名形式定位其他主机的 IP 地址。DNS 服务器同时支持递归查询，这意味着本地 DNS 服务器可链接上游 DNS 服务器，形成递归链。DNS 查询从链中第一个节点开始查找，找不到则查询下一个节点，直到找到或链的尾端。DNS 的解析也以 . 分割进行渐进式查找，假设 LAN 中的主机想要获取 witestlab.poly.edu 域名的 IP 地址。 所有的 DNS 域名在最后都有一个 .，但即便省略该 .，DNS 解析者也能够工作 下图展示了整个过程: LAN 中的 DNS 服务器并没有在本地存储 witestlab.poly.edu 的域名映射记录，则将其委托至上游 DNS 服务器 上游 DNS 服务器从最右边开始解析 witestlab.poly.edu，找到负责解析 . 的根 DNS 服务器 根 DNS 服务器不知道 witestlab.poly.edu 的映射记录，但它会回复一个能够解析 .edu(顶级域名) 的 DNS 服务器列表 .edu DNS 服务器也不知道 witestlab.poly.edu 的映射记录，但它会回复一个能够解析 poly.edu(二级域名) 的 DNS 服务器列表 最终，负责解析 poly.edu 的 DNS 服务器知道 witestlab.poly.edu 的映射记录，并最终返回期望的 IP 地址 因此，任何知道根 DNS 服务器地址的 DNS 服务器最终都能找到对应域名的映射记录(除非本身记录不存在)。 在上述例子中，域名服务器所存储的映射记录如下图所示: NAT家庭网关另一个常见的功能是 NAT(Network Address Translation)。NAT 通过修改穿越网关数据包头部信息将 IP 地址空间映射到另一个 IP 地址空间。由于全局公网 IPv4 地址稀缺，不可能为 LAN 中的每一台主机分配一个公网 IPv4 地址。相反，ISP(Internet Service Provider) 仅将为家庭网络分配一个公网 IPv4 地址。LAN 中的主机将使用一个私有的 IP 地址空间，如 192.168.0.0/16 空间。然而，这些地址无法在直接广域网中路由，因此 NAT 一个常见的功能是映射 LAN 中私有 IP 地址至该公网 IPv4 地址。这样，由 LAN 中主机发起或接收的流量就可被路由至广域网。 下图展示了 NAT 网关如何通过修改数据包头部信息来实现这一功能: LAN 中的主机发起一个指向 WAN 中主机的网络连接，该连接会穿越 NAT 网关。开始发送数据包后，这些数据包的原始 From 地址为 LAN 中的私有 IP 地址。 NAT 网关在其翻译表中添加一条新记录，记下 LAN 主机 IP 地址、TCP 端口号、并尝试在 NAT 主机中开放相同的 TCP 端口并记下，如果该端口已经被占用，则尝试其他端口。 当数据包穿越 NAT 网关时，NAT 根据翻译表中的记录，修改数据包的头部信息，将其 From 地址和端口号分别替换为公网 IPv4 地址及记录中的端口号。所以，当数据包实际抵达目标 WAN 主机时，该主机实际收到的是其公网 IP 及家庭网关设备对应的 TCP 端口号 当远程 WAN 主机回发数据包至 NAT 网关，NAT 检查数据包头部信息中的 Destionation Port，再与翻译表中存储的记录比对，提取该条记录对应的 LAN 主机 IP 地址 NAT 再次修改入站数据包头部信息的 Destionation IP 地址及端口号，最终成功完成数据包的转发。 NAT 仅服务于出站的新网络连接，如果网络连接直接由 WAN 主机发起，但 NAT 维护的翻译表中找不到任何匹配的记录，那么所有数据包将被丢弃。因此，位于 NAT 网关之后的设备无法接收来自 WAN 主机的网络连接。 想要 WAN 主机主动对位于 NAT 网关之后的主机发起连接，可以借助端口转发(Port Forwarding)。很多家庭网关设备同样内置了该功能，下图展示了一个端口转发的案例: 假设家庭网络的公网 IPv4 地址为 128.238.66.220，处于 WAN 中的任何主机都可以对该 IP 地址主动发起连接，并使用 TCP 端口 443。NAT 将检查端口转发表以定位 LAN 主机的 IP 地址，同样修改数据包的头部信息。]]></content>
      <categories>
        <category>Home Server</category>
      </categories>
      <tags>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网件路由器刷 OpenWrt]]></title>
    <url>%2Fhomeserver-install-openwrt-on-router%2F</url>
    <content type="text"><![CDATA[本文索引: 前言 检查兼容性 安装固件 通过 TFTP 的方式安装 通过网件 OEM 方式安装 配置 OpenWrt 安装 USB 驱动 启用 SMB 服务 前言路由器是家庭网络必不可少的基础设施，而路由器运行的系统也决定了家庭网络功能的边界。OpenWrt 是一个开源的路由器项目 检查兼容性 OpenWrt 项目官网 至这个页面查看支持的设备 定位到对应路由器设备页面，本文以 Netgear WNDR 4300 为例，注意安装和升级是两个文件 安装固件新版的镜像在 GUI 方面做了很大的改进，几乎所有设置都可以通过在 Web UI 上完成。 通过 TFTP 的方式安装 关闭路由器电源 为本机预设一个固定的 ip 地址，例如 192.168.1.35，用网线连接至路由器 打开路由器电源 当 LED 灯亮起时，按住 RESET 按钮 保持 RESET 按钮按住，直至「电源 LED 灯」由闪烁「黄灯」变为闪烁「绿灯」 执行 tftp 流转:1$ tftp -i 192.168.1.1 PUT ./openwrt-18.06.1-ar71xx-nand-wndr4300-ubi-factory.img PUT 之后的参数跟 image 的路径 通过网件 OEM 方式安装 使用网线连接至路由器，并在浏览器中输入 http://192.168.1.1 导航至 Advanced -&gt; Administration -&gt; Firmware Upgrade 上传 OpenWrt 固件 openwrt-18.06.1-ar71xx-nand-wndr4300-ubi-factory.img，点击开始 等待安装完成 安装完成之后，可能需要重启一次才能正常访问 192.168.1.1 配置 OpenWrt 导航至 192.168.1.1，使用 root(密码为空)，登录页面，修改一个 root 的密码 导航至 System -&gt; System，为路由器主机换一个名字，并更改为对应的时区: 将光猫用网线连接路由器的 WAN 口，导航至 Network -&gt; Interface，编辑 WAN: 使用路由器进行拨号上网，在 Protocol 一栏选择 PPPoE 点击 Switch protocol 确认操作 填写由 ISP 分配的账号与密码: 完成之后点击 Save &amp; Apply 导航至 Network -&gt; Wireless，设置 2.4 GHz 及 5 GHz 的无线网络 接下来，便可开始对路由器针对性的配置诸如 DDNS，端口转发等功能的配置了。 安装 USB 驱动See Installing and troubleshooting USB Drivers and Using storage devices 启用 SMB 服务See SMB Samba share overview (aka Windows file sharing)]]></content>
      <categories>
        <category>Home Server</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>openwrt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mediator 模式及其 .NET 实现]]></title>
    <url>%2Farchitecture-mediator-pattern%2F</url>
    <content type="text"><![CDATA[参考资料: Mediator pattern Simplifying Development and Separating Concerns with MediatR MediatR 中间人模式简介在软件工程层面，中间人模式定义了封装不同对象之间的交互方式。在应用系统中，随着业务体量的逐渐增大，不同对象之间的通信变得越来越复杂，这使得应用程序难以阅读及维护。中间人模式将对象之间的「通信(或交互)」封装至单独的「中间人(Mediator)」对象中，对象之间通过「中间人」进行通信，而不再直接交互。这减少了拟交互对象之间的依赖，进而降低了系统内部各组件之间的耦合。 定义中间人模式的要点，在于封装拟交互对象群间关系，拟交互类型通过「中间人」将消息发送至其他拟交互类型，并同时从其他拟交互类型接收消息。 案例在 MVC 项目中，应用层的 Controller 通常以 DI 的方式依赖其他组件，例如，我们经常看到如下的 Controller:123public DashboardController( ICustomerRepository customerRepository ) 一开始，这种实现并无不妥，但随着业务规则越来越复杂，它很快便会成长为:12345678910public DashboardController( ICustomerRepository customerRepository, IOrderService orderService, ICustomerHistoryRepository historyRepository, IOrderRepository orderRepository, IProductRespoitory productRespoitory, IRelatedProductsRepository relatedProductsRepository, ISupportService supportService, ILog logger ) 也许有人看到这段代码会觉得 Controller 承担了太多职责，于是开始思考应该将这些职责转移到更适合的下层组件当中去。然而，无论这些依赖存在于哪个组件都显得太臃肿了，因为它显式依赖了这些对象(无论是具体类型还是抽象类型)。 为了解决这个问题，我们引入中间人模式，让所有依赖其他对象进行交互的类型转而引用中间人类型，使得耦合度大大降低:123public DashboardController( IMediator mediator ) 签名看上去清爽多了，但实际的通信和交互应该如何实现呢？让我们看看如何将一个简单的命令通过 MediatR 应用在真实的项目中。 MediatR 类库MediatR 是 .NET 生态中实现「中间人」模式的轻量级类库，支持 Request/Notification 两种通信方式，在编码实现上支持同步/异步编程模型，我们以一个 ASP.NET Core 项目为例来演示如何实现这一过程，关键步骤为: 通过 Nuget 添加对 MediatR 的项目引用 创建 Request/Notification 对象 创建处理 Request/Notification 的 Handler 对象 在应用层中注册 IMediator 和 ServiceFactory 委托按照 MediatR Wiki， IMediator 使用 ServiceFactory 委托创建所需的 Handler 类型实例、Pipiline 行为和 pre/post 处理器。它们的服务类型及实现类型需要在应用层中进行注册，添加 Autofac.Extensions.DependencyInjection 库的引用:12345678910111213141516public IServiceProvider ConfigureServices(IServiceCollection services)&#123; services.AddAutofac(); var builder = new ContainerBuilder(); builder.Populate(services); builder.RegisterAssemblyTypes(typeof(IMediator).Assembly).AsImplementedInterfaces(); builder.RegisterAssemblyTypes(typeof(Startup).Assembly).AsImplementedInterfaces(); builder.Register&lt;ServiceFactory&gt;(ctx =&gt; &#123; var context = ctx.Resolve&lt;IComponentContext&gt;(); return type =&gt; context.Resolve(type); &#125;); var container = builder.Build(); return new AutofacServiceProvider(container);&#125; 上述代码的关键两行为 builder.RegisterAssemblyTypes(typeof(IMediator).Assembly).AsImplementedInterfaces(): 将 IMediator 接口的默认实现以单例模型注册至服务容器 builder.Register&lt;ServiceFactory&gt;(ctx =&gt;: 定义 ServiceFactory 委托的实现，该委托旨在提供在运行时解析类型的实现 创建实现 IRequest/INotification 接口的类型接下来，创建一个实现了 IRequest 接口的类型，该类型代表某个希望完成的工作:12345public class AddEmergencyContactCommand : IRequest&#123; public string Contact &#123; get; set; &#125; public string UserId &#123; get; set; &#125;&#125; 该类型仅包含一些 payload 属性，理论上可以在 Request 对象中定义任何需要发送至 Mediator 的载荷数据——基元类型或复杂类型都支持。 创建处理对应 Request/Notification 的 Handler 的类型Handler 类型继承自 RequestHandler&lt;TRequest&gt; 类型，并重写了 Handle 方法。Mediator 将确保 Handle 方法传入期望的 Request 对象。1234567public class AddEmergencyContactHandler : RequestHandler&lt;AddEmergencyContactCommand&gt;&#123; protected override void Handle(AddEmergencyContactCommand request) &#123; Console.WriteLine($"Emergency contact added: &#123;request.Contact&#125; by &#123;request.UserId&#125;."); &#125;&#125; Handler 类型可通过 DI 访问其他类型的引用以确保完成命令操作。Command 的发起者(本例中为 Controller)将不再关心执行该命令要依赖哪些对象，仅需知道要发起何种命令:1234567891011[HttpPost]public IActionResult AddEmergencyContact(string userId, string contact)&#123; if (ModelState.IsValid) &#123; var command = new AddEmergencyContactCommand &#123; Contact = contact, UserId = userId &#125;; _mediator.Send(command); return Ok(); &#125; return BadRequest();&#125; Controller 的 Post 方法中，组装了 AddEmergencyContactCommand 对象，并通过调用 Mediator.Send() 方法发送命令。Mediator 对象将确保调用栈的下一步指向对应的 AddEmergencyContactHandler 类型并将 AddEmergencyContactCommand 作为参数传入其 Handle 方法。类型的解析委托正是前文在 Startup.ConfigureServices 方法中定义的 ServiceFactory。 使用一对多的处理方式 - NotificationRequest 模拟了一对一的靶向操作，而 Notification 则模拟了一对多的发布/订阅操作。与 Request 类似，首先需要定义通知消息:1234public class ContactAddedNotification : INotification&#123; public string Contact &#123; get; set; &#125;&#125; 接下来，定义两个消费该通知消息的 Handler 类型:1234567891011121314151617public class ContactAddedPong1 : INotificationHandler&lt;ContactAddedNotification&gt;&#123; public Task Handle(ContactAddedNotification notification, CancellationToken cancellationToken) &#123; Debug.WriteLine($"&#123;nameof(ContactAddedPong1)&#125; Received &#123;nameof(ContactAddedNotification)&#125;, contact: &#123;notification.Contact&#125;."); return Task.CompletedTask; &#125;&#125;public class ContactAddedPong2 : INotificationHandler&lt;ContactAddedNotification&gt;&#123; public Task Handle(ContactAddedNotification notification, CancellationToken cancellationToken) &#123; Debug.WriteLine($"&#123;nameof(ContactAddedPong2)&#125; Received &#123;nameof(ContactAddedNotification)&#125;, contact: &#123;notification.Contact&#125;."); return Task.CompletedTask; &#125;&#125; 基于前文的 Request 的案例，发布通知，修改代码如下:1234567891011121314151617181920public class AddEmergencyContactHandler : AsyncRequestHandler&lt;AddEmergencyContactCommand&gt;&#123; private readonly IMediator _mediator; public AddEmergencyContactHandler(IMediator mediator) &#123; this._mediator = mediator; &#125; protected async override Task Handle(AddEmergencyContactCommand request, CancellationToken cancellationToken) &#123; Debug.WriteLine($"Emergency contact added: &#123;request.Contact&#125; by &#123;request.UserId&#125;."); var notification = new ContactAddedNotification &#123; Contact = request.Contact &#125;; await this._mediator.Publish&lt;ContactAddedNotification&gt;(notification); &#125;&#125; IMediator 使用 Publish 方法来发布通知。上述代码同时将原来继承的 RequestHandler 替换成了 AsyncRequestHandler 以支持异步编程模型。 需要指出的是，Mediator 只是在编码级别做了类似「消息队列」的工作，实际的调用序列依然是同步的，Mediator 关注的重点在于「解耦」，而非「异步」。 本 Sample 的源代码可至 Github 下载。]]></content>
      <categories>
        <category>Architecture and Pattern</category>
      </categories>
      <tags>
        <tag>architecture</tag>
        <tag>dotnet</tag>
        <tag>mediator-pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为 ASP.NET Core 应用程序添加 Docker 支持]]></title>
    <url>%2Faspnetcore-host-in-docker-containers%2F</url>
    <content type="text"><![CDATA[参考资料 Building Docker Images for .NET Core Applications Visual Studio Tools for Docker with ASP.NET Core 微软提供的 Docker Image微软为 ASP.NET Core 开发人员提供了三种官方 Docker Image: Development: 快速迭代和调试更改，以大尺寸的 Image 换取开发的便利 Build: 包含所有用于生成应用的依赖和库，如编译器和其他优化编码的工具，开发人员使用该 Image 创建最终要放置在 Production 环境下的 Image 所需的资产，该 Image 主要用于持续集成。这样的好处在于使得生成工具仅仅需要知道如何运行该 Image，而不用关心其他细节。 Production: 用于生产环境运行的 Image，体积经过了优化，因而在多 Host 部署时节省了网络通信时间，所有位于该 Image 中的内容都是为最优化运行应用程序而准备的。 Docker Image 命名规则 microsoft/dotnet:&lt;version&gt;-sdk: 该 Image 包含了 .NET Core SDK，其中包含 .NET Core 和 CLI，该 Image 用于支持上述 Development 和 Build 使用场景。另外，microsoft/dotnet:sdk 表示获取最新版本的 Image。 microsoft/dotnet:&lt;versuib&gt;-runtime: 该 Image 包含 .NET Core(运行时和类库)并对运行 .NET Core 应用程序做了优化，对应于上述 Production 的使用场景。 其他 Image除了上述三种 Image 之外，微软还提供了一些用于特殊用途的 Image，如 microsoft/dotnet:&lt;version&gt;-runtime-deps: runtime-deps 包含了 .NET Core 依赖的操作系统本地库，这种 Image 主要用于 Self-Contained 应用程序。 各个 Image 的最新版本: microsoft/dotnet 或 microsoft/dotnet:latest: SDK Image 的别名 microsoft/dotnet:sdk microsoft/dotnet:runtime microsoft/dotnet:runtime-deps 开始第一个 ASP.NET Core Docker App准备工作 安装 .NET Core SDK 2.0 安装一个喜欢的代码编辑器，例如 Visual Studio(Code)。 安装 Docker CE for Windows 安装 Git 获取示例项目首先选取一个工作目录，然后执行:1$ git clone https://github.com/dotnet/dotnet-docker-samples/ 克隆完成后，进入 aspnetapp 目录，执行 dotnet run，在容器化应用程序之前，首先确保该应用程序能够运行。123456$ cd aspnetapp$ dotnet runHosting environment: ProductionContent root path: D:\Development\Git Repositories\Github Projects\dotnet-docker-samples\aspnetappNow listening on: http://localhost:5000 确认 dotnet run 正常后，改用 docker 生成并运行:1234567cd aspnetapp$ docker build -t aspnetapp . # 生成 Docker Image 并将其 tag 为 aspnetapp$ docker run -it --rm -p 5000:80 --name aspnetcore_sample aspnetappSuccessfully built 8fb665ff9690Successfully tagged aspnetapp:latest Docker 的端口映射为 host:container 现在访问 http://{your-host-ip-address}:5000 便可得到示例应用程序的页面。 Visual Studio Docker 工具集为应用程序添加 Docker 支持要使 ASP.NET 与 Docker 集成，该项目必须是 .NET Core 项目，Linux 和 Windows 两种类别的容器都支持。ASP.NET Core 项目的 Container 类型必须与本机 Docker 引擎运行的 Container 类型相同。可通过在任务栏图标上右键单击 Docker 图标 -&gt; Switch to Windows containers 或 Switch to Linux containers 功能来进行切换。 创建新的应用程序对于新创建的 ASP.NET Core 项目，勾选 Enable Docker Support，并选择一个 Docker Container 类型: 为现有项目添加 Docker 支持Visual Studio 仅支持为 .NET Core 项目添加 Docker 支持，有两种方式，首先打开一个项目 选择 Project 菜单 -&gt; Docker Support 右键单击项目 -&gt; 添加 -&gt; Docker Support Visual Studio Docker 概览当对一个项目添加 Docker 支持后，VisualStudio 将项解决方案目录添加一个 docker-compose.dcproj 项目，其中包含: .dockerignore: 生成 build 时需要忽略的文件和目录匹配字段 docker-compose.yml: Docker Compose 的定义文件，定义了一系列 Image 的集合用于 docker-compose build 和 docker-compose run。 docker-compose.override.yml: 一个可选文件，也会被 Docker Compose 读取，包含需要对服务进行重写的配置信息。Visual Studio 执行 docker-compose -f &quot;docker-compose.yml&quot; -f &quot;docker-compose.override.yml&quot; 来合并这些文件 同时，ASP.NET Core 项目文件夹下自动生成了一个名为 Dockerfile 的文件，该文件起始包含 4 个单独的生成环节，其根据 Docker multi-stage build 定义，内容如下:dockerfile12345678910111213141516171819FROM microsoft/aspnetcore:2.0 AS baseWORKDIR /appEXPOSE 80FROM microsoft/aspnetcore-build:2.0 AS buildWORKDIR /srcCOPY AspDotNetCoreDocker/AspDotNetCoreDocker.csproj AspDotNetCoreDocker/RUN dotnet restore AspDotNetCoreDocker/AspDotNetCoreDocker.csprojCOPY . .WORKDIR /src/AspDotNetCoreDockerRUN dotnet build AspDotNetCoreDocker.csproj -c Release -o /appFROM build AS publishRUN dotnet publish AspDotNetCoreDocker.csproj -c Release -o /appFROM base AS finalWORKDIR /appCOPY --from=publish /app .ENTRYPOINT ["dotnet", "AspDotNetCoreDocker.dll"] 该 Dockerfile 基于 microsoft/aspnetcore Image，该 Image 包含了所有与 ASP.NET Core 相关的 Nuget 包。查看 docker-compose.yml 文件，其中包含了自建 Image 的名称:docker-compose.yml12345678version: '3.4'services: aspdotnetcoredocker: image: frosthe/aspdotnetcoredocker build: context: . dockerfile: AspDotNetCoreDocker/Dockerfile 在这个例子中，如果应用程序以 Debug 模式运行，aspdotnetcoredocker Image 会生成 aspdotnetcoredocker:dev，以 Release 模式运行时，会生成 aspdotnetcoredocker:latest Image。 Image 的名称通常以 Docker Hub 的用户名作为前缀(此处为 frosthe)。也可以自建 Registry 来承载私有的 Image。 调试在 Debug 模式下按下 F5，同时查看 Visual Studio 的输出窗口，其步骤如下: microsoft/aspnetcore: 获取 aspnet core runtime Image。 microsoft/aspnetcore-build: 获取编译/发布 Image。 ASPNETCORE_ENVIRONMENT: Container 内环境变量设置为 Development。 Container 暴露 80 端口了并映射到了主机的动态端口，该动态端口由 Docker 主机决定，可通过 docker ps 来查询。 应用程序被复制到了 Container 中 默认浏览器被打开，并通过动态端口将调试器附加到了 Container 中。 完成后执行 docker images 可以看到生成好的 aspdotnetcoredocker:dev Image 和 microsoft/aspnetcore Image。123REPOSITORY TAG IMAGE ID CREATED SIZEfrosthe/aspdotnetcoredocker dev bf575b94e1c2 2 weeks ago 345MBmicrosoft/aspnetcore 2.0.5 b1a5de255274 3 months ago 305MB 执行 docker ps 可以看到正在运行的 container。12CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESf92786da06e1 frosthe/aspdotnetcoredocker:dev "tail -f /dev/null" 52 seconds ago Up 50 seconds 0.0.0.0:32768-&gt;80/tcp dockercompose3863187778964625453_aspdotnetcoredocker_1 编辑并继续与传统 .NET 程序的调试一样，针对静态文件和 Razor 视图的更改都将实时更新，而无需重新编译，但针对源代码的修改，则需要重新编译并重启 Kestrel 服务器，这都在 Container 中完成。 发布 Docker Image一旦开发和调试完成，需要首先将配置切换至 Release，然后生成应用程序，Docker 工具集会生成一个新的打上 latest 标签的 Image，最后可将该 Image 上传至私有仓库或 Docker Hub。]]></content>
      <categories>
        <category>ASP.NET Core</category>
      </categories>
      <tags>
        <tag>aspnet-core</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 初探 (7) - 部署]]></title>
    <url>%2Fdocker-deployment%2F</url>
    <content type="text"><![CDATA[参考资料: Deploy your app Use the Docker Cloud Agent The Docker Cloud CLI Docker CloudDocker Cloud 提供了 image 托管，持续集成和集群部署等服务，之前已经使用 Docker ID 登录过 Docker Cloud 并上传 image。使用 Docker Cloud 在云服务提供商的虚拟主机上部署和运行 app 是官方推荐的做法，要实现这一点，需要: 将 Docker Cloud 连接至偏好的云服务提供商，并对 Docker Cloud 赋予适当的权限以自动容易化这些虚拟主机 使用 Docker Cloud 创建计算资源和创建集群 部署应用 Docker Cloud 提供了与亚马逊 AWS 和 微软 Azure 的自动集群部署服务，但其他云服务商需要自行在 Docker Cloud UI 上手动操作，文本介绍手动进行部署的路径。 Docker Cloud AgentDocker Cloud 允许使用任何 Linux 发行版的系统来部署 container，但要在这些 Linux 主机上安装 Docker Cloud Agent 才能对它们进行远程管理。 Docker Cloud Agent 目前仅支持 x64 架构。 Docker Cloud Agent 会将所有需要的包都安装好，并自动移除任何现有的 Docker 引擎。之后仍然可以在这些主机上执行 docker 命令，但会多出一些以 dockercloud/ 开头的运行的系统 container。 通过 Docker Cloud 网页界面安装 Docker Cloud Agent 开始安装之前，请确保目标主机上的 TCP/UDP 6783 端口: 允许该节点加入 Docker Cloud 账号下所有节点组成的叠加网络以支持服务发现 TCP 2375 端口: 允许 Docker CLoud 与目标主机的 Docker 守护进程直接通过 TSL 认证进行通信，如果该端口未开启，Docker Cloud 会让目标主机建立一个反向隧道以访问该端口。 登录 Docker Cloud，导航至节点仪表盘(Nodes)。 点击 Bring your own node。弹出窗口会展示目前支持的所有 Linux 发行版本并生成一行包含 token 的命令以使主机上的 Docker Cloud Agent 与 Docker Cloud 通信。 在目标 Linux 主机上执行该命令，该命令会下载一个脚本，安装并配置好 Docker Cloud Agent，最后将其注册到 Docker Cloud。 12345*******************************************************************************Docker Cloud Agent installed successfully*******************************************************************************You can now deploy containers to this node using Docker Cloud 当出现以上提示之后，关闭弹出框，刷新节点仪表盘，发现该主机已经与 Docker Cloud 关联: 该主机现在已经准备好部署了。 通过 CLI 安装 Docker Cloud Agent也可以借助 docker-cloud 命令来安装 Docker Cloud Agent，这种方式对熟悉命令行工具的同学来说更明白发生了什么，首先，需要在目标主机上安装 docker-cloud CLI，参考The Docker Cloud CLI可以不同的方式安装。 使用 python pip 安装 docker-cloud CLI:1$ pip install docker-cloud 使用以下命令取得一个节点的 token:12345678$ docker-cloud node byoDocker Cloud lets you use your own servers as nodes to run containers. Forthis you have to install our agent.Run the following command on your server:curl -Ls https://get.cloud.docker.com/ | sudo -H sh -s 63ad1c63ec5d431a9b31133e37e8a614 执行上述代码将下载一段脚本，安装并运行 dockercloud-agent 服务，然后在配置文件中设置 token，该 token 有一定的时限，服务向 Docker Cloud 进行注册，并开始下载 docker 引擎:12342018/05/11 20:18:34 Registering in Docker Cloud via PATCH: https://cloud.docker.com/api/agent/v1/node/d4289a2e-4a98-4767-b9c8-8c67b24a2ca32018/05/11 20:18:34 Downloading docker binary...2018/05/11 20:18:34 Downloading docker definition from https://cloud.docker.com/api/tutum/v1/agent/docker/1.11.2-cs5/1.1.0.json2018/05/11 20:18:34 Downloading docker from https://files.cloud.docker.com/packages/docker/docker-1.11.2-cs5.tgz 该过程由网络带宽决定耗时长短，下载过程中 Docker Cloud 会一直打印 docker 端口未开启:12Waiting for docker port to be open...Waiting for docker port to be open... 这是因为 docker 引擎还未在目标主机上就绪，无法找到端口 2375，由于笔者的云服务器只有 1Mbps 的带宽，下载该包的时间超过了 Docker Cloud 的超时时间，于是造成 Docker Cloud 等待超时，在 docker 包下载完成后，尝试重新启动 dockercloud-agent 服务，而由于 token 又过期了，所以只能重新申请 token 并设置配置文件:123Cannot register node in Docker Cloud: unauthorized. Please try again with a new token.$ docker-cloud node byo 取得新的 token 后，需要修改配置文件中的 token 值，重新启动服务。12$ dockercloud-agent set Token=xxx$ sudo service dockercloud-agent restart 卸载 Docker Cloud Agent12$ apt-get remove dockercloud-agent$ rm -rf /etc/dockercloud 升级 Docker Cloud Agent1$ apt-get update &amp;&amp; apt-get install -y dockercloud-agent]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>ops</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 初探 (6) - Docker Machine]]></title>
    <url>%2Fdocker-machine%2F</url>
    <content type="text"><![CDATA[参考资料: Swarms Docker Machine 前言Docker GetStarted Swarm 官方文档中，为了在单机上演示如何搭建 Docker Swarm 而引入了 Docker Machine，并在其中穿插了虚拟 shell 环境的内容，个人认为这部分内容干扰了集群搭建的关键信息。 Docker Machine通过 Docker Machine 可实现在虚拟主机或远程主机上安装 Docker 引擎，并使用 docker-machine 命令行对其进行管理的工具。Docker Machine 在 Docker for Mac 和 Docker for Windows 上都已经预装，Linux 系统需要手动安装。 Docker Machine 有以下两种常用场景: 有些老的桌面系统主机如 Windows 和 Mac，它们不满足预装 Docker for Windows 或 Docker for Mac 的条件，但我想要在这些系统上运行 Docker。 我想要在远程主机系统上运行统一的 Docker image。 docker 守护进程由服务端和客户端两部分组成，服务端发布 REST API 接口开放给客户端，docker CLI 客户端通过 REST API 接口与服务端通信。 无论你的管理主机是 Windows，Mac 还是 Linux，都可以安装 Docker Machine 并使用 docker-machine 命令统一管理大量的 Docker 从机。通常，你会将 Docker Machine 安装到本地主机，Docker Machine 包含 docker-machine 命令行工具和 Docker 引擎的客户端 docker 命令行工具。可通过 docker-machine 命令行工具在本地主机的虚拟环境或云主机上安装 Docker 引擎，它将自动创建虚拟环境，安装 Docker 引擎，配置好 docker 客户端，每一个被管理的从机由 Docker host(运行了 Docker 引擎的主机) 和一个配置好的客户端组成，它们通常又被称为 “machines”。 意即，如果仅仅安装 Docker Machine，将不会在本机安装 Docker 引擎，仅仅安装其客户端管理工具 在 Linux 上安装 Docker Machine首先在 docker/machine release page 页面上找到最新的发布版本号，并修改以下命令对应的位置123$ base=https://github.com/docker/machine/releases/download/v0.14.0 &amp;&amp; curl -L $base/docker-machine-$(uname -s)-$(uname -m) &gt;/tmp/docker-machine &amp;&amp; sudo install /tmp/docker-machine /usr/local/bin/docker-machine 打印 docker-machine 的版本以确认安装完成:12$ docker-machine --versiondocker-machine version 0.14.0, build 89b8332 以非 driver 方式添加主机Docker Machine 为众多的虚拟机和云服务商提供了 driver，以通过这些驱动在不同的服务商主机上安装 Docker 引擎，但也提供了一种 url 的方式来添加已有 docker 主机:1234$ docker-machine create --driver none --url=tcp://50.134.234.20:2376 custombox$ docker-machine lsNAME ACTIVE DRIVER STATE URLcustombox * none Running tcp://50.134.234.20:2376 此后，便可通过 docker-machine 远程管理列表中的所有主机，可通过 docker-machine ssh custombox 向该主机发送指令，例如:1$ docker-machine ssh custombox "docker container ls" 如果出于某些原因出现 ssh 连接的问题，那么可以改用系统本地的 ssh 进行通信，加入 --native-ssh 参数即可: docker-machine --native-ssh ssh 配置虚拟 Docker 主机的 shell 环境除了通过 docker-machine ssh 向 Docker 主机发送命令之外，还可以使用 docker-machine env &lt;machine&gt; 配置一个虚拟 shell 环境直接与目标主机的 Docker 守护进程通信。这样，便可访问执行 docker-machine 的本地主机的资源，如 docker-compose.yml 文件:12345678$ docker-machine env customboxexport DOCKER_TLS_VERIFY="1"export DOCKER_HOST="tcp://50.134.234.20:2376"export DOCKER_CERT_PATH="/Users/pango/.docker/machine/machines/custombox"export DOCKER_MACHINE_NAME="custombox"# Run this command to configure your shell:# eval $(docker-machine env custombox) 执行输出结果返回的最后一行命令:1eval $(docker-machine env myvm1) 执行 docker-machine ls 验证 custombox 变成了活动主机，Active 一栏的 * 指示了该状态:1234$ docker-machine lsNAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORScustombox * none Running tcp://50.134.234.20:2376 v17.06.2-ce 清除 docker-machine 的 shell 变量设置1eval $(docker-machine env -u) 该命令退出与目标主机建立的虚拟 shell 环境并回到之前的环境中。 有关 Docker Machine 更多详情参考 Docker Machine。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>ops</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 初探 (5) - Stacks]]></title>
    <url>%2Fdocker-stacks%2F</url>
    <content type="text"><![CDATA[参考资料: Stacks 前言一个 Stack 是一组相互作用并共享依赖的 service，并且一起协同和伸缩的单元，一个 Stack 可以能够定义包含一个系统的所有功能。之前关于 Service 的介绍中已经用到了 stack，但那只是包含单个服务的 stack，在生产环境中 stack 往往许多服务，并将它们运行在不同的主机上。 添加一个新的 service 并重新部署首先添加一个免费的可视化服务以监控 swarm 是如何调度 container 的。 打开 docker-compose.yml，填充以下内容:123456789101112131415161718192021222324252627282930version: "3"services: web: # replace username/repo:tag with your name and image details image: username/repo:tag deploy: replicas: 5 restart_policy: condition: on-failure resources: limits: cpus: "0.1" memory: 50M ports: - "80:80" networks: - webnet visualizer: image: dockersamples/visualizer:stable ports: - "8080:8080" volumes: - "/var/run/docker.sock:/var/run/docker.sock" deploy: placement: constraints: [node.role == manager] networks: - webnetnetworks: webnet: 在 web 服务之后，添加了一个名为 visualizer 的服务，注意两项: volumns 表示给予其访问 docker 主机的 socket 文件的权限。 placement 确保该服务仅能在 swarm manager 上运行。 重新部署 stack1234$ docker stack deploy -c docker-compose.yml getstartedlabUpdating service getstartedlab_web (id: fmh8sn491klzx4vnz6uft0wc9)Creating service getstartedlab_visualizer 从图上可以看出，visualizer 的单副本服务运行在了作为 Swarm Manager 的 Aiur 主机上。Visualizer 是一个可以包含在任何 stack 中单独运行的服务，它没有任何依赖。 持久化数据现在，为 Stack 添加 Redis 数据库服务。 在 docker-compose.yml 文件中新增服务声明:123456789101112redis: image: redis ports: - "6379:6379" volumes: - "/home/pango/data:/data" deploy: placement: constraints: [node.role == manager] command: redis-server --appendonly yes networks: - webnet Redis 官方提供了 Docker 的 image 并将其命名为 redis，所以没有 username/repo 的前缀，redis 的 container 预设端口为 6379，在 Compose 文件中同样以 6379 端口加以映射并对外界开放。在 redis 服务的声明中，有如下几点重要信息: redis 始终在 swarm manager 上运行，所以它总是使用相同的文件系统 redis 访问 container 中的 /data 目录来持久化数据，并映射到主机文件系统的 /home/docker/data 目录 如果不加以映射，那么 redis 仅将数据保存在 container 中的 /data 目录下，一旦该 container 被重新部署则数据就会被清除。 在 Swarm Manager 主机上创建 /data 目录: 1mkdir ~/data 重新部署 stack: 12345$ docker stack deploy -c docker-compose.yml getstartedlabUpdating service getstartedlab_web (id: fmh8sn491klzx4vnz6uft0wc9)Updating service getstartedlab_visualizer (id: oj86dzaracmuoxb3ucvi7ro1e)Creating service getstartedlab_redis 执行 docker service ls 验证 3 个服务都已运行: 123456$ docker service lsID NAME MODE REPLICAS IMAGE PORTSkuuocvu54rd1 getstartedlab_redis replicated 1/1 redis:latest *:6379-&gt;6379/tcpoj86dzaracmu getstartedlab_visualizer replicated 1/1 dockersamples/visualizer:stable *:8080-&gt;8080/tcpfmh8sn491klz getstartedlab_web replicated 5/5 frosthe/get-started:part2 *:80-&gt;80/tcp 现在访问任意节点的 ip:8080，可以看到 redis 服务已经运行在 Swarm Manager 节点上。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>ops</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 初探 (4) - Swarms]]></title>
    <url>%2Fdocker-swarms%2F</url>
    <content type="text"><![CDATA[参考资料: Swarms Create a swarm Swarm 简介Swarm 是一组运行了 Docker 的机器并加入到同一个集群，通过使用相同的命令，但这些命令由在该集群上被称作 「集群管理员(Swarm Manager)」 的机器执行。集群上的机器可以是物理主机，也可以是虚拟主机，在加入集群之后，它们统一称为「节点(nodes)」。 Swarm Manager 是唯一能够执行命令的主机，并且负责授权其他主机以 worker 身份加入到集群中，worker 仅提供集群容量，没有任何指挥其他主机的权限。Swarm Manager 可通过 「最小化节点」策略: 提取最为空闲的主机运行 container。 「全局化」策略: 确保集群中的每一个节点都运行一个指定的 container。 采用何种策略在 docker-compose.yml 文件中配置。 之前的案例都是以「单机模式」运行应用程序，Docker 可转换为「集群模式」，启用集群模式的主机将立即成为 Swarm Manager，自此之后，所有的命令都将作用于整个集群而非仅仅本地主机。 搭建 Docker 集群执行 docker swarm init 便可启用集群模式便将当前主机作为 Swarm Manager。然后在另外一台主机执行 docker swarm join 命令以 worker 身份加入集群。 接下来以一个可由公网访问的 Linux 主机(Aiur) 作为 Swarm Manager，一台 Windows PC(moby) 作为 Worker: 可借助 Docker Machine 在一台第三方的主机执行 docker-machine ssh &lt;hostname&gt; &quot;&lt;command&gt;&quot; 远程连接到另外一台 docker 主机，并执行相应的命令，简单起见，这里统一采用本机执行命令的方式。有关 Docker Machine 的更多信息参考 Docker Machine 首先创建 Swarm 并暴露 Manager 的公网 ip 地址:123456789$ docker swarm init --advertise-addr 192.168.99.100Swarm initialized: current node (bsa93xks81o4ab971nv8ppzza) is now a manager.To add a worker to this swarm, run the following command: docker swarm join --token SWMTKN-1-40lg4ocglu93sdfyp28nosqvrupjgmb4iv9cnxv46kcwdqvqtw-btzb7tu4ks5stfe0spf0x62ty 192.168.99.100:2377To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions. --advertise-addr 配置 Manager 节点以 192.168.99.100 向外发布，其他主机或集群中的其他节点必须能够访问该地址，输出的内容包含了如何加入新的 worker 节点以及如何加入新的 manager 节点。--token 是加入集群的凭证。 2377 是 Docker 集群的默认管理端口，2376 是 Docker 守护进程的端口。 查看当前 docker 的状态:12345678910$ docker info# ...snip...Swarm: active NodeID: bsa93xks81o4ab971nv8ppzza Is Manager: true ClusterID: s767fic8a9abaxq6n42d8vhd2 Managers: 1 Nodes: 1# ...snip... 1234$ docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSIONbsa93xks81o4ab971nv8ppzza * Aiur Ready Active Leader 18.03.1-ce 将其他主机加入该节点由创建集群提供的命令行代码将其他主机加入到节点:12docker swarm join --token SWMTKN-1-40lg4ocglu93sdfyp28nosqvrupjgmb4iv9cnxv46kcwdqvqtw-btzb7tu4ks5stfe0spf0x62ty 192.168.99.100:2377This node joined a swarm as a worker. 执行 docker node ls 查看节点:12345$ docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSIONbsa93xks81o4ab971nv8ppzza * Aiur Ready Active Leader 18.03.1-cel1tat89t1ihfi04ad11mccsmi moby Ready Active 17.09.1-ce ID 后面的 * 表示当前连接的节点。 在集群上部署应用现在，在 Swarm Manager 主机环境中执行在Docker 初探 - Serivces 中相同的命令 docker stack deploy 来部署应用:1234$ docker stack deploy -c docker-compose.yml getstartedlabCreating network getstartedlab_webnetCreating service getstartedlab_web 执行相同的命令来查看 service 中的 containers，与之前不同的是，5 份 container 的副本被分配到了集群的两个节点上 Aiur 和 moby。12345678$ docker stack ps getstartedlabID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTSaumkvyzfh3oo getstartedlab_web.1 frosthe/get-started:part2 moby Running Running about a minute agoy82s9nuonx3p getstartedlab_web.2 frosthe/get-started:part2 Aiur Running Running about a minute agoyp2zx0bncv55 getstartedlab_web.3 frosthe/get-started:part2 moby Running Running about a minute agoul7f48j0grzy getstartedlab_web.4 frosthe/get-started:part2 moby Running Running about a minute agojzn0fndpf206 getstartedlab_web.5 frosthe/get-started:part2 Aiur Running Running about a minute ago 访问集群通过访问 Aiur 和 moby 两者的 ip 地址都可以访问应用程序，返回的 Hostname 轮流展示 5 个 container 的 ID。但这些 container 实例分别运行于两个节点上。 之所以访问任何一个节点的 ip 地址都可以到达应用程序是因为参与集群的节点共用「入口路由网格」，这保证了一个 service 在部署到集群的某个端口后，无论哪个节点正在运行或没有运行任何 container 实例，该端口都会保留给该 service。下图表示了一个名为 my-web 的服务在一个三节点的集群中发布 8080 端口: 要使入口路由网格正常运作，请确保集群中各个节点的以下端口是可访问的: 7946 TCP/UDP 端口用于发现 container 网络 4789 UDP 端口用于 ingress network 清理与重启停止 stack:1234$ docker stack rm getstartedlabRemoving service getstartedlab_webRemoving network getstartedlab_webnet 将节点主机从集群分离: Worker: 12$ docker swarm leaveNode left the swarm. Manager: 12$ docker swarm leave --forceNode left the swarm.]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>ops</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 初探 (3) - Services]]></title>
    <url>%2Fdocker-services%2F</url>
    <content type="text"><![CDATA[参考资料: Services Docker ComposeDocker Compose 是用以定义与运行多容器 Docker 应用的工具，使用 YAML 文件配置应用的服务，之后，执行一句简单的命令行来创建和启动定义好的应用。Compose 在 Docker for Mac 和 Docker for Windows 上都已经预装了，但 Linux 系统需要手动安装。 安装 Docker Compose 执行命令下载 Docker Compose 的最新版1$ sudo curl -L https://github.com/docker/compose/releases/download/1.21.0/docker-compose-$(uname -s)-$(uname -m) -o /usr/local/bin/docker-compose 将版本号改为 Compose repository release page on GitHub 上最新版的版本号。 为 docker-compose 可执行程序添加执行权限。 1$ sudo chmod +x /usr/local/bin/docker-compose 测试安装是否成功: 12$ docker-compose --versiondocker-compose version 1.21.2, build a133471 有关 Docker Compose 的更多详情参考 Docker Compose 关于 Service在分布式系统中，各个部件被称作 Services。例如，一个视频分享网站，它很可能包含一个把应用数据存到数据库中的服务，用户上传一个视频后，在后台转码视频的专有服务以及一个响应前台的服务。一个 service 仅仅运行一个 image，但它指导了改 image 应该如何运行 - 应该使用哪个端口，需要运行多少个 container 实例以支撑服务的容量。container 实例数量的增减用以伸缩该服务。 docker-compose.yml 文件docker-compose.yml 文件是一个定义 container 应该如何运作的 YAML 文件。新建该文件放置于任何想要的位置，并为其填充内容:123456789101112131415161718192021$ touch docker-compose.ymlversion: "3"services: web: # replace username/repo:tag with your name and image details image: frosthe/get-started:part2 deploy: replicas: 5 resources: limits: cpus: "0.1" memory: 50M restart_policy: condition: on-failure ports: - "80:80" networks: - webnetnetworks: webnet: 该文件告知 Docker 执行以下事情: 拉取 frosthe/get-started:part2 的 image 定义了一个名为 web 的服务，该服务运行该 image 的 5 份实例，且限制每个实例最多占用 10% 的 CPU 和 50M 的内存 立即重启 container 如果任何一个启动失败 映射主机的 80 端口到 web 服务的 80 端口 告知名为 web 的服务的所有 container 实例通过一个名为 webnet 的负载均衡网络共享 80 端口(其内部机制为 container 轮流将它们自己发布到 web 服务的 80 端口) 定义 webnet 网络，默认配置为一个叠加的负载均衡网络 启动新的负载均衡应用首先初始化一个 swarm:123$ docker swarm initSwarm initialized: current node (iqaw9hws38ctvpghyxaycrj4t) is now a manager. 有关 swarm 的介绍，参考 Docker 初探 (4) - Swarms，如果不运行该指令，将会报 “this node is not a swarm manager” 的错误信息 现在，运行该程序，给它一个名称:1234$ docker stack deploy -c docker-compose.yml getstartedlabCreating network getstartedlab_webnetCreating service getstartedlab_web 执行 docker service ls 查看是否成功运行:1234$ docker service lsID NAME MODE REPLICAS IMAGE PORTSo3jo325ds62i getstartedlab_web replicated 5/5 frosthe/get-started:part2 *:80-&gt;80/tcp 可以看到名为 web 的服务已经运行，在一个服务中单独运行的 container 称为一个 task，task 会被分配递增的数字 ID，直到定义的副本数量的最大值，列出该服务的所有 task:12345678$ docker service ps lsID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTSg7dr8ecu5a6d getstartedlab_web.1 frosthe/get-started:part2 Aiur Running Running 2 minutes ago1gu635hjck46 getstartedlab_web.2 frosthe/get-started:part2 Aiur Running Running 2 minutes agorny0soxz5rh6 getstartedlab_web.3 frosthe/get-started:part2 Aiur Running Running 2 minutes agozfvdxi8e6jpt getstartedlab_web.4 frosthe/get-started:part2 Aiur Running Running 2 minutes agoqudnod8hs9xw getstartedlab_web.5 frosthe/get-started:part2 Aiur Running Running 2 minutes ago 如果使用命令列出当前系统中的 container，这些 task 也会被包含其中，但不会由其从属的 service 作筛选:12345678$ docker container lsCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES6642f46afaa4 frosthe/get-started:part2 &quot;python app.py&quot; 4 minutes ago Up 4 minutes 80/tcp getstartedlab_web.4.zfvdxi8e6jpte0qcobidxvuq600ffa6c89b09 frosthe/get-started:part2 &quot;python app.py&quot; 4 minutes ago Up 4 minutes 80/tcp getstartedlab_web.5.qudnod8hs9xwyhe07o2xomm25bc1563fa67f8 frosthe/get-started:part2 &quot;python app.py&quot; 4 minutes ago Up 4 minutes 80/tcp getstartedlab_web.3.rny0soxz5rh641082ybs1h6vj526e37ad6994 frosthe/get-started:part2 &quot;python app.py&quot; 4 minutes ago Up 4 minutes 80/tcp getstartedlab_web.1.g7dr8ecu5a6dh5ua5lqo0cbjwee599ab17416 frosthe/get-started:part2 &quot;python app.py&quot; 4 minutes ago Up 4 minutes 80/tcp getstartedlab_web.2.1gu635hjck46xt8leib3md9nb 现在，通过 ip 地址访问该应用，连续刷新浏览器，会看到每次刷新后 Hostname 一项都改变。之前提到过，Hostname 返回的是 container 的 ID，所以这里会看到 Hostname 的值为 5 个副本 ID 值轮流变化。 扩展该应用可以在 docker-compose.yml 文件中修改 replicas 的值来扩展计算量，然后再次执行 docker stack deploy 命令:1$ docker stack deploy -c docker-compose.yml getstartedlab Docker 支持实时更新，不需要关闭 stack 或停止任何 container。 停止应用及 swarm 停止 app: 1234$ docker stack rm getstartedlabRemoving service getstartedlab_webRemoving network getstartedlab_webnet 停止 swarm: 123$ docker swarm leave --forceNode left the swarm.]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>ops</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 初探 (2) - Containers]]></title>
    <url>%2Fdocker-containers%2F</url>
    <content type="text"><![CDATA[参考资料: Containers 以 Docker 的方式定义一个应用Container 位于架构层次的最底层，其上是 Service，服务定义了 Container 如何在生成环境互作用。Service 之上是 Stack，其定义了所有服务之间的互作用。 在过去，如果希望便携一个 python 应用，那么第一件事就是要在主机上安装 python 运行时，这便限制了该主机的功能很难用作它途，如果想要部署一个 .net core 应用，那么 python 的运行时毫无意义。 在 Docker 生态中，python 以 image 的形式定义，并且可由任何其他 image 引用，从而确保所有的 image 都是可插拔的，并且不会干扰本地主机的环境。 使用 Dockerfile 定义一个 image用于定义 image 的被称为 Dockerfile，该文件描述了哪些环境需要被加载到 container 中，类似访问网络资源的接口和硬盘驱动都在此环境中被虚拟化，并与系统的其他部分完全隔离。因此，我们需要将端口映射到 container 外部，并且确切定义要将哪些文件「复制到」该环境中，完成这些配置之后，便可期待该 Dockerfile 定义的应用可以在任何地方运行了。 创建一个新目录，并导航到其中作为工作目录 12$ mkdir my-first-docker-image$ cd my-first-docker-image 新建一个名为 Dockerfile 的文件: 12$ touch Dockerfile$ nano Dockerfile 复制以下内容至该文件: 1234567891011121314151617181920# Use an official Python runtime as a parent imageFROM python:2.7-slim# Set the working directory to /appWORKDIR /app# Copy the current directory contents into the container at /appADD . /app# Install any needed packages specified in requirements.txtRUN pip install --trusted-host pypi.python.org -r requirements.txt# Make port 80 available to the world outside this containerEXPOSE 80# Define environment variableENV NAME World# Run app.py when the container launchesCMD ["python", "app.py"] 该 Dockerfile 引用的 app.py 及 requirements.txt 尚未创建，执行命令以创建它们:12$ touch requirements.txt$ touch app.py 注意，两者位于与 Dockerfile 相同的目录 由此，应用所需的文件都已就绪，当上述 Dockerfile 生成一个 image 时，Dockerfile 中的 Add 指令会将当前目录下的所有文件拷贝至子目录 /app，并且 app.py 将可通过 HTTP 协议访问因为 EXPOSE 指令暴露了 80 端口。 填充 requirements.txt1234$ nano requirements.txtFlaskRedis 填充 app.py1234567891011121314151617181920212223242526$ nano app.pyfrom flask import Flaskfrom redis import Redis, RedisErrorimport osimport socket# Connect to Redisredis = Redis(host="redis", db=0, socket_connect_timeout=2, socket_timeout=2)app = Flask(__name__)@app.route("/")def hello(): try: visits = redis.incr("counter") except RedisError: visits = "&lt;i&gt;cannot connect to Redis, counter disabled&lt;/i&gt;" html = "&lt;h3&gt;Hello &#123;name&#125;!&lt;/h3&gt;" \ "&lt;b&gt;Hostname:&lt;/b&gt; &#123;hostname&#125;&lt;br/&gt;" \ "&lt;b&gt;Visits:&lt;/b&gt; &#123;visits&#125;" return html.format(name=os.getenv("NAME", "world"), hostname=socket.gethostname(), visits=visits)if __name__ == "__main__": app.run(host='0.0.0.0', port=80) 以上两段代码值得注意的是 pip install -r requirements.txt app.py 中使用了环境变量 NAME socket.gethostname() 的调用 至此，本地主机不需要安装任何声明在 requirements.txt 文件中的 python 库，但该程序仍然不完整，因为我们仅仅安装了 Redius 的 python 库，但 Redius 进程本身并没有在本地主机安装运行。 从 container 中查询主机名称将返回 container ID，它的值相当于进程的 ID。 生成应用 在生成应用之前，首先确保工作目录在新建目录的顶层: 123$ lsDockerfile app.py requirements.txt 执行生成指令，这将会产生一个 Docker image，使用 -t 选项给它一个标签。 1$ docker build -t friendlyhello . 注意 . 表示生成基于的目录位置，表示当前目录 生成过程中 Docker 引擎会根据 Dockerfile 声明的引用库去下载需要的文件，这可能需要一些时间。生成完成后，如何查看生成的位置呢？执行 docker image ls 指令即可看到新生成的 image。 1234$ docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEfriendlyhello latest 2f701134298d About a minute ago 145MB 在本地生成的 image 会放至 Docker 的本地 Registry，Docker 以 Registry 的形式进行本地与远程 image 库的同步。 运行应用使用 -p 选项将本地主机的 8000 端口映射到 container 的 80 端口1$ docker run -p 4000:80 friendlyhello 执行以上命令之后，可以看到一条 python 消息称应用侦听 http://0.0.0.0:80，该消息来自于 container 内部，其并不知道外部如何对其映射。 现在在浏览器中输入 {your-host-ip}:4000 将会得到预期的结果。同样，也可以使用命令行工具 curl 来获取相同的结果:1$ curl http://&#123;your-host-ip&#125;:4000 端口映射 4000:80 很好的对应了在 Dockerfile 中声明的 EXPOSE 和使用 docker run -p 指定的端口。 现在，使用 -d 选项让该应用以 detached 模式在后台运行：123$ docker run -d -p 4000:80 friendlyhellob3076b38a52b82c9c39fa0e99bd51a0f49912869a141ca2f3c677deb3e481bab 该命令返回一个 Container ID 执行 docker container ls 将会看到正在运行的应用，该 Container ID 与之前返回的 ID 一致。12CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESb3076b38a52b friendlyhello "python app.py" 7 seconds ago Up 6 seconds 0.0.0.0:4000-&gt;80/tcp admiring_vaugh 使用相同的 Container ID 执行 docker container stop 来结束进程: 分享 imageimage 的集合称作 repository，类似于一个 Github 仓库，而一个 Registry 是 repositories 的集合，一个 registry 的帐号可以创建多个 repository，docker 默认使用 Docker 的公共 Registry。有关 Registry 的详情参考 Docker Trusted Registry。 使用 Docker ID 登录cloud.docker.com 提供了托管 image 的云服务，注册一个帐号来使用公开的 Registry。docker CLI 同样集成了 docker cloud 的登录功能，执行以下代码:1$ docker login 为 image 设置标签将本地 image 与远程 registry 的 repository 同步的符号格式为 username/repository:tag，tag 是可选的，但建议为 image 设置标签，因为它是 registry 为 Docker image 添加版本号的机制。为 repository 和 tag 定义有意义的名称，例如 get-started:part2，这会将该 image 推送到 get-started 仓库并将其标签设置为 part2。 使用 docker tag {local-image} {your-docker-id}/{your-repository}:{your-tag} 来为 image 设置标签，例如:1$ docker tag friendlyhello pango/get-started:part2 再次执行 docker image ls 查看:1234REPOSITORY TAG IMAGE ID CREATED SIZEfriendlyhello latest d9e555c53008 3 minutes ago 195MBpango/get-started part2 d9e555c53008 3 minutes ago 195MBpython 2.7-slim 1c7128a655f6 5 days ago 183MB 发布 image将标签化的 image 上传至 repository:1$ docker push &#123;your-docker-id&#125;/&#123;your-repository&#125;:&#123;your-tag&#125; 上传完成后，使用 Docker ID 登录 Docker Hub 将会看到刚刚上传的 image。 拉取并运行 image现在，可以执行以下代码在任何地方运行应用:1$ docker run -p 4000:80 username/repository:tag 如果该 image 无法在本地获取，Docker 会从远程 repository 将其拉取至本地。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>ops</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 初探 (1) - 搭建 Docker 环境]]></title>
    <url>%2Fdocker-setup%2F</url>
    <content type="text"><![CDATA[参考资料: Get Docker CE for Ubuntu Post-installation steps for Linux Docker 继承自 Linux 系统的「容器化(Containerization)」，是一个为开发人员和系统管理员用于开发，部署和运行应用程序的容器系统，容器化的特点有: 灵活性: 任何复杂的应用都可以被容器化 轻量: 容器共享主机的内核 可互换: 可在运行过程中部署更新 便携性: 本地编译，云端部署，在任何地方都可以运行 伸缩性: 增加容器副本相当容易且自动化 可堆叠: 可在运行过程中纵向扩展 Docker 官方目前提供两个版本：Community Edition (CE) 和 Enterprise Edition (EE)。企业版是收费的。 搭建 Docker 环境Image 和 ContainerImage 是一个包含了运行应用程序所需所有东西的包——源代码，运行时，库，环境变量和配置文件Container 是 Image 的运行时实例，是 Image 在内存中的体现。 Containers 和虚拟机Container 运行在 Linux 系统本地并与其他 Container 共享主机内核，它以「离散的进程」形式存在，不会占用比一般进程更多的资源。而虚拟机则运行整个客户机操作系统，并以虚拟化的方式访问主机资源，因此虚拟机会占用更多不必要的资源。 在 Ubuntu Xenial 16.04(LTS) 系统上安装 Docker CE首先移除任何 Docker 旧版本:1$ sudo apt-get remove docker docker-engine docker.io 从 Repository 安装搭建 Repository 从 apt 更新包: 1$ sudo apt-get update 允许 apt 使用 https 来安装包 12345$ sudo apt-get install \ apt-transport-https \ ca-certificates \ curl \ software-properties-common 添加 Docker 官方 GPG key: 1$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - 验证 key 的最后 8 位字符:9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88 123456$ sudo apt-key fingerprint 0EBFCD88pub 4096R/0EBFCD88 2017-02-22 Key fingerprint = 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88uid Docker Release (CE deb) &lt;docker@docker.com&gt;sub 4096R/F273FCD8 2017-02-22 使用以下命令搭建稳定版的 repository: 1234$ sudo add-apt-repository \ "deb [arch=amd64] https://download.docker.com/linux/ubuntu \ $(lsb_release -cs) \ stable" lsb_release 返回 Ubuntu 发行版的名称，如 xenial。stable 为每季度发行一次的稳定版，edge 为每月发行一次的尝鲜版。 安装 Docker CE 更新包的索引: 1$ sudo apt-get update 安装最新版的 Docker CE: 1$ sudo apt-get install docker-ce 安装完成后，Docker 守护进程将自动启动 通过运行一个 hello world 程序来验证 Docker CE 已经正确安装1$ sudo docker run hello-world 该命令会从网络下载一个测试 image，并以新的容器实例执行。执行以下命令查看已下载的 image:1$ sudo docker image ls 检查正在运行的 container 实例: 1$ sudo docker container ls --all 该指令检查包含正在运行和过往运行的 container 实例记录，如果有 container 正在运行，则不需要 --all 选项。 卸载 Docker CE 卸载 Docker CE 包: 1$ sudo apt-get purge docker-ce image, container, volumns 或其他自定义的配置文件将不会自动删除，如果想要完全删除，则执行: 1$ sudo rm -rf /var/lib/docker 以 non-root 用户管理 Dockerdocker 守护进程绑定一个 Unix 套接字而非普通的 TCP 端口，默认情况下，Unix 套接字被 root 用户所有，其他用户只能通过 sudo 进行访问。docker 进程始终以 root 用户运行。 Docker CE 在安装完成后，会创建一个新的 docker 群组，但不会加入任何现有用户到该群组下，如果不想每次执行 docker 命令时加上 sudo，可以将指定用户加入到群组下。当 docker 进程启动时，docker 群组对 docker 使用的 Unix 套接字具有读写权限。 由于 docker 群组与 root 权限一致，有关 docker 的安全问题请参考 Docker Security 将当前用户添加至 docker 群组: 1$ sudo usermod -aG docker $USER 登出用户再登录以使群组重新评估再次执行 docker run hello-world 不再要求 root 权限，如果在将用户添加到 docker 群组之前已经执行过 docker 的任何命令，那么 ~/.docker 文件夹的权限会以 root 创建，为了解决这个问题，要么移除 ~/.docker(它将会自行创建)，要么更改其拥有者和权限: 12$ sudo chown "$USER":"$USER" /home/"$USER"/.docker -R$ sudo chmod g+rwx "/home/$USER/.docker" -R 将 docker 配置为开启启动有许多 Linux 发行版使用 systemd 来管理自启动服务，要使 docker 开机启动，执行:1$ sudo systemctl enable docker 禁用开机启动:1$ sudo systemctl disable docker]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>ops</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ASP.NET Core 的出站请求客户端]]></title>
    <url>%2Faspnetcore-outgoing-httpclient-factory%2F</url>
    <content type="text"><![CDATA[参考资料: 启动 Htpp 请求 本文索引: 前言 用法 配置 HttpMessageHandler 出站请求中间件 基于 Polly 的 Handlers HttpClient 的生存期 日志记录 前言当应用有对外部 Http 服务有依赖时，通常的做法是在应用内部使用 HttpClient。ASP.NET Core 加入了 HttpClientFactory，以集中的方式管理 HttpClient 及其使用的系统资源。 用法这些用法分别对应于 services.AddHttpClient() 方法的几个重载，并且适用于不同的场景: 基本用法: services.AddHttpClient() 命名 HttpClient: services.AddHttpClient(string name, Action&lt;HttpClient&gt; configureClient) 强类型 HttpClient: 不再以 string 类型参数提供 key，而是以单独的服务类型通过依赖注入的方式提供 HttpClient 实例，services.AddHttpClient&lt;TService&gt; 动态 HttpClient 配置 HttpMessageHandler在 services.AddHttpClient 方法重载中，有一些返回 IHttpClientBuilder 实例，该实例可用于进一步对该客户端进行配置:12345678services.AddHttpClient("configured-inner-handler").ConfigurePrimaryHttpMessageHandler(() =&gt; &#123; return new HttpClientHandler() &#123; AllowAutoRedirect = false, UseDefaultCredentials = true &#125;; &#125;); 可借由此功能定制出站请求的 HttpMessageHandler 或使用 Mock 的处理程序以支持测试。 出站请求中间件HttpClient 本身其实是将出站请求交给相应的委托进行处理，可以传入继承自 HttpMessageHandler 类型的实例来创建 HttpClient 实例。IHttpClientFactory 简化了为不同命名 HttpClient 注入预期的 HttpMessageHandler。可通过继承 DelegatingHandler 类型并重写 SendAsync 方法来实现 Handler 的处理逻辑:12345678public class MyCustomHandler : DelegatingHandler&#123; protected override async Task&lt;HttpResponseMessage&gt; SendAsync(HttpRequestMessage request, CancellationToken cancellationToken) &#123; // ... return await base.SendAsync(request, cancellationToken); &#125;&#125; 这样，在添加 AddHttpClient 服务时可对其配置相应的 Handler:12services.AddTransient&lt;MyCustomHandler&gt;();services.AddHttpClient("Github").AddHttpMessageHandler&lt;MyCustomHandler&gt;(); 值得注意的是，MyCustomHandler 必须在 DI 中以瞬时(Transient)生存期注册 可为同一个 IHttpClientFactory 多次调用 AddHttpMessageHandler 方法，Handler 将按照注册的顺序依次执行，这样将形成 Handler 链，一个 Handler 将包装下一个 Handler。与 ASP.NET Core 管道的概念类似，例如:123456services.AddTransient&lt;SecureRequestHandler&gt;();services.AddTransient&lt;RequestDataHandler&gt;();services.AddHttpClient("clientwithhandlers") .AddHttpMessageHandler&lt;SecureRequestHandler&gt;() // This handler is on the outside and called first during the request, last during the response. .AddHttpMessageHandler&lt;RequestDataHandler&gt;(); // This handler is on the inside, closest to the request being sent. 基于 Polly 的 HandlersIHttpClientFactory 通过扩展方法支持与 Polly 的 Policy 集成。这些扩展方法定义在 Microsoft.Extensions.Http.Polly 包中。 例如，用于从临时故障中重试的 AddTransientHttpErrorPolicy，定义了请求失败后最多重试三次，每次尝试间隔 600 ms 的 Policy:1services.AddHttpClient&lt;UnreliableEndpointCallerService&gt;().AddTransientHttpErrorPolicy(p =&gt; p.WaitAndRetryAsync(3, _ =&gt; TimeSpan.FromMilliseconds(600))); 其他一些扩展方法用于支持 Polly-based 处理程序，例如 AddPolicyHandler() 方法:12345var timeout = Policy.TimeoutAsync&lt;HttpResponseMessage&gt;(TimeSpan.FromSeconds(10));var longTimeout = Policy.TimeoutAsync&lt;HttpResponseMessage&gt;(TimeSpan.FromSeconds(30));// Run some code to select a policy based on the requestservices.AddHttpClient("conditionalpolicy").AddPolicyHandler(request =&gt; request.Method == HttpMethod.Get ? timeout : longTimeout); 上述代码中，如果出站请求为 GET，则应用 10 秒超时。其他所有 HTTP 方法应用 30 秒超时。 嵌套 Polly 策略以增强功能是很常见的:123services.AddHttpClient("multiplepolicies") .AddTransientHttpErrorPolicy(p =&gt; p.RetryAsync(3)) .AddTransientHttpErrorPolicy(p =&gt; p.CircuitBreakerAsync(5, TimeSpan.FromSeconds(30))); 上述示例中，添加了两个 Handler。 第一个使用 AddTransientHttpErrorPolicy 扩展添加重试策略。若请求失败，最多重试三次。第二个调用 AddTransientHttpErrorPolicy 添加断路器策略。如果尝试连续失败了五次，则会阻止后续外部请求 30 秒，并且通过此 HttpClientFactory 进行的所有调用都共享同样的线路状态。 HttpClient 的生存期每次调用 IHttpClientFactory.CreateClient 都会返回一个新的 HttpClient 实例。一个命名 HttpClient 服务关联一个 HttpMessageHandler 实例。IHttpClientFactory 将这些 HttpMessageHandler 实例汇集到池中，以减少资源消耗。 日志记录由 IHttpClientFactory 创建的客户端包含了请求的所有日志消息。单个客户端的管道外部以 LogicalHandler 类别来记录消息，而管道内部以 ClientHandler 类别记录。]]></content>
      <categories>
        <category>ASP.NET Core</category>
      </categories>
      <tags>
        <tag>aspnet-core</tag>
        <tag>polly</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ASP.NET Core 开发实践汇总]]></title>
    <url>%2Faspnetcore-notes%2F</url>
    <content type="text"><![CDATA[本文索引: ASP.NET Core 的入口点在哪？ Startup 从何而来？ IStartupFilter 是什么？ 使用 ASP.NET Core 2.1 开发 Api Controller 自动 HTTP 400 相应 自动参数源推定 Route 特性现在是必须的 ApiBehaviorOptions DI 的 Scoped 生存期是什么？ 你真的了解中间件吗？ 如何定义中间件？ IMiddleware 接口有什么用？ IFilter 和 Attribute，我该用哪一个？ 通过 Attribute 将 Filter 应用到 Controller 和 Action 级别 ServiceFilter 和 TypeFilters 又是什么？ Middleware 还是 Filters？ ASP.NET Core 的入口点在哪？正常情况下，ASP.NET Core 应用的 Program 类型看上去大概如下:1234567891011public class Program&#123; public static IHostingEnvironment HostingEnvironment &#123; get; set; &#125; public static IConfiguration Configuration &#123; get; set; &#125; public static void Main(string[] args) &#123; var webHost = CreateWebHostBuilder(args).Build(); webHost.Run(); &#125;&#125; ASP.NET Core 的 Main 方法实际是启动了一个 WebHost 的实例，该 WebHost 通过一个 Builder 对其进行配置，以下是 CreateWebHostBuilder 方法的实现:12345678910public static IWebHostBuilder CreateWebHostBuilder(string[] args) =&gt; WebHost.CreateDefaultBuilder(args) .ConfigureServices(services =&gt; &#123; ///... &#125;) .Configure(app =&gt; &#123; //... &#125;); 多次调用 ConfigureServices 将追加到前一个调用，多次调用 Configure 将基于上一个调用。 Startup 从何而来？微软认为，调用 IWebHostBuilder 的配置方法，诸如 ConfigureServices 以及 Configure 应该交由单独的类型来控制，于是对 IWebHostBuilder 接口添加了扩展方法 UseStartup&lt;TStartup&gt;。TStartup 可以不实现任何接口，但必须以约定命名的方式命名并实现框架要求的方法： 必须包括 Configure 方法，以创建应用的请求处理管道。 可选择性地包括 ConfigureServices 方法。 可以为不同的环境定义对应的 Startup 类型(例如 StartupDevelopment)，同样基于约定，如果应用在开发环境中运行并包含 Startup 类和 StartupDevelopment 类，则使用 StartupDevelopment 类。详情参考Startup 类约定 IStartupFilter 是什么？通过其命名可以看出，该接口是一种 Filter，用于在 Startup 类型外部添加中间件注册，这意味着: 在 StartupFilter 中注册的中间件将先于 Startup.Configure 方法注册的任何中间件执行 多个 IStartupFilter 接口将按照注册顺序决定中间件的执行顺序 可利用外部程序集增强 ASP.NET Core 的功能而不影响其原本的业务逻辑 IStartupFilter 仅定义了一个方法:1234567891011public class RequestSetOptionsStartupFilter : IStartupFilter&#123; public Action&lt;IApplicationBuilder&gt; Configure(Action&lt;IApplicationBuilder&gt; next) &#123; return builder =&gt; &#123; builder.UseMiddleware&lt;TMiddleware&gt;(); next(builder); &#125;; &#125;&#125; 通过 IWebHostBuilder.ConfigureServices 方法来注册该 Filter:12345678910public static IWebHostBuilder CreateWebHostBuilder(string[] args)&#123; WebHost.CreateDefaultBuilder(args) .ConfigureServices(services =&gt; &#123; services.AddTransient&lt;IStartupFilter, RequestSetOptionsStartupFilter&gt;(); &#125;) .UseStartup&lt;Startup&gt;() .Build();&#125; 使用 ASP.NET Core 2.1 开发 Api ControllerASP.NET Core 2.1 版本新增了部分便于开发 Web Api 的功能。现在，当创建用于 Web Api 的控制器时: 从 ControllerBase 类继承: Api 控制器类型不再需要继承自传统的 Mvc 控制器 Controller 类型，ControllerBase 提供了诸如 BadRequest()、CreateAtAction() 等分别返回相应状态码的行为 对类型标注 ApiController 特性: ASP.NET Core 2.1 版本引入了 ApiController 特性，该特性通常结合 ControllerBase 来为控制器启用 REST 的行为。为了确保在控制器级别该特性能够正常工作，需要在 Startup.ConfigureServices 方法设置兼容版本:1services.AddMvc().SetCompatibilityVersion(CompatibilityVersion.Version_2_1); ApiController 添加了以下行为: 自动 HTTP 400 相应当模型验证失败时，ModelState.IsValid 的计算结果为 false，并自动返回包含问题详细信息的 HTTP 400 响应。因此，不再需要以下类似代码:1234if (!ModelState.IsValid)&#123; return BadRequest(ModelState);&#125; 自动参数源推定应用了 ApiController 的控制器类，将根据下表隐式推定参数的绑定源: FromBody 请求正文 FromForm 表单数据 FromHeader 请求头 FromQuery 查询字符串参数 FromRoute 路由数据 FromServices 作为操作参数插入的请求服务 没有 ApiController 特性时，需要为入站请求参数显式定义绑定源特性。在下例中，FromQuery 特性指示 discontinuedOnly 参数值在请求 URL 的查询字符串中提供:12[HttpGet]public async Task&lt;ActionResult&lt;List&lt;Product&gt;&gt;&gt; GetAsync([FromQuery]bool discontinuedOnly = false) Route 特性现在是必须的使用 ApiController 特性标注的控制器类型将不再采用 Startup.Configure 方法中为 Mvc 程序定义的诸如 UseMvc().UseMvcWithDefaultRoute 的约定式路由策略。转而要求必须为每个标注了 ApiController 特性的控制器类型添加 Route 特性标注。 ApiBehaviorOptions上述讨论的默认行为可通过 ApiBehaviorOptions 对象启用或禁用，在 Startup.ConfigureServices 方法中修改这些配置的值:1234567services.Configure&lt;ApiBehaviorOptions&gt;(options =&gt;&#123; options.SuppressConsumesConstraintForFormFileParameters = true; options.SuppressInferBindingSourcesForParameters = true; options.SuppressModelStateInvalidFilter = true; options.InvalidModelStateResponseFactory = ...&#125;); 具体每项配置的影响可参考 ApiBehaviorOptions DI 的 Scoped 生存期是什么？初次接触 ASP.NET Core 的开发人员可能对 Scoped 生存期心存疑惑: 作用域生存期的服务以每个请求一次的方式创建，即 instance per HttpContext 默认情况下，在中间件内使用有作用域的服务必须在 Invoke 或 InvokeAsync 方法参数注入服务，而不要通过构造函数进行注入，因为「按约定激活」的中间件总是以单例创建，在构造函数中注入 Scoped 生存期的服务将导致不一致的状态。 你真的了解中间件吗？中间件的特点是: 选择是否将请求传递到管道中的下一个组件 可在调用管道中的下一个组件前后执行工作 中间件可定义为匿名委托或创建单独的类型实现，可借助以下方法应用中间件: Run: 该方法进传入一个 HttpContext 参数，指示该中间件总在管道的最后执行 Map: 传入匹配条件，使得中间件在某些条件下执行 Use: 传入参数中包含下一个中间件的引用，如果不调用 next.Invoke，可短路管道 如何定义中间件？ASP.NET Core 大量使用了命名约定的方式来隐式定义组件，中间件也不例外，默认情况下，以 Middleware 后缀结尾的类型被认为是隐式定义的中间件，该类型必须遵循: 构造函数接收一个代表下一个中间件的 RequestDelegate 参数注入 包含一个 Task InvokeAsync(HttpContext context) 的方法签名 如前文所述，中间件实例在应用程序启动时创建，如果定义的中间件需要使用 Scoped 生存期的服务，则必须在 Task InvokeAsync(HttpContext context) 方法的参数列表中添加注入。 随后，框架在 IStartupFilter 和 Startup.Configure 方法中调用 IApplicationBuilder.Use&lt;TMiddleware&gt; 以激活中间件。通常，为了方便使用，会专门为中间件定义 IApplicationBuilder.Use&lt;Middlware&gt; 的扩展方法。例如 IApplicationBuilder.UseMvc()。 IMiddleware 接口有什么用？除了基于命名约定的方式定义和激活中间件，微软提供了 IMiddleware 接口用于显式定义中间件并以工厂模式激活中间件。UseMiddleware 方法检查中间件的注册类型是否实现了 IMiddleware 接口，如果是，则从服务容器中解析 IMiddlewareFactory 实例激活中间件，这样做的好处在于: 可实现按作用域管理中间件的生存期 中间件强类型化 IMiddleware 接口定义了 InvokeAsync(HttpContext, RequestDelegate) 方法，其实现类可在构造函数中注入 Scoped 或 Singleton 生存期的服务。同时，基于工厂的中间件在调用 IApplicationBuilder.UseMiddleware&lt;TMiddleware&gt; 时不再支持传入参数。 IFilter 和 Attribute，我该用哪一个？首先要明确一点，Filter 是组件，而 Attribute 支持以标注方式使用 Filter 的一种方式。 Filter 在 ASP.NET 中由来已久，ASP.NET Core 中定义了诸多内置 Filter，例如 IActionFilter, IResultFilter 等等，可通过创建实现这些接口的类型或继承现有类型来定义 Filter。定义好 Filter 之后，便可在 ConfigureServices 中注册该 Filter，随后便可在 AddMvc 方法中以服务或实例的方式对该 Filter 进行应用。1234services.AddMvc(options =&gt; &#123; options.Filters.Add(new XXXFilter()) options.Filters.AddService&lt;TFilter&gt;();&#125;); 通过 Attribute 将 Filter 应用到 Controller 和 Action 级别上述方式展示了在「全局级别」应用 Filter 的案例，ASP.NET Core 还提供了在 Controller 和 Action 级别应用 Filter 的方式，这是结合 Attribute 和 IFilterMetadata 接口实现的。 IFilterMetadata 用于标记 Filter 类型，该接口未定义任何方法签名，仅仅是告知框架该类型是一个 Filter。另一个接口 IFilterFactory 派生自 IFilterMetadata 接口，进一步告知框架该 Filter 的实例应该如何创建。与 Middleware 的工厂激活模式相似，这种模式不必在应用程序中显式指定 Filter 的创建时机，转而通过引入 Attribute 来扮演 IFilterFactory 的角色。所以定义的 FilterAttribute 通常都实现了 IFilterFactory 接口，并在接口方法中返回一个与之对应的真正的 Filter 实例。此处的 Attribute 实际上是 Filter 的提供器。 ServiceFilter 和 TypeFilters 又是什么？由于 Attribute 在语言层面的限制(必须显式传入构造参数)，它无法通过自身提供有 DI 依赖的 Filter 实例，为了解决这个问题，微软提供了 ServiceFilterAttribute 和 TypeFilterAttribute: ServiceFilterAttribute: 通过 Attribute 的方式 从 DI 解析目标 Filter 类型的实例，该 Filter 必须要在 Startup 的 ConfigureServices 中注册，否则将抛出异常 TypeFilterAttribute: 与 ServiceFilterAttribute 类似，但引入的 Filter 无需事先在 Startup 的 ConfigureServices 中注册，且可以部分传入构造函数的参数。 Middleware 还是 Filters？中间件在请求抵达 Mvc 之前对请求进行处理，在这里还访问不到任何有关 Mvc 的内容，所以如果不依赖 Mvc 的组件，如 Routes, Actions, Controllers 等，优先使用 Middleware，反之使用 Filters。另外，ResourceFilter 是抵达 Mvc 之前的最后一种 Filter，此时它具有最完整的 HttpContext 信息。ResourceFilter 是将 Middleware 以 Filter 的形式应用到指定 Controller 或 Action 的最佳选择。]]></content>
      <categories>
        <category>ASP.NET Core</category>
      </categories>
      <tags>
        <tag>aspnet-core</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ASP.NET Core 应用 - 验证]]></title>
    <url>%2Faspnetcore-validation%2F</url>
    <content type="text"><![CDATA[参考资料: Model validation in ASP.NET Core MVC 本文大纲: 验证特性(Attribute) Required 特性和 BindRequired 特性的使用说明 模型状态(Model State) 手动验证 自定义验证 继承自 ValidationAttribute 定义自定义验证特性 在类级别实现 IValidateObject 接口 验证特性(Attribute)结合 ASP.NET Core 的模型绑定，可基于「入站请求数据模型」对请求数据进行验证，ASP.NET Core 内置了一系列用于验证的 attribute(下称“特性”) 使得开发人员可以声明式地将它们应用于任何类型或属性。 1234567891011121314151617181920212223242526public class Movie&#123; public int ID &#123; get; set; &#125; [StringLength(60, MinimumLength = 3)] [Required] public string Title &#123; get; set; &#125; [Display(Name = "Release Date")] [DataType(DataType.Date)] public DateTime ReleaseDate &#123; get; set; &#125; [Range(1, 100)] [DataType(DataType.Currency)] public decimal Price &#123; get; set; &#125; [RegularExpression(@"^[A-Z]+[a-zA-Z""'\s-]*$")] [Required] [StringLength(30)] public string Genre &#123; get; set; &#125; [RegularExpression(@"^[A-Z]+[a-zA-Z""'\s-]*$")] [StringLength(5)] [Required] public string Rating &#123; get; set; &#125;&#125; [CreditCard]: 属性匹配信用卡格式 [Compare]: 在一个模型中验证两个属性 [EmailAddress]: 属性匹配电子邮件格式 [Phone]: 属性匹配电话号码格式 [Range]: 属性值匹配一个范围 [RegularExpression]: 模式匹配 [Required]: 要求属性必须有值 [StringLength]: 属性匹配字符串长度 [Url]: 属性匹配 url 格式 DataType 特性提供格式化不提供验证。 所有继承自 ValidationAttribute 的类型均支持模型验证，查看 System.ComponentModel.DataAnnotations 获取更多有用的验证类型。 当内置验证特性无法满足要求时，可新建继承自 ValidationAttribute 的自定义验证类或将模型实现 IValidatableObject 接口进行扩展。 Required 特性和 BindRequired 特性的使用说明需要不可为 null 的值类型(如 decimal、int、float 和 DateTime)不需要为其标注 Required 特性，应用程序将不会检查这些类型的 Required 特性。MVC 模型绑定系统会忽略表单中为 null 或空白的提交，导致传入的表单数据缺少表单域。BindRequired 特性用于保证传递至后台的数据是完整的，在一个属性上标注 BindRequired 特性时，模型绑定器要求该属性必须有值，在一个类型上标注 BindRequired 特性时，模型绑定器要求该类型下的所有属性都必须有值。 对于上述值类型的可空类型(Nullable&lt;T&gt;)，模型绑定器将执行验证检查，就像该属性是标准的可为 null 的类型(例如 string)一样。 模型状态(Model State)MVC 会持续验证字段直到达到错误数量的最大值(默认值 200)，可以通过以下代码来改变该值:1services.AddMvc(options =&gt; options.MaxModelValidationErrors = 50); 调用 ModelState.IsValid 方法将显式评估应用到模型上的所有验证特性 手动验证完成模型绑定和验证后，可能需要重复其中的某些步骤。 例如，用户可能在应输入整数的字段中输入了文本，或者你可能需要计算模型的某个属性的值。可通过调用 ModelState.TryValidateModel 方法来实施手动模型验证。 自定义验证自定义验证支持两种方式，它们分别是 继承自 ValidationAttribute 定义自定义验证特性创建继承自 ValidationAttribute 的类型并重写 IsValid 方法，该方法接受两个参数: value: 要被验证的目标对象 validationContext: 获取与验证相关的其他信息，包括被模型绑定器已经绑定好的模型本身及其他属性 1234567891011121314151617181920public class ClassicMovieAttribute : ValidationAttribute&#123; private int _year; public ClassicMovieAttribute(int Year) &#123; _year = Year; &#125; protected override ValidationResult IsValid(object value, ValidationContext validationContext) &#123; Movie movie = (Movie)validationContext.ObjectInstance; if (movie.Genre == Genre.Classic &amp;&amp; movie.ReleaseDate.Year &gt; _year) &#123; return new ValidationResult(GetErrorMessage()); &#125; return ValidationResult.Success; &#125; 在类级别实现 IValidateObject 接口也可以通过实现 IValidatableObject 接口上的 Validate 方法，将验证逻辑直接放入模型中，以实现类级别的验证。如果某些验证规则仅仅适用于某个类型或验证逻辑依赖类的状态，那么让该模型 IValidateObject 接口可能是更好的选择。123456789public IEnumerable&lt;ValidationResult&gt; Validate(ValidationContext validationContext)&#123; if (Genre == Genre.Classic &amp;&amp; ReleaseDate.Year &gt; _classicYear) &#123; yield return new ValidationResult( $"Classic movies must have a release year earlier than &#123;_classicYear&#125;.", new[] &#123; "ReleaseDate" &#125;); &#125;&#125;]]></content>
      <categories>
        <category>ASP.NET Core</category>
      </categories>
      <tags>
        <tag>aspnet-core</tag>
        <tag>aspnet-core-mvc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ASP.NET Core 应用 - Filters]]></title>
    <url>%2Faspnetcore-filters%2F</url>
    <content type="text"><![CDATA[参考资料: Filters in ASP.NET Core 过滤器类型每个过滤器类型都将在管道的不同阶段被执行: Authorization 过滤器: 第一个运行的过滤器，决定执行请求的当前用户是否被授权。 Resource 过滤器: 紧随 Authorization 过滤器之后处理请求的过滤器，其代码在管道的其余部分之前或之后被执行，它们是实现缓存或因性能原因阻塞请求的最佳位置，它们在「Model Binding」之前运行，所以其代码可以影响模型绑定。 Action 过滤器: 在特定的 Action 之前或之后运行的过滤器，它们被用于操作传入 Action 的参数以及被其返回的结果。 Exception 过滤器: 用于将全局策略应用于在返回响应之前未被捕获的异常。 Result 过滤器: 在 Action 返回结果之前或之后执行代码，仅当 Action 方法成功之后才会运行，它们被用于处理必须围绕视图的逻辑。 实现过滤器通过定义不同的接口支持同步及异步实现。同步实现以 OnStageExecuting 和 OnStageExecuted 方法为模板，例如 OnActionExecuting 在方法执行之前运行，OnActionExecuted 在方法执行之后运行。123456789101112131415161718using FiltersSample.Helper;using Microsoft.AspNetCore.Mvc.Filters;namespace FiltersSample.Filters&#123; public class SampleActionFilter : IActionFilter &#123; public void OnActionExecuting(ActionExecutingContext context) &#123; // do something before the action executes &#125; public void OnActionExecuted(ActionExecutedContext context) &#123; // do something after the action executes &#125; &#125;&#125;异步过滤器定义一个 OnStageExecutionAsync 方法，该方法接收一个 FilterTypeExecutionDelegate 委托参数 next，next 参数代表 Action 本身，可在其之前或之后添加扩展逻辑:1234567891011121314151617using System.Threading.Tasks;using Microsoft.AspNetCore.Mvc.Filters;namespace FiltersSample.Filters&#123; public class SampleAsyncActionFilter : IAsyncActionFilter &#123; public async Task OnActionExecutionAsync( ActionExecutingContext context, ActionExecutionDelegate next) &#123; // do something before the action executes var resultContext = await next(); // do something after the action executes; resultContext.Result will be set &#125; &#125;&#125; 过滤器的同步和异步接口版本只要实现一个就够了，框架会首先检查过滤器类型是否实现了异步接口，如果是，则执行异步版本。否则，才会执行同步版本。如果同时实现了两个接口，则同步接口会被忽略。 IFilterFactoryIFilterFactory 实现了 IFilterMetaData 接口，所以 IFilterFactory 可以当作 IFilterMetaData 接口的实例在管道的任何地方使用。当框架准备调用 Filter 时，首先尝试将其转换成 IFilterFactory 接口，如果转换成功，接下来调用接口的 CreateInstance 方法以构造 IFilterMetaData 实例，这种设计更加灵活，因为不必在应用程序启动时显式指定具体的 Filter 类型。可以在自定义的 Attribute 上实现 IFilterFactory 接口以另一种方式创建 Filter:1234567891011121314151617181920212223242526272829public class AddHeaderWithFactoryAttribute : Attribute, IFilterFactory&#123; // Implement IFilterFactory public IFilterMetadata CreateInstance(IServiceProvider serviceProvider) &#123; return new InternalAddHeaderFilter(); &#125; private class InternalAddHeaderFilter : IResultFilter &#123; public void OnResultExecuting(ResultExecutingContext context) &#123; context.HttpContext.Response.Headers.Add( "Internal", new string[] &#123; "Header Added" &#125;); &#125; public void OnResultExecuted(ResultExecutedContext context) &#123; &#125; &#125; public bool IsReusable &#123; get &#123; return false; &#125; &#125;&#125; 框架内置过滤器特性 Filter Attribute框架包含了可继承或自定义的内置 attribute-based 形式的 Filter。例如以下 ResultFilter 在响应头添加了一个 Header。1234567891011121314151617181920212223using Microsoft.AspNetCore.Mvc.Filters;namespace FiltersSample.Filters&#123; public class AddHeaderAttribute : ResultFilterAttribute &#123; private readonly string _name; private readonly string _value; public AddHeaderAttribute(string name, string value) &#123; _name = name; _value = value; &#125; public override void OnResultExecuting(ResultExecutingContext context) &#123; context.HttpContext.Response.Headers.Add( _name, new string[] &#123; _value &#125;); base.OnResultExecuting(context); &#125; &#125;&#125;特性允许 Filter 接收参数，在上面的例子中，可以用该 Attribute 修饰一个 Controller 或 Action 方法并指定 Http Header 的名称。12345678910111213[AddHeader("Author", "Steve Smith @ardalis")]public class SampleController : Controller&#123; public IActionResult Index() &#123; return Content("Examine the headers using developer tools."); &#125; [ShortCircuitingResourceFilter] public IActionResult SomeResource() &#123; return Content("Successful access to resource - header should be set."); &#125;Index Action 的结果如下: Filter 特性: ActionFilterAttribute ExceptionFilterAttribute ResultFilterAttribute FormatFilterAttribute ServiceFilterAttribute TypeFilterAttribute TypeFilterAttribute 和 ServiceFilterAttribute 将在后文介绍。 Filter 应用级别和执行顺序过滤器可以以三种级别应用 - 以 Attribute 的形式应用在特定的 Action 或 Controller 类上。或者在 ConfigureServices 方法中配置 MvcOptions.Filters 以全局方式应用到所有 Action 和 Controller 上。123456789101112public void ConfigureServices(IServiceCollection services)&#123; services.AddMvc(options =&gt; &#123; options.Filters.Add(new AddHeaderAttribute("GlobalAddHeader", "Result filter added to MvcOptions.Filters")); // an instance options.Filters.Add(typeof(SampleActionFilter)); // by type options.Filters.Add(new SampleGlobalActionFilter()); // an instance &#125;); services.AddScoped&lt;AddHeaderFilterWithDi&gt;();&#125;多个内置的 Filter 接口都实现了对应的 Attribute 用于继承以支持自定义实现。 过滤器的默认执行顺序当管道中多处都应用了过滤器，scope 决定了过滤器的默认执行顺序。该序列看来如下: 全局过滤器的 before 部分 Controller 级别过滤器的 before 部分 Action 方法级别过滤器的 before 部分 Action 方法级别过滤器的 after 部分 Controller 级别过滤器的 after 部分 全局过滤器的 after 部分 所有继承自 Controller 类型的控制器都包含 OnActionExecuting 和 OnActionExecuted 方法。这些方法先于任何应用其上的过滤器的 OnActionExecuting 方法并且后于 OnActionExecuted 方法。 重写默认顺序可以通过实现 IOrderedFilter 接口来重写过滤器的默认执行顺序。该接口暴露一个 Order 属性先与过滤器的应用级别来影响执行顺序。Order 的属性值越低，其 before 部分代码先执行，after 部分后执行。 取消和短路通过在 context 上设置 Result 属性可以在任何点上短路管道。 依赖注入过滤器以服务的形式注册到 IoC，但实现为 Attribute 的过滤器无法通过依赖注入的方式获取构造器参数，这是因为 Attribute 类型的构造器参数必须在使用时指定，这是 Attribute 的一个限制。 如果过滤器在其创建过程种依赖 DI，可以通过以下方式之一解决该问题: ServiceFilterAttribute TypeFilterAttribute IFilterFactory 你可能想要在过滤器中从 DI 获取 logger。应该避免将过滤器仅用作日志目的，因为框架内置的日志系统介绍了更科学的记录日志的方法，如果一定要将日志功能加入过滤器逻辑中，那么该日志应该侧重于记录该过滤器与业务领域逻辑相关的内容，而不是 MVC Action 或其他框架事件。 ServiceFilterAttributeServiceFilterAttribute 从 DI 中请求一个特定过滤器的实例，你应该在 ConfigureServices 方法中注册该过滤器类型，并在 ServiceFilter 引用它。12345678910public void ConfigureServices(IServiceCollection services)&#123; services.AddScoped&lt;AddHeaderFilterWithDi&gt;();&#125;[ServiceFilter(typeof(AddHeaderFilterWithDi))]public IActionResult Index()&#123; return View();&#125; TypeFilterAttributeTypeFilterAttribute 与 ServiceFilterAttribute 非常相似，但它并不是从 DI 中解析过滤器类型的实例，而是通过 Microsoft.Extensions.DependencyInjection.ObjectFactory 创建过滤器类型的实例。因此: 被 TypeFilterAttribute 类型引用的过滤器类型无需在 IoC 中注册。 TypeFilterAttribute 可以有选择地传递过滤器类型的构造函数参数。 以下示例演示了如何将构造函数参数传递给 TypeFilterAttribute:123456[TypeFilter(typeof(AddHeaderAttribute), Arguments = new object[] &#123; "Author", "Steve Smith (@ardalis)" &#125;)]public IActionResult Hi(string name)&#123; return Content($"Hi &#123;name&#125;");&#125; Authorization 过滤器 管道中第一批被执行的过滤器 有 before 方法，没有 after 方法 不要在该过滤器中的抛出异常 Resource 过滤器 实现 IResourceFilter 或 IAsyncResourceFilter 之一 包围大多数管理过滤器 只有 Authorization 过滤器先于它执行 Resource 过滤器用于短路请求的大多数工作，例如，缓存过滤器如果检查到响应位于缓存中，则跳过管道中的其余逻辑 Action 过滤器实现 IActionFilter 或 IAsyncActionFilter 接口之一，以下是一个示例 Action 过滤器:123456789101112public class SampleActionFilter : IActionFilter&#123; public void OnActionExecuting(ActionExecutingContext context) &#123; // do something before the action executes &#125; public void OnActionExecuted(ActionExecutedContext context) &#123; // do something after the action executes &#125;&#125; ActionExecutingContext 提供了以下属性: ActionArguments: 操作提供给方法的输入参数 Controller: 操作控制器实例 Result: 设置该值以短路该 Action 方法及其后的过滤器，抛出异常亦然，但会被认为是一个失败请求。 ActionExecutedContext 提供了以下属性: Canceled: 当 Action 执行短路时为 true Exception: 抛出异常时该值不为空，将该值显式设置为 null 则被认为异常已经过处理，之后 Result 属性将被处理。 对于 IAsyncActionFilter，执行 ActionExecutionDelegate 将: 同时执行所有后续的过滤器和 Action 方法本身 返回 ActionExecutedContext 要短路，则设置 ActionExecutingContext.Result 并且不要调用 ActionExecutionDelegate。 Exception 过滤器Exception 实现 IExceptionFilter 或 IAsyncExceptionFilter 接口之一。其用于实现通用错误处理策略。Exception 过滤器: 没有 before 和 after 事件 实现 OnException 或 OnExceptionAsync 处理发生在创建控制器，模型绑定，Action 过滤器或 Action 方法中未捕获的异常 不要在 Resource 过滤器，Result 过滤器或 MVC Result 执行过程中捕获异常 设置 ExceptionContext.ExceptionHandled 为 true 并返回一个请求响应以指示异常被处理。Exception 过滤器: 对于处理 MVC Action 中抛出的异常是最佳位置 不如错误处理中间件来得灵活 「仅当需要针对性对某个 MVC Action 进行特殊处理时采用 Exception 过滤器。」 在管道中使用过滤器中间件Resource 过滤器由于其包围了管道其后的所有执行过程，所以其职责非常类似于一个过滤器中间件。然而其与中间件最大的区别在于，Resource 过滤器是 MVC 的一部分，这意味着它们可以访问 MVC 的 context 和构造。 当使用中间件时同时也希望能够访问 MVC 的路由数据或仅仅为某个特定的 Controller 或 Action 服务。定义一个包含 Configure 方法的类型，以下示例展示了一个使用本地化中间件为请求建立当前文化:1234567891011121314151617181920212223public class LocalizationPipeline&#123; public void Configure(IApplicationBuilder applicationBuilder) &#123; var supportedCultures = new[] &#123; new CultureInfo("en-US"), new CultureInfo("fr") &#125;; var options = new RequestLocalizationOptions &#123; DefaultRequestCulture = new RequestCulture(culture: "en-US", uiCulture: "en-US"), SupportedCultures = supportedCultures, SupportedUICultures = supportedCultures &#125;; options.RequestCultureProviders = new[] &#123; new RouteDataRequestCultureProvider() &#123; Options = options &#125; &#125;; applicationBuilder.UseRequestLocalization(options); &#125;&#125;之后，可以在 Controller 上或 Action 上或全局地通过 MiddlewareFilterAttribute 应用该中间件:1234567[Route("&#123;culture&#125;/[controller]/[action]")][MiddlewareFilter(typeof(LocalizationPipeline))]public IActionResult CultureFromRouteData()&#123; return Content($"CurrentCulture:&#123;CultureInfo.CurrentCulture.Name&#125;," + $"CurrentUICulture:&#123;CultureInfo.CurrentUICulture.Name&#125;");&#125; 中间件过滤器与 Resource 过滤器运行在同一阶段。]]></content>
      <categories>
        <category>ASP.NET Core</category>
      </categories>
      <tags>
        <tag>aspnet-core</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ASP.NET Core 框架基础 - 管道与中间件]]></title>
    <url>%2Faspnetcore-fundamentals-pipelines%2F</url>
    <content type="text"><![CDATA[参考资料: 采用管道处理请求 管道如何处理请求 管道如何创建 中间件究竟是什么 本文大纲: 概述 一个简单的 Hello World 应用 管道的构成 定制管道 服务器 HttpApplication HostingApplication KestrelServer ServerAddressesFeature WebHost WebHostOptions 构建管道 WebHostBuilder 几个常用的扩展方法 HttpContext FeatureCollection DefaultHttpContext HttpContextFactory ApplicationBulder ApplicationBuilderFactory 中间件类型 中间件类型注册 概述HTTP 协议自身的特性决定了任何一个 Web 应用的工作方式都是监听、接收并处理 HTTP 请求，并最终对请求予以响应。HTTP 请求处理是管道式设计典型的应用场景，ASP.NET Core 根据一个具体的 HTTP 请求构建一个管道，接收到的 HTTP 请求消息像水一样流入这个管道，组成这个管道的各个环节依次对它作相应的处理。整个请求处理完成后的结果同样转变成消息逆向流入这个管道进行处理，并最终变成回复给客户端的 HTTP 响应。 一个简单的 Hello World 应用首先来看一个简单的 .NET Core 应用程序: 1234567891011public class Program&#123; public static void Main() &#123; new WebHostBuilder() .UseKestrel() .Configure(app =&gt; app.Run(async context=&gt; await context.Response.WriteAsync("Hello World"))) .Build() .Run(); &#125;&#125; WebHost 对象可以看成是 Web 应用的宿主，启动 Web 应用本质上就是启动 WebHost 宿主对象。WebHostBuilder 负责创建 WebHost 对象，它的 Build 方法创建并返回相应的 WebHost。 Configure 方法注册到 WebHostBuilder 上的委托对象(委托类型为 Action&lt;IApplicationBuilder&gt;)用于定制管道的逻辑。调用 WebHost 的扩展方法 Run 启动应用程序时，用于监听，接收，处理和响应 HTTP 请求的管道也随之被建立。 管道的构成HTTP 请求处理流程始于对请求的监听，终于对请求的响应，这两项工作均由同一个对象来完成，我们称之为 「服务器(Server)」 。尽管 ASP.NET Core 的请求处理管道可以任意定制，但是该管道必须有一个 Server，Server 是整个管道的「水龙头」。在上述的 Hello World 应用中，在 Build 一个 WebHost 之前，首先调用了扩展方法 UseKestrel，该方法就是为后续构建的管道注册一个名为 KestrelServer 的「服务器」。 调用 WebHost 的 Start 方法(调用 WebHost 的扩展方法 Run 时，它的 Start 方法会被自动调用)之后，定制的管道会被构建出来，管道的服务器将绑定到一个预设的端口(KestrelServer 默认采用 5000 作为监听端口)开始监听请求。HTTP 请求一旦抵达，服务器将其标准化并分发给管道后续的节点。管道中位于服务器之后的节点称为「中间件(Middleware)」。每个中间件都具有各自独立的功能，例如有专门实现路由功能的中间件，有专门实施用户认证的中间件。所谓的管道定制体现在根据具体的需求选择对应的中间件组成最终的请求处理管道。下图揭示了由一个服务器和一组中间件构成的请求处理管道:一个基于 ASP.NET Core 的应用程序通常是根据某个框架开发的，而框架本身就是通过某个或多个「中间件」构建出来的。ASP.NET Core MVC 就是典型的基于 ASP.NET Core 的开发框架，它定义了一个叫做「路由」的中间件实现了请求地址与 Controller/Action 之间的映射，并在此基础实现了激活 Controller，执行 Action 以及呈现 View 等一系列的功能。所以应用程序可以视为某个中间件的一部分，如果一定要将它独立出来，整个请求处理管道将呈现出如下图所示的结构: 定制管道在上述的 Hello World 程序中，调用扩展方法 UseKestrel 注册 KestrelServer 服务器之后，还调用 WebHostBuilder 的 Configure 的扩展方法注册了一个类型为 Action&lt;IApplicationBuilder&gt; 的委托对象。注册这个委托对象的目的在于对构建的管道定制请求处理逻辑，即为管道注册中间件。这个委托对象调用 ApplicationBuilder 的 Run 扩展方法注册了一个中间件来为每个请求响应一个「Hello World」字符串。1public static IWebHostBuilder Configure(this IWebHostBuilder hostBuilder, Action&lt;IApplicationBuilder&gt; configureApp) 除了调用 WebHostBuilder 的 Configure 方法来注册一个 Action&lt;IApplicationBuilder&gt; 类型的委托，注册中间件定义管道的逻辑更多地还是定义在一个单独的类型中。由于管道的定制总是在应用程序启动(Startup)的时候进行，一般称这个用于定制管道的类型为「启动类型」，并在大部分情况下会直接命名为 Startup。按照约定，通过注册中间件定制管道的操作会实现在名为 Configure 的方法中，方法的第一个参数必须是一个 IApplicationBuilder 接口的实例，后续可定义任意数量和类型的参数，当 ASP.NET Core 框架调用该方法的时候，会以依赖注入的方式提供这些参数的值。启动类型可以通过调用 WebHostBuilder 的扩展方法 UseStartup&lt;T&gt; 来指定，如下面的代码与前面演示的示例是完全等效的。12345678910111213141516171819public class Startup&#123; public void Configure(IApplicationBuilder app) &#123; app.Run(async context =&gt; await context.Response.WriteAsync("Hello World")); &#125;&#125;public class Program&#123; public static void Main() &#123; new WebHostBuilder() .UseKestrel() .UseStartup&lt;Startup&gt;() .Build() .Run(); &#125;&#125;在真正的项目开发中，我们会利用 ApplicationBuilder 注册相应的中间件进而构建一个符合需求的请求处理管道。如下所示，我们除了按照上面的方式调用扩展方法 UseMvc 注册了支撑 MVC 框架的中间件(实际上是一个实现路由的中间件)之外，还调用了其它的扩展方法注册了相应的中间件实现了对静态文件的访问(UseStaticFiles)，错误页面的呈现(UseExceptionHandler)以及基于 ASP.NET Identity Framework 的认证(UseIdentity):1234567891011public class Startup&#123; public void Configure(IApplicationBuilder app) &#123; app.UseExceptionHandler("/Home/Error"); app.UseStaticFiles(); app.UseIdentity(); app.UseMvc(); &#125;&#125; 服务器服务器是 ASP.NET Core 管道的第一个节点，它负责请求的监听和接收，并最终完成对请求的响应。服务器是所有实现了 IServer 接口的类型及其对象的统称。IServer 接口定义了一个只读属性 Features 返回描述自身特性集合的 IFeatureCollection 对象，Start 方法用于启动服务器。12345public interface IServer&#123; IFeatureCollection Features &#123; get; &#125; void Start&lt;TContext&gt;(IHttpApplication&lt;TContext&gt; application); &#125; Start 方法一旦执行，服务会马上开始监听工作。任何 HTTP 请求抵达，该方法接收一个 HttpApplication 对象创建一个上下文，并在此上下文中完成对请求的所有处理操作。当完成了对请求的处理任务之后，HttpApplication 对象会自行负责回收释放由它创建的上下文。 HttpApplicationASP.NET Core 请求处理管道由一个服务器和一组有序排列的中间件组合而成。如果在此之上作进一步抽象，将后者抽象成一个 HttpApplication 对象，该管道就成了一个 Server 和 HttpApplication 的组合。Server 将接收到的 HTTP 请求转发给 HttpApplication 对象，后续的请求完全由它来负责。HttpApplication 从服务器获得请求之后，会使用注册的中间件对请求进行处理，并最终将请求递交给应用程序。HttpApplication 针对请求的处理在一个执行上下文中完成，这个上下文为对单一请求的整个处理过程定义了一个边界。描述 HTTP 请求的 HttpContext 是这个执行上下文中最核心的部分，除此之外，我们还可以根据需要将其他相关的信息定义其中，所以 IHttpApplication&lt;TContext&gt; 接口采用泛型来表示定义这个上下文的类型。一个 HttpApplication 对象在接收到 Server 转发的请求之后完成三项基本的操作，即「创建上下文」，「在上下文中处理请求」以及「请求处理完成之后释放上下文」，这些操作通过三个方法来完成。123456public interface IHttpApplication&lt;TContext&gt;&#123; TContext CreateContext(IFeatureCollection contextFeatures); Task ProcessRequestAsync(TContext context); void DisposeContext(TContext context, Exception exception);&#125; CreateContext 和 DisposeContext 方法分别体现了执行上下文的创建和释放，CreateContext 方法的参数 contextFeatures 表示描述原始上下文的特性集合。在此上下文中针对请求的处理实现在另一个方法 ProcessRequestAsync 中。 HostingApplication在 ASP.NET Core 中，HostingApplication 类型是 IHttpApplication&lt;Context&gt; 默认实现类，它创建的执行上下文有如下定义:123456public struct Context&#123; public HttpContext HttpContext &#123; get; set; &#125; public IDisposable Scope &#123; get; set; &#125; public long StartTimestamp &#123; get; set; &#125;&#125; 该类型封装了一个 HttpContext 对象，后者是真正描述当前 HTTP 请求的上下文，承载着核心的上下文信息。除此之外，Context 还定义了 Scope 和 StartTimestamp 两个属性，两者与日志记录和事件追踪有关，前者用来将针对同一请求的多次日志记录关联到同一个上下文区限(见日志区限；后者表示请求开始处理的时间戳，如果在完成请求处理的时候记录下当时的时间戳，就可以计算出整个请求处理所花费的时间。 12345678public class HostingApplication : IHttpApplication&lt;HostingApplication.Context&gt;&#123; public HostingApplication(RequestDelegate application, ILogger logger, DiagnosticSource diagnosticSource, IHttpContextFactory httpContextFactory); public Context CreateContext(IFeatureCollection contextFeatures); public void DisposeContext(Context context, Exception exception); public Task ProcessRequestAsync(Context context);&#125; HostingApplication 的构造函数依赖一个 RequestDelegate 的委托对象，该对象由 IApplicationBuilder 注册的中间件生成，HttpContextFactory 用以创建 HttpContext 对象:123456789101112131415public class HostingApplication : IHttpApplication&lt;HostingApplication.Context&gt;&#123; private readonly RequestDelegate _application; private readonly DiagnosticSource _diagnosticSource; private readonly IHttpContextFactory _httpContextFactory; private readonly ILogger _logger; public HostingApplication(RequestDelegate application, ILogger logger, DiagnosticSource diagnosticSource, IHttpContextFactory httpContextFactory) &#123; _application = application; _logger = logger; _diagnosticSource = diagnosticSource; _httpContextFactory = httpContextFactory; &#125;&#125;logger 和 diagnosticSource 是与日志记录有关的参数。HostingApplication 对 CreateContext，ProcessRequestAsync 和 DisposeContext 有如下实现:12345678910111213141516171819202122public Context CreateContext(IFeatureCollection contextFeatures)&#123; //省略其他实现代码 return new Context &#123; HttpContext = _httpContextFactory.Create(contextFeatures), Scope = ..., StartTimestamp = ... &#125;;&#125; public Task ProcessRequestAsync(Context context)&#123; Return _application(context.HttpContext);&#125; public void DisposeContext(Context context, Exception exception)&#123; //省略其他实现代码 context.Scope.Dispose(); _httpContextFactory.Dispose(context.HttpContext);&#125; CreateContext 直接利用私有字段 _httpContextFactory 创建一个 HttpContext 对象并将其赋值给 Context 的同名属性。 ProcessRequestAsync 方法则使用 HttpContext 传入 RequestDelegate 委托。 DisposeContext 方法执行时 Context 属性的 Scope 会率先被释放，此后 调用 IHttpContextFactory.Dispose 方法释放 HttpContext 对象。 KestrelServer跨平台是 ASP.NET Core 一个显著的特性，而 KestrelServer 是目前微软推出的唯一一个能够真正跨平台的服务器。KestrelServer 基于 KestrelEngine 的网络引擎实现对请求的监听，接收和响应。KetrelServer 之所以可以跨平台，在于 KestrelEngine 是在 libuv 跨平台网络库上开发的。 libuv 是基于 Unix 系统针对事件循环和事件模型的网络库 libev 开发的。libev 不支持 Windows，有人在 libev 之上创建了一个抽象层以屏蔽平台之间的差异，这个抽象层就是 libuv。libuv 在 Windows 平台上使用 IOCP 的形式实现，到目前为止，libuv 已经支持更多除 Unix 和 Windows 以外的平台了，如 Linux(2.6)、MacOS 和 Solaris (121以及之后的版本)。下图揭示了 libuv 针对 Unix 和 Windows 的跨平台实现原理。 以下是 KestrelServer 类型的定义:123456789public class KestrelServer : IServer&#123; public IFeatureCollection Features &#123; get; &#125; public KestrelServerOptions Options &#123; get; &#125; public KestrelServer(IOptions&lt;KestrelServerOptions&gt; options, IApplicationLifetime applicationLifetime, ILoggerFactory loggerFactory); public void Dispose(); public void Start&lt;TContext&gt;(IHttpApplication&lt;TContext&gt; application);&#125; 除了实现接口 IServer 定义的 Features 属性之外，KestrelServer 还包含一个类型为 KestrelServerOptions 的只读属性 Options。这个属性表示 KestrelServer 的配置信息，构造函数通过输入参数 IOptions&lt;KestrelServerOptions&gt; 对其进行初始化，这里同样采用 Options 模式。例如可以通过一个 JSON 文件来配置 KestrelServer:12345&#123; "noDelay" : false, "shutdownTimeout" : "00:00:10", "threadCount" : 10&#125; 构造函数的另外两个参数 - IApplicationLifetime 与与应用的生命周期管理有关， ILoggerFactory 则用于创建记录日志的 Logger。 通常，通过调用 WebHostBuilder 的 UseKestrel 扩展方法来注册 KestrelServer。UseKestrel 方法有两个重载，其中一个接收一个类型为 Action&lt;KestrelServerOptions&gt; 的参数，通过赋值该参数直接完成对 KestrelServer 的配置。代码如下:12345public static class WebHostBuilderKestrelExtensions&#123; public static IWebHostBuilder UseKestrel(this IWebHostBuilder hostBuilder); public static IWebHostBuilder UseKestrel(this IWebHostBuilder hostBuilder, Action&lt;KestrelServerOptions&gt; options);&#125;由于服务器负责监听，接收和响应请求，它是影响整个 Web 应用响应能力和吞吐量最大的因素之一，为了更加有效地使用服务器，可以根据具体的网络负载状况对其作针对性的设置。现在来看看 KestrelServerOptions 类型的定义:123456789public class KestrelServerOptions&#123; //省略其他成员 public int MaxPooledHeaders &#123; get; set; &#125; public int MaxPooledStreams &#123; get; set; &#125; public bool NoDelay &#123; get; set; &#125; public TimeSpan ShutdownTimeout &#123; get; set; &#125; public int ThreadCount &#123; get; set; &#125;&#125; ServerAddressesFeatureKestrelServer 默认采用 http://localhost:5000 作为监听地址，服务器的监听地址可以显式指定，其通过 IServerAddressesFeature 提供支持。服务器接口 IServer 中定义了一个类型为 IFeatureCollection 的只读属性 Features，它表示当前服务器的特性集合，ServerAddressesFeature 作为一个重要的特性，就包含在这个集合中。该接口只有一个唯一的只读属性返回服务器的监听地址列表。ASP.NET Core 默认使用 ServerAddressesFeature 类型实现 IServerAddressesFeature 接口，定义如下:123456789public interface IServerAddressesFeature&#123; ICollection&lt;string&gt; Addresses &#123; get; &#125;&#125; public class ServerAddressesFeature : IServerAddressesFeature&#123; public ICollection&lt;string&gt; Addresses &#123; get; &#125;&#125;WebHost 通过依赖注入创建的服务器的 Features 属性中会默认包含一个 ServerAddressesFeature 对象。WebHost 会将显式指定的地址(一个或者多个)添加到该对象的监听地址列表中。地址列表其作为配置项保存在一个 Configuration 对象上，配置项对应的 Key 为 urls，可以通过 WebHostDefaults 的静态只读属性 ServerUrlsKey 返回这个 Key。123456new WebHostBuilder() .UseSetting(WebHostDefaults.ServerUrlsKey, "http://localhost:3721/") .UseKestrel() .UseStartup&lt;Startup&gt;() .Build() .Run(); WebHost 的配置最初来源于创建它的 WebHostBuilder，WebHostBuilder 提供了一个 UseSettings 方法来设置某个配置项的值。对监听地址的显式设置，最直接的编程方式是调用 WebHostBuilder 的扩展方法 UseUrls，该方法的实现逻辑与上面完全一致:12345public static class WebHostBuilderExtensions&#123; public static IWebHostBuilder UseUrls(this IWebHostBuilder hostBuilder, params string[] urls) =&gt;hostBuilder.UseSetting(WebHostDefaults.ServerUrlsKey, string.Join(ServerUrlsSeparator, urls)) ; &#125; WebHostASP.NET Core 管道是由作为应用程序宿主的 WebHost 对象创建出来的。应用的启动和关闭是通过启动或者关闭对应 WebHost 的方式实现的。IWebHost 接口定义了如下三个基本成员:123456public interface IWebHost : IDisposable&#123; void Start(); IFeatureCollection ServerFeatures &#123; get; &#125; IServiceProvider Services &#123; get; &#125;&#125;Start 方法用于启动宿主程序。编程中通常会调用它的一个扩展方法 Run 来启动 WebHost，Run 方法会在内部调用 Start 方法。当 WebHost 启动后，服务器立即开始监听请求。IWebHost 接口的默认实现类是 WebHost，它总是由一个 WebHostBuilder 对象创建，WebHost 的构造函数依赖 4 个参数:12345678910111213141516171819202122232425262728293031323334353637public class WebHost : IWebHost&#123; private IServiceCollection _appServices; private IServiceProvider _hostingServiceProvider; private WebHostOptions _options; private IConfiguration _config; private ApplicationLifetime _applicationLifetime; public IServiceProvider Services &#123; get; private set; &#125; public IFeatureCollection ServerFeatures &#123; get &#123; return this.Services.GetRequiredService&lt;IServer&gt;()?.Features; &#125; &#125; public WebHost(IServiceCollection appServices, IServiceProvider hostingServiceProvider, WebHostOptions options, IConfiguration config) &#123; _appServices = appServices; _hostingServiceProvider = hostingServiceProvider; _options = options; _config = config; _applicationLifetime = new ApplicationLifetime(); appServices.AddSingleton&lt;IApplicationLifetime&gt;(_applicationLifetime); &#125; public void Dispose() &#123; _applicationLifetime.StopApplication(); (this.Services as IDisposable)?.Dispose(); _applicationLifetime.NotifyStopped(); &#125; public void Start() &#123; &#125;&#125; appServices 从直接注册到 WebHostBuilder 上的服务而来 hostingServiceProvider 是由 appServices 创建的IServiceProvider。 只读属性 Services 返回一个 ServiceProvider 对象，其利用构造函数传入的 ServiceCollection 对象创建。 只读属性 ServerFeatures 返回服务器的特性集合，而服务器本身使用 ServiceProvider 获得 Dispose 方法释放服务器对象，并利用 ApplicationLifetime 发送相应的信号。 WebHostOptions一个 WebHostOptions 对象为构建的 WebHost 对象提供一些预定义的选项，这些选项很重要，它们决定了由 WebHost 构建的管道进行内容加载以及异常处理等方面的行为。以下是其类型定义:12345678910111213public class WebHostOptions&#123; public string ApplicationName &#123; get; set; &#125; public bool DetailedErrors &#123; get; set; &#125; public bool CaptureStartupErrors &#123; get; set; &#125; public string Environment &#123; get; set; &#125; public string StartupAssembly &#123; get; set; &#125; public string WebRoot &#123; get; set; &#125; public string ContentRootPath &#123; get; set; &#125; public WebHostOptions() public WebHostOptions(IConfiguration configuration) &#125;可以将这些选项定义在配置中，并利用 Options 模式创建一个 WebHostOptions 对象。 构建管道Start 方法真正启动 WebHost:123456789101112131415161718192021222324252627282930313233public void Start()&#123; //注册服务 IStartup startup = _hostingServiceProvider.GetRequiredService&lt;IStartup&gt;(); this.Services = startup.ConfigureServices(_appServices); //注册中间件 Action&lt;IApplicationBuilder&gt; configure = startup.Configure; configure = this.Services.GetServices&lt;IStartupFilter&gt;().Reverse().Aggregate(configure, (next, current) =&gt; current.Configure(next)); IApplicationBuilder appBuilder = this.Services.GetRequiredService&lt;IApplicationBuilder&gt;(); configure(appBuilder); //为服务器设置监听地址 IServer server = this.Services.GetRequiredService&lt;IServer&gt;(); IServerAddressesFeature addressesFeature = server.Features.Get&lt;IServerAddressesFeature&gt;(); if (null != addressesFeature &amp;&amp; !addressesFeature.Addresses.Any()) &#123; string addresses = _config["urls"] ?? "http://localhost:5000"; foreach (string address in addresses.Split(';')) &#123; addressesFeature.Addresses.Add(address); &#125; &#125; //启动服务器 RequestDelegate application = appBuilder.Build(); ILogger logger = this.Services.GetRequiredService &lt;ILogger&lt;MyWebHost&gt;&gt;(); DiagnosticSource diagnosticSource = this.Services.GetRequiredService&lt;DiagnosticSource&gt;(); IHttpContextFactory httpContextFactory = this.Services.GetRequiredService&lt;IHttpContextFactory&gt;(); server.Start(new HostingApplication(application, logger, diagnosticSource, httpContextFactory)); //对外发送通知 _applicationLifetime.NotifyStarted();&#125; 注册服务: Start 方法首先通过 ServiceProvider 获取 Startup 的实例，并调用 ConfigureServices 注册所有服务。 注册中间件: 使用 ServiceProvider 获取所有注册的 StartupFilter，并结合之前提取的 Startup 对象创建一个注册中间件的委托(Action&lt;IApplicationBuilder&gt;)。从 ServiceProvider 获取 ApplicationBuilder 对象作为参数传入该委托，完成中间件的注册。 设置服务器监听地址: 使用 ServiceProvider 提取注册在 WebHostBuilder 上的服务器对象，从该对象的 Features 属性中提取 IServerAddressesFeature 对象，从配置中提取显式指定的监听地址，将其逐个加入到 IServerAddressesFeature 的 Addresses 集合中。如果没有任何显式指定的监听地址，那么默认值为 http://localhost:5000。 启动服务器: 准备就绪的服务器由 IServer.Start 方法启动，该方法接收一个 HttpApplication&lt;TContext&gt; 作为参数，创建该接口的默认实现者 HostingApplication 需要 4 个参数: RequestDelegate: 中间件链表，通过 IApplicationBuilder.Build 获取。 Logger: 日志记录器，通过 ServiceProvider 获取。 DiagnosticSource: 通过 ServiceProvider 获取。 HttpContextFactory: Http 上下文工厂，通过 ServiceProvider 获取。 发布通知: 服务器成功启动之后，向外发送通知 WebHostBuilderWebHostBuilder 是 WebHost 的创建者，IWebHostBuilder 接口除了定义用来创建 WebHost 的核心方法 Build 之外，还定义了其他一些方法:123456789public interface IWebHostBuilder&#123; IWebHost Build(); IWebHostBuilder ConfigureServices(Action&lt;IServiceCollection&gt; configureServices); IWebHostBuilder UseLoggerFactory(ILoggerFactory loggerFactory); IWebHostBuilder ConfigureLogging(Action&lt;ILoggerFactory&gt; configureLogging); string GetSetting(string key); IWebHostBuilder UseSetting(string key, string value);&#125;ASP.NET Core 有两种注册服务的途径，一种是将服务注册实现在启动类的 ConfigureServices 方法中，另一种就是调用 IWebHostBuilder 的 ConfigureServices 方法。前者实际上是在 WebHost 启动时提取 Startup 对象调用其 ConfigureServices 进行注册，而 IWebHostBuilder.ConfigureServices 直接将服务提供给创建的 WebHost。 UseLoggerFactory 设置一个默认的 ILoggerFactory 对象，ConfigureLogging 则对 ILoggerFactory 进行配置，具体参见日志系统。 IWebHostBuilder 的默认实现类型时 WebHostBuilder，以下代码展示了除 Build 方法以外的其他成员的实现:1234567891011121314151617181920212223242526272829303132333435363738public interface IWebHostBuilderpublic class WebHostBuilder : IWebHostBuilder&#123; private List&lt;Action&lt;ILoggerFactory&gt;&gt; _configureLoggingDelegates = new List&lt;Action&lt;ILoggerFactory&gt;&gt;(); private List&lt;Action&lt;IServiceCollection&gt;&gt; _configureServicesDelegates = new List&lt;Action&lt;IServiceCollection&gt;&gt;(); private ILoggerFactory _loggerFactory = new LoggerFactory(); private IConfiguration _config = new ConfigurationBuilder().AddEnvironmentVariables("ASPNETCORE_").Build(); public IWebHostBuilder ConfigureLogging(Action&lt;ILoggerFactory&gt; configureLogging) &#123; _configureLoggingDelegates.Add(configureLogging); return this; &#125; public IWebHostBuilder ConfigureServices(Action&lt;IServiceCollection&gt; configureServices) &#123; _configureServicesDelegates.Add(configureServices); return this; &#125; public string GetSetting(string key) &#123; return _config[key]; &#125; public IWebHostBuilder UseLoggerFactory(ILoggerFactory loggerFactory) &#123; _loggerFactory = loggerFactory; return this; &#125; public IWebHostBuilder UseSetting(string key, string value) &#123; _config[key] = value; return this; &#125; ...&#125;默认创建了一个 Configuration 类型的字段 _config 表示应用使用的配置，它默认采用环境变量(用于筛选环境变量的前缀为ASPNETCORE_)作为配置源，GetSetting 和 UseSetting 方法都在内部操作这个字段。另一个字段 _loggerFactory 表示默认使用的 ILoggerFactory，UseLoggerFactory 方法指定的 LoggerFactory 用来对这个字段进行赋值。ConfigureLogging 和 ConfigureServices 仅仅将传入的委托对象保存在一个集合中。 Build 方法实现创建 WebHost 对象并注册必要的服务，以下列出这些服务的不完全列表: 用于注册服务和中间件的 Startup 对象。 用来创建 Logger 的 LoggerFactory 对象 构建中间件链表的 ApplicationBuilder 对象 创建 HTTP 上下文的 HttpContextFactory 对象 用户实现诊断功能的 DiagnosticSource 对象 用来保存承载环境的 HostingEnvironment 对象 以下代码展示了 Build 方法的实现:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class WebHostBuilder : IWebHostBuilder&#123; private List&lt;Action&lt;ILoggerFactory&gt;&gt; _configureLoggingDelegates = new List&lt;Action&lt;ILoggerFactory&gt;&gt;(); private List&lt;Action&lt;IServiceCollection&gt;&gt; _configureServicesDelegates = new List&lt;Action&lt;IServiceCollection&gt;&gt;(); private ILoggerFactory _loggerFactory = new LoggerFactory(); private IConfiguration _config = new ConfigurationBuilder().AddInMemoryCollection().Build(); public IWebHost Build() &#123; //根据配置创建WebHostOptions WebHostOptions options = new WebHostOptions(_config); //注册服务IStartup IServiceCollection services = new ServiceCollection(); if (!string.IsNullOrEmpty(options.StartupAssembly)) &#123; Type startupType = StartupLoader.FindStartupType(options.StartupAssembly, options.Environment); if (typeof(IStartup).GetTypeInfo().IsAssignableFrom(startupType)) &#123; services.AddSingleton(typeof(IStartup), startupType); &#125; else &#123; services.AddSingleton&lt;IStartup&gt;(_ =&gt; new ConventionBasedStartup(StartupLoader.LoadMethods(_, startupType, options.Environment))); &#125; &#125; //注册ILoggerFactory foreach (var configureLogging in _configureLoggingDelegates) &#123; configureLogging(_loggerFactory); &#125; services.AddSingleton&lt;ILoggerFactory&gt;(_loggerFactory); //注册服务IApplicationBuilder，DiagnosticSource和IHttpContextFactory services .AddSingleton&lt;IApplicationBuilder&gt;(_ =&gt; new ApplicationBuilder(_)) .AddSingleton&lt;DiagnosticSource&gt;(new DiagnosticListener("Microsoft.AspNetCore")) .AddSingleton&lt;IHttpContextFactory, HttpContextFactory&gt;() .AddOptions() .AddLogging() .AddSingleton&lt;IHostingEnvironment, HostingEnvironment&gt;() .AddSingleton&lt;ObjectPoolProvider, DefaultObjectPoolProvider&gt;(); //注册用户调用ConfigureServices方法设置的服务 foreach (var configureServices in _configureServicesDelegates) &#123; configureServices(services); &#125; //创建MyWebHost return new WebHost(services, services.BuildServiceProvider(), options, _config); &#125; &#125; 几个常用的扩展方法除了使用 GetSetting 和 UseSetting 方法来以键值对的形式来获取和设置配置项，还可以通过 UseConfiguration 扩展方法直接指定一个 IConfiguration 对象作为参数，该对象会原封不动的拷贝至内部的配置项中，其内部依旧是调用了 UseSettings 方法来实现的。1234public static class HostingAbstractionsWebHostBuilderExtensions&#123; public static IWebHostBuilder UseConfiguration(this IWebHostBuilder hostBuilder, IConfiguration configuration);&#125;WebHostBuilder 在创建 WebHost 的时候需要一个 WebHostOptions 对象，为了方便设置 WebHostOptions 的配置项，ASP.NET Core 定义了一系列扩展方法，这些方法最终也是通过 UseSettings 方法。1234567891011public static class HostingAbstractionsWebHostBuilderExtensions&#123; public static IWebHostBuilder CaptureStartupErrors(this IWebHostBuilder hostBuilder, bool captureStartupErrors); public static IWebHostBuilder UseContentRoot(this IWebHostBuilder hostBuilder, string contentRoot); public static IWebHostBuilder UseEnvironment(this IWebHostBuilder hostBuilder, string environment); public static IWebHostBuilder UseStartup(this IWebHostBuilder hostBuilder, string startupAssemblyName); public static IWebHostBuilder UseWebRoot(this IWebHostBuilder hostBuilder, string webRoot); public static IWebHostBuilder UseUrls(this IWebHostBuilder hostBuilder, params string[] urls); public static IWebHostBuilder UseServer(this IWebHostBuilder hostBuilder, IServer server); public static IWebHostBuilder UseUrls(this IWebHostBuilder hostBuilder, params string[] urls); &#125; HttpContext对于管道来说，请求的接收者和最终响应者都是服务器，服务器接收到请求之后会创建与之对应的「原始上下文」，请求的响应也通过这个「原始上下文」来完成。 但对于建立在管道上的应用程序来说，它们不需要关注管道究竟采用了何种类型的服务器，更不会关注由这个服务器创建的「原始上下文」。ASP.NET Core 定义了 HttpContext 抽象类来描述当前请求的上下文，对当前上下文的抽象解除了管道对具体服务器类型的依赖，这使得可以为 ASP.NET Core 应用程序自由地选择寄宿(Hosting)方式，而不是像传统的 ASP.NET 应用一样只能寄宿在 IIS 中。抽象的 HttpContext 为请求处理提供了标准化的方式，这使得位于管道中的中间件与具体的服务器类型进行了解耦，中间件只要遵循标准来实现其自身的逻辑即可。HttpContext 包含了当前请求的所有细节，可以直接利用它完成对请求的响应:12345678910111213141516public abstract class HttpContext&#123; public abstract IFeatureCollection Features &#123; get; &#125; public abstract HttpRequest Request &#123; get; &#125; public abstract HttpResponse Response &#123; get; &#125; public abstract ConnectionInfo Connection &#123; get; &#125; public abstract WebSocketManager WebSockets &#123; get; &#125; public abstract AuthenticationManager Authentication &#123; get; &#125; public abstract ClaimsPrincipal User &#123; get; set; &#125; public abstract IDictionary&lt;object, object&gt; Items &#123; get; set; &#125; public abstract IServiceProvider RequestServices &#123; get; set; &#125; public abstract CancellationToken RequestAborted &#123; get; set; &#125; public abstract string TraceIdentifier &#123; get; set; &#125; public abstract ISession Session &#123; get; set; &#125; public abstract void Abort();&#125; 当需要中止对请求的处理时，可通过为 RequestAborted 属性设置一个 CancellationToken 对象将终止通知发送给管道。如果需要对整个管道共享一些与当前上下文相关的数据，可以将它保存在 Items 属性表示的字典中。RequestServices 属性返回一个 IServiceProvider 对象，该对象为中间件提供注册的服务实例，只要相应的服务事先注册到指定的服务接口上，就可以利用这个 IServiceProvider 来获取对应的服务对象。 表示请求和响应的 HttpRequest 和 HttpResponse 同样是抽象类:123456789101112131415161718192021222324252627282930313233343536373839404142public abstract class HttpRequest&#123; public abstract QueryString QueryString &#123; get; set; &#125; public abstract Stream Body &#123; get; set; &#125; public abstract string ContentType &#123; get; set; &#125; public abstract long? ContentLength &#123; get; set; &#125; public abstract IRequestCookieCollection Cookies &#123; get; set; &#125; public abstract IHeaderDictionary Headers &#123; get; &#125; public abstract string Protocol &#123; get; set; &#125; public abstract IQueryCollection Query &#123; get; set; &#125; public abstract IFormCollection Form &#123; get; set; &#125; public abstract PathString Path &#123; get; set; &#125; public abstract PathString PathBase &#123; get; set; &#125; public abstract HostString Host &#123; get; set; &#125; public abstract bool IsHttps &#123; get; set; &#125; public abstract string Scheme &#123; get; set; &#125; public abstract string Method &#123; get; set; &#125; public abstract HttpContext HttpContext &#123; get; &#125; public abstract bool HasFormContentType &#123; get; &#125; public abstract Task&lt;IFormCollection&gt; ReadFormAsync(CancellationToken cancellationToken = default(CancellationToken));&#125;public abstract class HttpResponse&#123; public abstract HttpContext HttpContext &#123; get; &#125; public abstract int StatusCode &#123; get; set; &#125; public abstract IHeaderDictionary Headers &#123; get; &#125; public abstract Stream Body &#123; get; set; &#125; public abstract long? ContentLength &#123; get; set; &#125; public abstract string ContentType &#123; get; set; &#125; public abstract IResponseCookies Cookies &#123; get; &#125; public abstract bool HasStarted &#123; get; &#125; public abstract void OnCompleted(Func&lt;object, Task&gt; callback, object state); public virtual void OnCompleted(Func&lt;Task&gt; callback); public abstract void OnStarting(Func&lt;object, Task&gt; callback, object state); public virtual void OnStarting(Func&lt;Task&gt; callback); public virtual void Redirect(string location); public abstract void Redirect(string location, bool permanent); public virtual void RegisterForDispose(IDisposable disposable);&#125; FeatureCollection在 ASP.NET Core 管道式处理设计中，特性是一个非常重要的概念，它是实现抽象化的 HttpContext 的途径，不同类型的服务器在接收到请求时会创建一个「原始上下文」，接下来服务器将「原始上下文」的操作封装成一系列标准的特性对象(IFeature)，进而封装成一个 FeatureCollection 对象，当调用 DefaultHttpContext 相应的属性和方法时，其内部又借助封装的特性对象去操作「原始上下文」。 当原始上下文被创建出来之后，服务器会将它封装成一系列标准的特性对象，HttpContext 正是对这些特性对象的封装。这些特性对象对应的类型均实现了某个预定义的标准接口，接口定义了相应的属性来读写原始上下文中描述的信息，还定义了相应的方法来操作原始上下文。HttpContext 的 Features 属性返回这组特性对象的集合，类型为 IFeatureCollection，该接口用于描述某个对象所具有的一组特性，我们可以将其视为一个 Dictionary&lt;Type, object&gt; 对象，字典的 Value 代表特性对象，Key 则表示该对象的注册类型(特性描述对象的具体类型，具体类型的基类或者接口)。调用 Set 方法来注册特性对象，而 Get 方法则根据指定的注册类型得到对应的特性对象。12345678public interface IFeatureCollection : IEnumerable&lt;KeyValuePair&lt;Type, object&gt;&gt;, IEnumerable&#123; object this[Type key] &#123; get; set; &#125; bool IsReadOnly &#123; get; &#125; int Revision &#123; get; &#125; TFeature Get&lt;TFeature&gt;(); void Set&lt;TFeature&gt;(TFeature instance);&#125; 特性对象的注册和获取也可以通过的索引器来完成。如果 IsReadOnly 属性返回 True，便不能注册新的特性或修改已经注册的特性。只读属性 Revision 可视为 IFeatureCollection 对象的版本，注册新特性或修改现有的特性都将改变这个属性的值。 IFeatureCollection 的默认实现类型是 FeatureCollection:123456public class FeatureCollection : IFeatureCollection&#123; //其他成员 public FeatureCollection(); public FeatureCollection(IFeatureCollection defaults);&#125;FeatureCollection 类型的 IsReadOnly 总是返回 False，如果调用无参构造函数，它的 Revision 默认返回 0。如果调用第二个构造函数，其 Revision 属性将延续传入参数的 IFeatureCollection.Revision 的值，并采用递增来修改其值。 DefaultHttpContextASP.NET Core 使用 DefaultHttpContext 类型作为 HttpContext 的默认实现，原始上下文由「特性集合」来创建 HttpContext 的策略就体现在该类型上。DefaultHttpContext 的构造函数如下:1234public class DefaultHttpContext : HttpContext&#123; public DefaultHttpContext(IFeatureCollection features);&#125;无论是组成管道的中间件还是建立在管道上的应用程序，都统一采用 DefaultHttpContext 对象来获取请求信息，并利用它完成对请求的响应。针对 DefaultHttpContext 的调用(属性或方法)最终都转发给具体服务器创建的「原始上下文」，构造函数接收的 FeatureCollection 对象所代表的特性集合是这两个上下文对象进行沟通的唯一渠道。定义在 DefaultHttpContext 中的所有属性几乎都具有一个对应的特性，这些特性又都对应一个接口。下表列出了部分特性接口以及 DefaultHttpContext 对应的属性: 接口 属性 描述 IHttpRequestFeature Request 获取描述请求的基本信息 IHttpResponsetFeature Response 控制对请求的响应 IHttpAuthenticationFeature AuthenticationManger/User 提供用户认证的 AuthenticationHandler 对象和表示当前用户的 ClaimsPrincipal 对象 IHttpConnectionFeature Connection 提供描述当前 HTTP 连接的基本信息。 IItemsFeature Items 提供客户代码存放关于当前请求的对象容器。 IHttpRequestLifetimeFeature RequestAborted 传递请求处理取消通知和中止当前请求处理。 IServiceProvidersFeature RequestServices 提供根据服务注册创建的 ServiceProvider。 ISessionFeature Session 提供描述当前会话的 Session 对象。 IHttpRequestIdentifierFeature TraceIdentifier 为追踪日志(Trace)提供针对当前请求的唯一标识。 IHttpWebSocketFeature WebSockets 管理 WebSocket 其中最重要的两个接口为表示请求和响应的 IHttpRequestFeature 和 IHttpResponseFeature。这两个接口分别与抽象类 HttpRequest 和 HttpResponse 具有一致的定义。 1234567891011121314151617181920212223public interface IHttpRequestFeature&#123; string Protocol &#123; get; set; &#125; string Scheme &#123; get; set; &#125; string Method &#123; get; set; &#125; string PathBase &#123; get; set; &#125; string Path &#123; get; set; &#125; string QueryString &#123; get; set; &#125; string RawTarget &#123; get; set; &#125; IHeaderDictionary Headers &#123; get; set; &#125; Stream Body &#123; get; set; &#125;&#125;public interface IHttpResponseFeature&#123; int StatusCode &#123; get; set; &#125; string ReasonPhrase &#123; get; set; &#125; IHeaderDictionary Headers &#123; get; set; &#125; Stream Body &#123; get; set; &#125; bool HasStarted &#123; get; &#125; void OnCompleted(Func&lt;object, Task&gt; callback, object state); void OnStarting(Func&lt;object, Task&gt; callback, object state);&#125; DefaultHttpContext 对象中表示请求和响应的 Request 和 Response 属性就是分别提取 HttpRequestFeature 和 HttpResponseFeature 特性创建出 DefaultHttpRequest 和 DefaultHttpResponse 对象，它们分别继承自 HttpRequest 和 HttpResponse。以下是伪代码的实现:1234567891011121314151617public class DefaultHttpRequest : HttpRequest&#123; public IHttpRequestFeature RequestFeature &#123; get; &#125; public DefaultHttpRequest(DefaultHttpContext context) &#123; this.RequestFeature = context.HttpContextFeatures.Get&lt;IHttpRequestFeature&gt;(); &#125; public override Uri Url &#123; get &#123; return this.RequestFeature.Url; &#125; &#125; public override string PathBase &#123; get &#123; return this.RequestFeature.PathBase; &#125; &#125;&#125; 1234567891011121314151617181920212223242526public class DefaultHttpResponse : HttpResponse&#123; public IHttpResponseFeature ResponseFeature &#123; get; &#125; public override Stream OutputStream &#123; get &#123; return this.ResponseFeature.OutputStream; &#125; &#125; public override string ContentType &#123; get &#123; return this.ResponseFeature.ContentType; &#125; set &#123; this.ResponseFeature.ContentType = value; &#125; &#125; public override int StatusCode &#123; get &#123; return this.ResponseFeature.StatusCode; &#125; set &#123; this.ResponseFeature.StatusCode = value; &#125; &#125; public DefaultHttpResponse(DefaultHttpContext context) &#123; this.ResponseFeature = context.HttpContextFeatures.Get&lt;IHttpResponseFeature&gt;(); &#125;&#125; HttpContextFactory在服务器接收到请求时，它并不是直接利用原始上下文来创建 HttpContext 对象，而是通过 HttpContextFactory 来创建。IHttpContextFactory 接口除了定义创建 HttpContext 对象的 Create 方法之外，还定义了一个 Dispose 方法来释放指定的 HttpContext 对象。 HttpContextFactory 类是该接口的默认实现者，由它的 Create 方法创建并返回的是一个 DefaultHttpContext 对象:123456789101112public interface IHttpContextFactory&#123; HttpContext Create(IFeatureCollection featureCollection); void Dispose(HttpContext httpContext);&#125;public class HttpContextFactory : IHttpContextFactory&#123; //省略其他成员 public HttpContext Create(IFeatureCollection featureCollection); public void Dispose(HttpContext httpContext);&#125; 以上涉及的类型和接口和所在的命名空间： 类型或接口 命名空间 HttpContext Microsoft.AspNetCore.Http HttpRequest Microsoft.AspNetCore.Http HttpResponse Microsoft.AspNetCore.Http DefaultHttpRequest Microsoft.AspNetCore.Http.Internal DefaultHttpResponse Microsoft.AspNetCore.Http.Internal IHttpRequestFeature Microsoft.AspNetCore.Http.Features IHttpResponseFeature Microsoft.AspNetCore.Http.Features 以及它们之间的 UML 关系图: ApplicationBulder创建 WebHost 的 WebHostBuilder 提供了一个用于管道定制的 Configure 方法，它利用 ApplicationBuilder 参数进行中间件的注册。中间件在请求处理流程中体现为一个类型为 Func&lt;RequestDelegate，RequestDelegate&gt; 的委托对象，RequestDelegate 相当于一个 Func&lt;HttpContext, Task&gt; 对象，它体现了针对 HttpContext 所进行的某项操作，进而代表某个中间件针对请求的处理过程。那为何我们不直接用一个 RequestDelegate 对象来表示一个中间件，而将它表示成一个 Func&lt;RequestDelegate，RequestDelegate&gt; 对象呢？ 在多数情况下，具体的请求处理需要注册多个不同的中间件，这些中间件按照注册时间的顺序进行排列构成了管道。对于单个中间件来说，在它完成了自身的请求处理任务之后，需要将请求传递给下一个中间件作后续的处理。Func&lt;RequestDelegate，RequestDelegate&gt; 中作为输入参数的 RequestDelegate 对象代表一个委托链，体现了后续中间件对请求的处理。当某个中间件将自身实现的请求处理任务添加到这个委托链中，新的委托链将作为这个 Func&lt;RequestDelegate，RequestDelegate&gt; 对象的返回值。以上图为例，如果用一个 Func&lt;RequestDelegate，RequestDelegate&gt; 来表示中间件 B，那么作为输入参数的 RequestDelegate 对象代表的是中间件 C 对请求的处理操作，而返回值则代表 B 和 C 先后对请求的处理操作。如果一个 Func&lt;RequestDelegate，RequestDelegate&gt; 代表第一个从服务器接收请求的中间件(比如 A)，那么执行该委托对象返回的 RequestDelegate 实际上体现了整个管道对请求的处理。 现在，来看看 IApplicationBuilder 接口的定义:12345678910public interface IApplicationBuilder&#123; IServiceProvider ApplicationServices &#123; get; set; &#125; IFeatureCollection ServerFeatures &#123; get; &#125; IDictionary&lt;string, object&gt; Properties &#123; get; &#125; RequestDelegate Build(); IApplicationBuilder New(); IApplicationBuilder Use(Func&lt;RequestDelegate, RequestDelegate&gt; middleware);&#125; Use 方法实现对中间件的注册，而 Build 方法则将所有注册的中间件转换成一个 RequestDelegate 对象。除了这两个核心方法，IApplicationBuilder 接口还定义了三个属性，其中 ApplicationServices 返回根据最初服务注册生成的 ServiceProvider 对象，而 ServerFeatures 属性返回的 FeatureCollection 对象是描述 Server 的特性集合。字典类型的 Properties 属性供用户存储任意自定义的属性，而 New 方法会根据自己「克隆」出一个新的 ApplicationBuilder 对象，这两个 ApplicationBuilder 对象应用具有相同的属性集合。 从编程便利性考虑，很多预定义的中间件类型都具有对应的用来注册的扩展方法，比如 UseStaticFiles 注册处理静态文件请求的中间件。 ApplicationBuilder 类型是 IApplicationBuilder 的默认实现者，其定义了一个 List&lt;Func&lt;RequestDelegate, RequestDelegate&gt;&gt; 属性来存放所有注册的中间件，Use 方法只需要将指定的中间件添加到这个列表即可，而 Build 方法只需要逆序调用这些中间件对应的 Func&lt;RequestDelegate, RequestDelegate&gt; 对象就能得需要的 RequestDelegate 对象。值得一提的是，Build 方法在中间件链条的尾部添加了一个额外的中间件，该中间件会负责将响应状态码设置为 404，如果没有注册任何对请求作最终响应的中间件(这样的中间件将不会试图调用后续中间件)，整个管道会回复一个状态码为 404 的响应。123456789101112131415161718192021222324public class ApplicationBuilder : IApplicationBuilder&#123; private IList&lt;Func&lt;RequestDelegate, RequestDelegate&gt;&gt; middlewares = new List&lt;Func&lt;RequestDelegate, RequestDelegate&gt;&gt;(); public RequestDelegate Build() &#123; RequestDelegate app = context =&gt; &#123; context.Response.StatusCode = 404; return Task.FromResult(0); &#125;; foreach (var component in middlewares.Reverse()) &#123; app = component(app); &#125; return app; &#125; public IApplicationBuilder Use(Func&lt;RequestDelegate, RequestDelegate&gt; middleware) &#123; middlewares.Add(middleware); return this; &#125;&#125; ApplicationBuilderFactoryIApplicationBuilderFactory 是 ASP.NET Core 用来创建 IApplicationBuilder 的工厂，如下面的代码片段所示，该接口定义了唯一个方法 CreateBuilder 接收 FeatureCollection 对象参数 来创建 IApplicationBuilder 对象，该 IFeatureCollection 对象正是承载与服务器相关特性的集合。ApplicationBuilderFactory 类型是该接口的默认实现者，当 CreateBuilder 方法被调用的时候，它会直接将构造时提供 ServiceProvider 对象和 serverFeatures 参数表示的 IFeatureCollection 对象来创建 ApplicationBuilder 对象。1234567891011121314151617181920public interface IApplicationBuilderFactory&#123; IApplicationBuilder CreateBuilder(IFeatureCollection serverFeatures);&#125; public class ApplicationBuilderFactory : IApplicationBuilderFactory&#123; private readonly IServiceProvider _serviceProvider; public ApplicationBuilderFactory(IServiceProvider serviceProvider) &#123; this._serviceProvider = serviceProvider; &#125; public IApplicationBuilder CreateBuilder(IFeatureCollection serverFeatures) &#123; return new ApplicationBuilder(_serviceProvider, serverFeatures); &#125;&#125; 中间件类型虽然中间件最终体现为一个类型为 Func&lt;RequestDelegate, RequestDelegate&gt; 的委托对象，但是大部分情况下都会将中间件定义成一个单独的类型。中间件类型不要求实现某个接口或继承某个基类，但要遵循几个必要的约定。现在通过 ContentMiddleware 类来看看一个合法的中间件类型应该如何定义。1234567891011121314151617181920public class ContentMiddleare&#123; public RequestDelegate _next; public byte[] _content; public string _contentType; public ContentMiddleare(RequestDelegate next, byte[] content, string contentType) &#123; _next = next; _content = content; _contentType = contentType; &#125; public async Task Invoke(HttpContext context, ILoggerFactory loggerFactory) &#123; loggerFactory.CreateLogger&lt;ContentMiddleare&gt;().LogInformation($"Write content (&#123;_contentType&#125;)"); context.Response.ContentType = _contentType; await context.Response.Body.WriteAsync(_content,0, _content.Length); &#125;&#125;ContentMiddleware 中间件将任何类型的内容响应给客户端，它的 _content 和 _contentType 两个字段分别代表响应内容和媒体类型(内容类型或者 MIME 类型)，它体现了一个典型中间件类型的定义规则或者约定: 应该定义为非静态类。 具有一个公共构造函数。这个构造函数的第一个参数类型必须为 RequestDelegate，代表对请求的后续操作(可以视为下一个注册的中间件) 针对请求的处理定义在一个名为 Invoke 的公共实例方法，其返回类型为 Task。该方法的第一个参数类型为 HttpContext，代表当前 HTTP 上下文。可以为这个方法定义任意数量和类型的额外参数，当这个方法被执行的时候，系统将会采用依赖注入的方式为这些参数赋值。 中间件类型注册中间件类型的注册可以通过调用 IApplicationBuilder 接口的扩展方法 UseMiddleware 和 UseMiddleware&lt;TMiddleware&gt; 来注册。除了指定中间件的类型之外，我们还需要按照顺序指定目标构造函数的全部或部分参数。不过构造函数的第一个参数 RequestDelegate 不需要提供，如果只指定了部分参数，缺失的参数将会通过 ServiceProvider 提供。12345public static class UseMiddlewareExtensions&#123; public static IApplicationBuilder UseMiddleware&lt;TMiddleware&gt;(this IApplicationBuilder app, params object[] args); public static IApplicationBuilder UseMiddleware(this IApplicationBuilder app, Type middleware, params object[] args);&#125;可以按照下面的方式来注册上面定义的 ContentMiddleware 中间件:123new WebHostBuilder() .Configure(app =&gt; app.UseMiddleware&lt;ContentMiddleare&gt;(File.ReadAllBytes("girl.png"),"image/png"))...]]></content>
      <categories>
        <category>ASP.NET Core</category>
      </categories>
      <tags>
        <tag>aspnet-core</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ASP.NET Core 框架基础 - 日志系统]]></title>
    <url>%2Faspnetcore-fundamentals-logging%2F</url>
    <content type="text"><![CDATA[参考资料: Logging in ASP.NET Core Logging with Logger Message .NET Core 的日志 本文大纲: 前言 日志模型三要素 创建 Logger 采用依赖注入来创建日志 日志类别(Category) 日志级别(LogLevel) 日志事件 ID(EventId) 日志消息模板(Message Template) 日志过滤 通过配置创建日志过滤规则 以编程方式创建日志过滤规则 日志过滤规匹配算法 日志提供器别名 默认最小日志级别 日志全局过滤器委托 日志区限(Log Scopes) 内置日志提供器 Console 提供器 Debug 提供器 EventSource 提供器 Windows EventLog 提供器 TraceSource 提供器 Azure App Service 提供器 LoggerMessage 模式 LoggerMessage.Define LoggerMessage.DefineScope 前言.NET Core提供了独立的日志模型使我们可以采用统一的 API 来完成针对日志记录的编程，我们同时也可以利用其扩展点对这个模型进行定制，比如可以将第三方日志提供器整合到我们的应用中。 日志模型三要素日志记录编程的核心对象: ILogger: 将日志消息写到对应的目的地(如文件，数据库等) ILoggerFactory: 创建组合式的 Logger，该 Logger 其实是对一组 Logger 的封装，自身并不提供日志写入功能，而是委托内部封装的 Logger 来写日志。 ILoggerProvider: 创建具有写入日志功能的 Logger。 LoggerFactory 可以注册多个 LoggerProvider 对象，在进行日志编程时，我们会利用 LoggerFactory 对象创建 Logger 来写日志，而该对象委托的内部 Logger 则由这些 LoggerProvider 提供。这三者的关系如下: 创建 Logger引入以下 Nuget Package 以实现原始的日志功能: Microsoft.Extensions.Logging.Abstractions: 引入 ILoggerFactory 和 ILogger 接口 Microsoft.Extensions.Logging: 引入 ILoggerFactory 的默认实现 LoggerFactory Microsoft.Extensions.Logging.Console: 引入 ConsoleLoggerProvider Microsoft.Extensions.Logging.Debug: 引入 DebugLoggerProvider System.Text.Encoding.CodePages: 由于 .NET Core 在默认情况下并不支持中文编码，需要在程序启动的时候显式注册一个支持中文编码的 EncodingProvider 首先创建 LoggerFactory 对象，然后通过 AddProvider 方法将一个 ConsoleLoggerProvider 和 DebugLoggerProvider 对象注册到 LoggerFactory 上，这两个 LoggerProvider 的构造函数接收一个 Func&lt;string, LogLevel, bool&gt; 类型的参数，该委托对象的两个输入参数分别代表日志消息的类型和等级，布尔类型的返回值决定创建的 Logger 是否会写入给定的日志消息。由于传入的委托对象总是返回 True，意味着所有级别的日志消息均会被这两个 LoggerProvider 创建的 Logger 对象写入对应的目的地。日志提供器注册完成之后，调用 LoggerFactory 的 CreateLogger 方法创建一个指定类别的 Logger 对象。12345678910111213141516171819class Program&#123; static void Main(string[] args) &#123; // 注册 EncodingProvider 实现对中文编码的支持 Encoding.RegisterProvider(CodePagesEncodingProvider.Instance); Func&lt;string, LogLevel, bool&gt; filter = (category, level) =&gt; true; ILoggerFactory loggerFactory = new LoggerFactory(); loggerFactory.AddProvider(new ConsoleLoggerProvider(filter, false)); loggerFactory.AddProvider(new DebugLoggerProvider(filter)); ILogger logger = loggerFactory.CreateLogger(nameof(Program)); int eventId = 3721; logger.LogInformation(eventId, $"升级到 .NET Core version 1.0.0"); logger.LogWarning(eventId, "并发量接近上限"); logger.LogError(eventId, "数据库连接失败(数据库：&#123;Database&#125;，用户名：&#123;User&#125;)", "TestDb", "sa"); &#125;&#125; 采用依赖注入来创建日志在 ASP.NET Core 应用中，总是以依赖注入的方式来获取相关的服务类型实例，ILoggerFactory 就是服务类型的一种。在创建 ServiceCollection 对象之后，调用 AddLogging() 向其注册日志服务，再从 ServiceCollection 对象中获取 ILoggerFactory 对象，调用 ILoggerFactory 的 AddConsole() 和 AddDebug() 扩展方法完成日志提供器向 ILoggerFactory 的注册。12345678var logger = new ServiceCollection() .AddLogging() // call this extension method to register logging service .BuildServiceProvider() // build service provider to get services .GetService&lt;ILoggerFactory&gt;() // get ILoggerFactory service .AddConsole() // register console logger provider to logger factory .AddDebug() // register debug logger provider to logger factory .CreateLogger(nameof(Program)); // create logger of category 'Program' 同一个 LoggerFactory 可以注册多个 LoggerProvider，当 LoggerFactory 创建出相应的 Logger 对象来写入日志时，日志消息实际上会分发给所有 LoggerProvider。而每条日志消息都携带了日志等级， LoggerProvider 通过其构造函数传入的 Func 委托来过滤不同等级的日志消息，这样就实现了一条日志消息只写入特定的日志提供器的目的地。 日志类别(Category)每一条日志消息都带有日志类别信息，在创建 ILogger 时可以指定类别，类别为任何字符串值，但按照惯例日志类别为类型的完全限定名，例如: “TodoApi.Controllers.TodoController”。 调用 ILoggerFactory.CreateLogger 时可以指定日志类别:1234567891011public class TodoController : Controller&#123; private readonly ITodoRepository _todoRepository; private readonly ILogger _logger; public TodoController(ITodoRepository todoRepository, ILoggerFactory logger) &#123; _todoRepository = todoRepository; _logger = logger.CreateLogger("TodoApi.Controllers.TodoController"); &#125;更多时候使用 ILogger&lt;T&gt; 则更简单:1234567891011public class TodoController : Controller&#123; private readonly ITodoRepository _todoRepository; private readonly ILogger _logger; public TodoController(ITodoRepository todoRepository, ILogger&lt;TodoController&gt; logger) &#123; _todoRepository = todoRepository; _logger = logger; &#125; 日志级别(LogLevel)日志级别由轻至重分别为: Trace = 0: 提供给发开人员用于跟踪和调试的信息，通常包含一些敏感数据，绝不能暴露给用户 Debug = 1: 在开发与调试阶段帮助开发人员分析调试的信息，这些消息通常是短期有效的信息，在部署环境中不会启用该级别 Information = 2: 记录应用程序的正常行为的日志级别，这些消息通常具有长期有效性。 Warning = 3: 记录应用程序运行期间不正常或意外事件的日志，这些行为不会导致应用程序崩溃但需要记录下来以供后续调查。 Error = 4: 记录无法被处理的错误及异常，这些消息指示在单一事务边界内失败，但不影响应用程序的其他部分 Critical = 5: 记录需要立即进行修正的致命错误，最高警戒级别 ASP.NET Core 将框架级别的事件日志以 Debug 级别日志分发给不同的日志提供器。 日志事件 ID(EventId)每记录一条日志，都可以为其指定事件 ID，事件 ID 用于将一系列相互关联的日志消息串起来，例如，将某件产品添加至购物车相关的日志的 ID 可为 1000，而与结账付款的事件 ID 可为 1001。日志事件 ID 以数据的形式将不同的日志进行逻辑分组，方便日后的查阅与分析。 日志消息模板(Message Template)在调用 ILogger.Log() 时，需要为每条日志消息提供消息模板，该消息模板不同于传统 C# 格式化字符串和最新的插值字符串，其中包含命名占位符而不是数字占位符，填充到占位符的顺序又不与其名称相对应，而是按照占位符的顺序，日志框架这样设计是为了让日志提供器能够实现语义化或结构化的日志存储。如果采用以下方式写入日志:123string p1 = "parm1";string p2 = "parm2";_logger.LogInformation("Parameter values: &#123;p2&#125;, &#123;p1&#125;", p1, p2);将会得到的输出结果为:1Parameter values: parm1, parm2 按照笔者的理解，许多日志提供器都采用了将占位符参数以字段的形式进行存储的功能，在消息模板中的占位符既是可以在消息输出中被替代的字符串，也是在结构化存储中的字段信息，当收集到大量的日志数据之后，通过结构化查询语句将大大提供分析效率。 日志过滤可以针对特定的提供器，或类别，或所有提供器或所有类别指定最小记录的日志级别，小于该级别的日志消息将不会分布至相应的日志提供器，同样，可通过将日志级别设置为 LogLevel.None 来忽略所有日志。 通过配置创建日志过滤规则ASP.NET Core 项目模板的代码调用 CreateDefaultBuilder 方法了，该方法默认注册了 Console 和 Debug 提供器，同时告知日志系统查询 Logging 配置块来加载日志配置。1234567891011121314151617181920212223public static void Main(string[] args)&#123; var webHost = new WebHostBuilder() .UseKestrel() .UseContentRoot(Directory.GetCurrentDirectory()) .ConfigureAppConfiguration((hostingContext, config) =&gt; &#123; var env = hostingContext.HostingEnvironment; config.AddJsonFile("appsettings.json", optional: true, reloadOnChange: true) .AddJsonFile($"appsettings.&#123;env.EnvironmentName&#125;.json", optional: true, reloadOnChange: true); config.AddEnvironmentVariables(); &#125;) .ConfigureLogging((hostingContext, logging) =&gt; &#123; logging.AddConfiguration(hostingContext.Configuration.GetSection("Logging")); logging.AddConsole(); logging.AddDebug(); &#125;) .UseStartup&lt;Startup&gt;() .Build(); webHost.Run();&#125;配置数据以日志提供器和类别为单位指定了最小日志级别，例如:123456789101112131415161718192021&#123; "Logging": &#123; "IncludeScopes": false, "Debug": &#123; "LogLevel": &#123; "Default": "Information" &#125; &#125;, "Console": &#123; "LogLevel": &#123; "Microsoft.AspNetCore.Mvc.Razor.Internal": "Warning", "Microsoft.AspNetCore.Mvc.Razor.Razor": "Debug", "Microsoft.AspNetCore.Mvc.Razor": "Error", "Default": "Information" &#125; &#125;, "LogLevel": &#123; "Default": "Debug" &#125; &#125;&#125; 以编程方式创建日志过滤规则考虑以下代码:123456WebHost.CreateDefaultBuilder(args) .UseStartup&lt;Startup&gt;() .ConfigureLogging(logging =&gt; logging.AddFilter("System", LogLevel.Debug) .AddFilter&lt;DebugLoggerProvider&gt;("Microsoft", LogLevel.Trace)) .Build(); 第一个 AddFilter 方法指示所有提供器的 “System” 类别最小日志级别为 Debug。 第二个 AddFilter 方法指示 Debug 日志提供器的 “Microsoft” 类别最小日志级别为 Trace。 日志过滤规匹配算法综合以上配置项和编程方式添加的过滤规则，其可以解释为:]]></content>
      <categories>
        <category>ASP.NET Core</category>
      </categories>
      <tags>
        <tag>aspnet-core</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ASP.NET Core 框架基础 - 配置系统 Options 模式]]></title>
    <url>%2Faspnetcore-fundamentals-configuration-options%2F</url>
    <content type="text"><![CDATA[参考资料: Options pattern in ASP.NET Core http://www.cnblogs.com/artech/p/new-config-system-01.html Options Github Source 本文大纲: Options 模式 配置绑定 扩展方法 AddOptions OptionsManager IConfigureOptions ConfigureOptions 扩展方法 Configure 创建 Options 对象 Options 模式在真实的项目中我们大多采用 Options 模式来使用配置，Options 是配置的逻辑结构在对象层面的体现，通常，可以将一个 Configuration 对象绑定为一个 Options 对象。这样的绑定称为「配置绑定」。 配置绑定Microsoft.Extensions.Configuration.Binder 包为 IConfiguration 接口定义了 Bind 扩展方法，该方法接收一个代表 Options 的 object 类型的参数，并将 Configuration 的配置数据绑定到该对象上。1234public static class ConfigurationBinder&#123; public static void Bind(this IConfiguration configuration, object instance);&#125; 配置绑定的目标类型可以是一个简单的基元类型，也可以是一个自定义数据类型，还可以是一个数组、集合或者字典类型。上述 Bind 方法在进行配置绑定的过程中会根据不同的目标类型采用不同的策略。 Options 模式是对依赖注入的应用，通过调用 IServiceCollection 扩展方法 AddOptions 添加 Options 模式的服务注册，再通过 Configure&lt;TOptions&gt; 扩展方法配置目标 Options 的 T 类型。消费方利用 ServiceProvider 得到一个类型为 IOptions&lt;TOptions&gt; 的服务对象后，读取 Value 属性得到由配置绑定生成的 TOptions 实例。1234567IConfiguration config = ...;FormatOptions options = new ServiceCollection() .AddOptions() .Configure&lt;FormatOptions&gt;(config.GetSection("Format")) .BuildServiceProvider() .GetService&lt;IOptions&lt;FormatOptions&gt;&gt;() .Value; 扩展方法 AddOptions当调用 IServiceCollection 的 AddOptions 时，该方法对 IOptions&lt;&gt; 接口注册一个服务，该服务的实现类型为 OptionsManager&lt;TOptions&gt; ，生命周期为 Singleton。配置绑定生成的 Options 对象最终都是通过 OptionsManager&lt;TOptions&gt; 创建的。12345public static IServiceCollection AddOptions(this IServiceCollection services)&#123; services.TryAdd(ServiceDescriptor.Singleton(typeof(IOptions&lt;&gt;), typeof(OptionsManager&lt;&gt;))); return services;&#125;以下是几个相关类型的定义: OptionsManager12345public class OptionsManager&lt;TOptions&gt; : IOptions&lt;TOptions&gt; where TOptions: class, new()&#123; public OptionsManager(IEnumerable&lt;IConfigureOptions&lt;TOptions&gt;&gt; setups); public virtual TOptions Value &#123; get; &#125;&#125; OptionsManager&lt;TOptions&gt; 类型的构造函数接受一个 IConfigureOptions&lt;TOptions&gt; 的集合，Options 对象的创建体现在 Value 属性上。该属性的实现非常简单，它先调用 TOptions 类型的默认无参构造函数(TOptions 代表的类型必须具有一个默认无参构造函数)创建一个空的 TOptions 对象，然后将其传递给构造函数中指定的ConfigureOptions&lt;TOptions&gt; 对象逐个进行转换处理。 IConfigureOptions1234public interface IConfigureOptions&lt;in TOptions&gt; where TOptions: class&#123; void Configure(TOptions options);&#125; IConfigureOptions&lt;TOptions&gt; 接口定义了一个唯一的 Configure 方法，该方法将 Options 对象作为输入参数。 ConfigureOptions123456789101112public class ConfigureOptions&lt;TOptions&gt;: IConfigureOptions&lt;TOptions&gt; where TOptions : class, new()&#123; public Action&lt;TOptions&gt; Action &#123; get; private set; &#125; public ConfigureOptions(Action&lt;TOptions&gt; action) &#123; this.Action = action; &#125; public void Configure(TOptions options) &#123; this.Action(options); &#125;&#125; IConfigure&lt;TOptions&gt; 的默认实现类型 ConfigureOptions&lt;TOptions&gt; 在其构造函数中接收一个 Action&lt;TOptions&gt; 委托对象，再在 Configure 方法中调用该委托实现对 TOptions 的操作。 扩展方法 Configure123456789101112131415public static IServiceCollection Configure&lt;TOptions&gt;(this IServiceCollection services, string name, IConfiguration config, Action&lt;BinderOptions&gt; configureBinder) where TOptions : class&#123; if (services == null) &#123; throw new ArgumentNullException(nameof(services)); &#125; if (config == null) &#123; throw new ArgumentNullException(nameof(config)); &#125; return services.AddSingleton&lt;IConfigureOptions&lt;TOptions&gt;&gt;(new NamedConfigureFromConfigurationOptions&lt;TOptions&gt;(name, config, configureBinder));&#125; 在调用 IServiceCollection 的 Configure 方法时，其内部注册了一个 IConfigureOptions&lt;TOptions&gt; 接口的单例服务，其实际类型为 NamedConfigureFromConfigurationOptions&lt;TOptions&gt;，该类型最终继承自 ConfigureOptions&lt;TOptions&gt; 类型，并且在其构造函数中声明了一个匿名方法作为 Action&lt;TOptions&gt; 的参数传入 NamedConfigureFromConfigurationOptions&lt;TOptions&gt; 中，最终实现配置绑定。12public NamedConfigureFromConfigurationOptions(string name, IConfiguration config, Action&lt;BinderOptions&gt; configureBinder) : base(name, options =&gt; config.Bind(options, configureBinder)) 创建 Options 对象Options 编程模式以两个注册到 ServiceCollection 的服务为核心，这两个服务对应的服务接口分别是: IOptions&lt;TOptions&gt;: 直接提供最终绑定了配置数据的 Options 对象 IConfigureOptions&lt;TOptions&gt;: 在 Options 对象返回之前对它实施相应的初始化工作。 这个两个服务分别通过扩展方法 AddOptions 和 Configure 方法注册到指定的 ServiceCollection 中，服务的真实类型分别是 OptionsManager&lt;TOptions&gt; 和 NamedConfigureFromConfigurationOptions&lt;TOptions&gt;，后者派生于 ConfigureOptions&lt;TOptions&gt;。下图所示的 UML 体现了 Options 模型中涉及的这些接口／类型以及它们之间的关系。]]></content>
      <categories>
        <category>ASP.NET Core</category>
      </categories>
      <tags>
        <tag>aspnet-core</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ASP.NET Core 框架基础 - 配置系统]]></title>
    <url>%2Faspnetcore-fundamentals-configuration%2F</url>
    <content type="text"><![CDATA[参考资料: Configuration in ASP.NET Core http://www.cnblogs.com/artech/p/new-config-system-01.html 本文大纲: 前言 从编程角度认识配置系统 从设计角度认识配置系统 配置数据的转换 Configuration 对象 ConfigurationProvider 对象 ConfigurationSource 对象 ConfigurationBuilder 对象 对象关系图 同步 Configuration 的更改 前言配置 API 提供了统一的方式以键值对的形式来读取和设置配置项，配置项在运行时从多个配置源读取信息，并以一个多层级的字典表树来存储这些值。配置源支持以下提供器: 文件格式(INI, JSON 和 XML) 命令行参数 环境变量 内存对象 Secret Manager 存储 Azure Key Vault 自定义配置源提供器 任何一个配置项的值都映射到一个字符串键，框架内置了实现类型将配置项映射到一个 POCO 对象。Options 模式使用 Options 类型代表一组关联的设置项。 从编程角度认识配置系统从编程角度来看，开发人员主要用到了以下三个对象 Configuration: 客户代码最终使用的包含配置项的对象 ConfigurationBuilder: 构建 Configuration 的对象 ConfigurationSource: 配置源对象 读取配置时，根据配置的定义方式创建相应的 ConfigurationSource 对象，并将其注册到创建的 ConfigurationBuilder 对象上，后者利用注册的这些 ConfigurationSource 提供最终的 Configuration 对象。 IConfiguration, IConfigurationSource 和 IConfigurationBuilder 接口分别代表这些对象的抽象，三者均定义在 Microsoft.Extensions.Configuration.Abstractions 包中，默认实现定义在 Microsoft.Extensions.Configuration 包中。 虽然大部分情况下配置从整体来说都具有结构化的层次关系，但是「原子」配置项都以最简单的「键-值对」的形式来体现，并且键和值通常都是字符串。 1234var configBuilder = new ConfigurationBuilder();var configuration = configBuilder .Add(new MemoryConfigurationSource &#123; InitialData = source &#125;) .Build(); 这里首先创建了一个 ConfigurationBuilder 对象，然后将一个 MemoryConfigurationSource 对象注册到它上面，随后调用 IConfigurationBuilder.Build 方法得到一个 IConfiguration 对象。 真实项目中涉及的配置大都具有结构化的层次，Configuration 对象同样具有这样的结构，结构化配置具有一个配置树，一个 Configuration 对象对应这棵树的某个节点，而整棵配置树也可由根节点对应的 Configuration 来表示，以键值对体现的原子配置项对应配置树中不具有子节点的「叶子节点」。 从设计角度认识配置系统配置具有多种原始来源，如内存对象，物理文件，数据库或其他自定义存储介质。如果采用物理文件来存储配置数据，我们还可以选择不同的文件格式(JSON, XML 和 INI)。因此配置的原始数据结构是不确定的，配置模型的最终目的在于提取原始的配置数据并将其转换成一个 Configuration 对象以对客户代码提供统一的编程模型。 配置数据的转换配置从原始结构向逻辑结构的转换需要一种「中间结构」——数据字典，整棵配置树的所有节点都会转换成基于字典的中间结构，最终再完成到 Configuration 对象的转换，父子级节点之间以 : 进行连接。 一个 Configuration 对象具有树形层次结构的意思不是说该类型具有对应的数据成员(字段或属性)定义，而是它提供的 API 「在逻辑上体现出树形层次结构」，配置树是一种逻辑结构。 Configuration 对象一个 Configuration 对象表示配置树的某个配置节点，表示根节点的对象与表示其它配置节点的对象是不同的，所以配置模型采用 IConfigurationRoot 接口来表示根节点，根节点以外的其他配置节点则用 IConfigurationSection 接口表示，这两个接口都继承自 IConfiguration。下图为我们展示了由一个 ConfigurationRoot 对象和一组 ConfigurationSection 对象构成的配置树。下面的代码展示了 IConfigurationRoot 接口的定义，该接口仅定义了一个 Reload 方法实现对配置数据的重新加载。ConfigurationRoot 对象表示配置树的根，也代表整棵配置树，如果它被重新加载，意味着整棵配置树的所有配置数据均被重新加载。1234public interface IConfigurationRoot : IConfiguration&#123; void Reload();&#125;非根配置节点的 IConfigurationSection 接口具有如下三个属性: Key: 只读，用来唯一标识多个具有相同父节点的 ConfigurationSection 对象 Path 表示当前配置节点在配置树中的路径，该路径由多个 Key 值组成，并采用冒号(:)分隔纵深节点。Path 和 Key 的值体现了当前配置节在整个配置树中的位置。 Value: 表示当前 IConfigurationSection 配置节点的值。只有配置树的叶子节点对应的ConfigurationSection 对象的 Value 属性才有值，非叶子节点对应的 ConfigurationSection 对象仅表示存放子配置节点的逻辑容器，它们的 Value 为 Null。值得一提的是，这个 Value 属性并不是只读的，而是可读可写的，但是写入的值不会被持久化，因为配置树只是逻辑结构，而非物理结构。所以一旦配置树被重新加载，写入的值将会丢失。123456public interface IConfigurationSection : IConfiguration&#123; string Path &#123; get; &#125; string Key &#123; get; &#125; string Value &#123; get; set; &#125;&#125; 现在来看看 IConfiguration 接口的定义: 12345678public interface IConfiguration&#123; IEnumerable&lt;IConfigurationSection&gt; GetChildren(); IConfigurationSection GetSection(string key); IChangeToken GetReloadToken(); string this[string key] &#123; get; set; &#125;&#125; GetChildren: 返回 ConfigurationSection 的集合，表示所有从属于它的配置节点 GetSection: 根据指定的 key 返回一个具体的子配置节点。key 参数与当前配置对象的 Path 属性的值进行组合以确定目标配置节点所在的路径。 GetReloadToken: 返回当配置重新加载时进行回调的 IChangeToken 对象，有关 IChangeToken 详见后文。 以下示例通过不同的 key 值获得相同配置节点的值:12345678910111213141516171819Dictionary&lt;string, string&gt; source = new Dictionary&lt;string, string&gt;&#123; ["A:B:C"] = "ABC"&#125;;IConfiguration root = new ConfigurationBuilder() .Add(new MemoryConfigurationSource &#123; InitialData = source &#125;) .Build(); IConfigurationSection section1 = root.GetSection("A:B:C");IConfigurationSection section2 = root.GetSection("A:B").GetSection("C");IConfigurationSection section3 = root.GetSection("A").GetSection("B:C"); Debug.Assert(section1.Value == "ABC");Debug.Assert(section2.Value == "ABC");Debug.Assert(section3.Value == "ABC"); Debug.Assert(!ReferenceEquals(section1, section2));Debug.Assert(!ReferenceEquals(section1, section3)); Debug.Assert(null != root.GetSection("D"));虽然上述代码得到的 ConfigurationSection 对象均指向配置树的同一个节点，但是它们并非同一个对象。当调用 GetSection 方法时，无论配置树是否存在一个与指定路径匹配的配置节点，它总是会创建一个 ConfigurationSection 对象。 IConfiguration 的索引器执行与 GetSection 方法相同的逻辑。 ConfigurationProvider 对象虽然每种不同类型的配置源都具有一个对应的 ConfigurationSource 类型，但对原始数据的读取并不由 ConfigurationSource 实现，而是委托一个对应的 ConfigurationProvider 对象来完成。不同配置类型的 ConfigurationSource 由不同的 ConfigurationProvider 实现读取。ConfigurationProvider 将配置数据从原始结构转换为数据字典，因此定义在 IConfigurationProvider 接口中的方法大多为针对字典对象的操作:12345678public interface IConfigurationProvider&#123; void Load(); bool TryGet(string key, out string value); void Set(string key, string value); IEnumerable&lt;string&gt; GetChildKeys(IEnumerable&lt;string&gt; earlierKeys, string parentPath)&#125;配置数据通过调用 ConfigurationProvider 的 Load 方法完成加载。TryGet 方法获取由指定的Key 所标识的配置项的值。ConfigurationProvider 是只读的，ConfigurationProvider 只负责从持久化资源中读取配置数据，而不负责更新保存在持久化资源的配置数据，它的 Set 方法设置的配置数据只会保存在内存中。ConfigurationProvider 的 GetChildKeys 方法用于获取某个指定配置节点的所有子节点的 Key。 ConfigurationSource 对象ConfiurationSource 在配置模型中代表配置源，它通过注册到 ConfigurationBuilder 上为后者创建的 Configuration 提供原始的配置数据。由于原始配置数据的读取实现在相应的 ConfigurationProvider 中，所以 ConfigurationSource 的作用在于提供相应的 ConfigurationProvider。如下面的代码片段所示，该接口具有一个唯一的 Build 方法根据指定的 ConfigurationBuilder 对象提供对应的ConfigurationProvider。1234public interface IConfigurationSource&#123; IConfigurationProvider Build(IConfigurationBuilder builder);&#125; ConfigurationBuilder 对象ConfigurationBulder 在整个配置模型中处于一个核心地位，它是 Configuration 的创建者，IConfigurationBulder 接口定义了两个方法，其中 Add 方法用于注册 ConfigurationSource，最终的 Configuration 则通过 Build 方法创建，后者返回一个代表整棵配置树的ConfigurationRoot 对象。注册的 ConfigurationSource 保存在 Sources 属性表示的集合中，Properties 属性则以字典的形式存放任意的自定义数据。12345678public interface IConfigurationBuilder&#123; IEnumerable&lt;IConfigurationSource&gt; Sources &#123; get; &#125; Dictionary&lt;string, object&gt; Properties &#123; get; &#125; IConfigurationBuilder Add(IConfigurationSource source); IConfigurationRoot Build();&#125;配置系统提供了 ConfigurationBulder 类型作为 IConfigurationBulder 接口的默认实现者。 无论是 ConfigurationRoot 还是 ConfigurationSection，它们自身都没有维护任何数据。这句话有点自相矛盾，因为配置树仅仅是 API 在逻辑上所体现的数据结构，并不代表具体的配置数据也是按照这样的结构进行存储的。 对象关系图配置系统的四个核心对象之间的关系简单而清晰，可以通过一句话来概括: ConfigurationBuilder 利用注册的 ConfigurationSource 得到相应的 ConfigurationProvider，再调用 ConfigurationProvider 的 Load 方法读取原始配置数据并创建出相应的 Configuration 对象。下图所示的 UML 展示了配置模型涉及的主要接口/类型以及它们之间的关系: 同步 Configuration 的更改参考配置的同步机制是如何实现的？]]></content>
      <categories>
        <category>ASP.NET Core</category>
      </categories>
      <tags>
        <tag>aspnet-core</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ASP.NET Core 框架基础 - 文件系统]]></title>
    <url>%2Faspnetcore-fundamentals-filesystem%2F</url>
    <content type="text"><![CDATA[参考资料: ASP.NET Core 的文件系统 File Providers in ASP.NET Core 本文大纲: 抽象的「文件系统」 FileProvider 抽象 文件系统的实现者 PhysicalFileProvider EmbeddedFileProvider CompositeFileProvider 监控变化 文件系统详解 FileInfo &amp; GetFileInfo 方法 DirectoryContents &amp; GetDirectoryContents 方法 ChangeToken 及 Watch 方法 路径前缀 「/」 对象关系图 抽象的「文件系统」ASP.NET Core 利用一个抽象化的 FileProvider 以统一的方式提供所需的文件。FileProvider 是所有实现了 IFileProvider 接口的类型的统称，FileProvider 是个抽象的概念，所以由它构建的也是一个抽象的文件系统。 这个文件系统采用目录的方式来组织和规划文件，这里所谓的目录和文件都是抽象的概念，并非对一个具体物理目录和文件的映射。文件系统的目录仅仅是文件的逻辑容器，而文件可能对应一个物理文件，也可能保存在数据库中，或者来源于网络，甚至有可能根本就不能存在，其内容需要在读取时动态生成。 一个 FileProvider 可以视为针对一个根目录的映射。目录除了可以存放文件之外，还可以包含多个子目录，所以目录/文件在整体上呈现出树形层细化结构。 FileProvider 抽象IFileProvider 接口提供了获取文件信息(IFileInfo)和目录信息的方法，并支持追踪变化并发送通知(IChangeToken)的功能。 IFileInfo 接口代表单独的文件信息或目录，其含有以下属性: Exists: 标识是否存在 IsDirectory: 标识是否为目录 Name: 描述「文件」的名称 Length: 以字节计算 LastModified: 上次修改的日期 CreateReadStream: 调用该方法来读取内容 文件系统的实现者IFileProvider 内置了三个实现类型: Physical: 访问真实的物理文件结构 Embedded: 访问嵌套于程序集内的文件 Composite: 组合来自于其他提供器的文件和目录访问 PhysicalFileProviderPhysicalFileProvider 实现了对访问物理文件系统的支持，其内部包裹了 System.IO.File 类型，该类型将所有可访问路径限制在一个根目录下，在初始化该类型时必须为其提供一个代表目录的路径参数。以下代码演示了如何创建一个 PhysicalFileProvider:123IFileProvider provider = new PhysicalFileProvider(applicationRoot);IDirectoryContents contents = provider.GetDirectoryContents(""); // the applicationRoot contentsIFileInfo fileInfo = provider.GetFileInfo("wwwroot/js/site.js"); // a file under applicationRoot EmbeddedFileProvider在 .NET Core 中，通过在 .csproj 文件中使用 &lt;EmbeddedResource&gt; 元素将文件嵌套至程序集中:123456&lt;ItemGroup&gt; &lt;EmbeddedResource Include="Resource.txt;**\*.js" Exclude="bin\**;obj\**;**\*.xproj;packages\**;@(EmbeddedResource)" /&gt; &lt;Content Update="wwwroot\**\*;Views\**\*;Areas\**\Views;appsettings.json;web.config"&gt; &lt;CopyToPublishDirectory&gt;PreserveNewest&lt;/CopyToPublishDirectory&gt; &lt;/Content&gt;&lt;/ItemGroup&gt; 向 EmbeddedFileProvider 类型的构造函数提供 Assembly 对象来创建它。1var embeddedProvider = new EmbeddedFileProvider(Assembly.GetEntryAssembly());嵌套资源没有「目录」的概念，不同命名空间的资源同样可以通过 . 语法来访问。EmbeddedFileProvider 类型的构造器接收一个可选的 baseNamespace 参数，指定该参数可以将调用 GetDirectoryContents 方法访问的范围限制在该命名空间下。 CompositeFileProviderCompositeFileProvider 组合多个 IFileProvider 对象并暴露一个针对不同 provider 的统一访问接口，创建 CompositeFileProvider 实例需要向其传递一个或多个 IFileProvider 对象。123var physicalProvider = _hostingEnvironment.ContentRootFileProvider;var embeddedProvider = new EmbeddedFileProvider(Assembly.GetEntryAssembly());var compositeProvider = new CompositeFileProvider(physicalProvider, embeddedProvider); 监控变化IFileProvider 包含一个 Watch 方法对监控文件和目录变化提供了支持，该方法接收一个路径参数，该参数可通过 globbing patterns 来指定多个文件。Watch 方法返回一个 IChangeToken 对象，该对象包含一个 HasChanged 属性和一个 RegisterChangeCallback 方法。RegisterChangeCallback 在指定路径的文件发送变化后被调用。 值得注意的是，每一个 IChangeToken 对象仅监控一次变化。单个 ChangeToken 对象的使命在于当绑定的数据源第一次发生变换时对外发送相应的信号，而不具有持续发送数据变换的能力。它具有一个 HasChanged 属性表示数据是否已经发生变化，而并没有提供一个让这个属性「复位」的方法。 如果需要对文件进行持续监控，需要在注册的回调中重新调用 FileProvider 的 Watch 方法，并利用新生成的 ChangeToken 再次注册回调。除此之外，考虑到 ChangeToken 的 RegisterChangeCallback 方法以一个 IDisposable 对象的形式返回回调注册对象，我们应该在对回调实施二次注册时调用第一次返回的回调注册对象的 Dispose 方法将其释放掉。 或者，可以使用定义在 ChangeToken 类型中如下两个方法 OnChange 方法来注册数据发生改变时自动执行的回调。这两个方法具有两个参数: Func&lt;IChangeToken&gt;: 用于创建 ChangeToken对象的委托对象 Action&lt;object&gt;/Action&lt;TState&gt;: 代表回调操作的委托对象 12345678910111213141516171819202122public static class ChangeToken&#123; public static IDisposable OnChange(Func&lt;IChangeToken&gt; changeTokenProducer, Action changeTokenConsumer) &#123; Action&lt;object&gt; callback = null; callback = delegate (object s) &#123; changeTokenConsumer(); changeTokenProducer().RegisterChangeCallback(callback, null); &#125;; return changeTokenProducer().RegisterChangeCallback(callback, null); &#125; public static IDisposable OnChange&lt;TState&gt;(Func&lt;IChangeToken&gt; changeTokenProducer, Action&lt;TState&gt; changeTokenConsumer, TState state) &#123; Action&lt;object&gt; callback = null; callback = delegate (object s) &#123; changeTokenConsumer((TState) s); changeTokenProducer().RegisterChangeCallback(callback, s); &#125;; return changeTokenProducer().RegisterChangeCallback(callback, state); &#125;&#125; 也可以使用 TaskCompletionSource 对象:123456789101112private static async Task MainAsync()&#123; IChangeToken token = _fileProvider.Watch("quotes.txt"); var tcs = new TaskCompletionSource&lt;object&gt;(); token.RegisterChangeCallback(state =&gt; ((TaskCompletionSource&lt;object&gt;)state).TrySetResult(null), tcs); await tcs.Task.ConfigureAwait(false); Console.WriteLine("quotes.txt changed");&#125; 基于 Docker 容器和网络共享的文件系统不会正确的发送改变通知，可通过设置 DOTNET_USE_POLLINGFILEWATCHER 环境变量为 1 或者 true 每 4 秒轮询文件改变。 文件系统详解FileProvider 的定义:123456public interface IFileProvider&#123; IFileInfo GetFileInfo(string subpath); IDirectoryContents GetDirectoryContents(string subpath); IChangeToken Watch(string filter);&#125; FileInfo &amp; GetFileInfo 方法可以通过向 GetFileInfo 传递一个子路径(通常为相对路径)来访问指定文件的信息，当调用这个方法的时候，无论指定的路径是否存在，该方法总是返回一个具体的 FileInfo 对象。即使指定的路径对应一个具体的目录，这个 FileInfo 对象的 IsDirectory 也总是返回 False（它的Exists属性也返回False）。 DirectoryContents &amp; GetDirectoryContents 方法调用 FileProvider 的 GetDirectoryContents 方法，目录内容通过该方法返回 DirectoryContents 对象来表示。一个 DirectoryContents 对象实际上表示一个 FileInfo 的集合，组成这个集合的所有 FileInfo 是对所有文件和子目录的描述。和 GetFileInfo 方法一样，不论指定的目录是否存在，GetDirectoryContents 方法总是会返回一个具体的 DirectoryContents 对象，它的 Exists 属性会帮助我们确定指定目录是否存在。1234public interface IDirectoryContents : IEnumerable&lt;IFileInfo&gt;&#123; bool Exists &#123; get; &#125;&#125; ChangeToken 及 Watch 方法目前仅 PhysicalFileProvider 类型提供了 Watch 方法的实现，它会委托一个 FileSystemWatcher 对象来完成最终的文件监控任务。Watch 方法的返回类型为 IChangeToken 接口，ChangeToken 可视为一个与某个数据进行关联，并在数据发生变化对外发送通知的令牌。如果关联的数据发生改变，它的 HasChanged 属性将变成 True。调用它的 RegisterChangeCallback 方法注册一个在数据发生改变时可以自动执行的回调方法。该方法以一个 IDisposable 对象的形式返回注册对象，原则上讲我们应该在适当的时机调用其 Dispose 方法注销回调的注册，以免内存泄漏。IChangeToken 接口的另一个属性 ActiveChangeCallbacks，它表示当数据发生变化时是否需要主动执行注册的回调操作。 路径前缀 「/」无论是调用 GetFileInfo，GetDirectoryContents 方法指定的目标文件和目录的路径，还是在调用 Watch 方法时指定筛选表达式，都是针对当前 FileProvider 根目录的相对路径。指定的这个路径可以采用 / 字符作为前缀，但是这个前缀是不必要的。 对象关系图文件系统还涉及到其他一些对象，如 DirectoryContents、FileInfo 和 ChangeToken。这些对象都具有对应的接口定义，下图所示的 UML 展示了涉及的这些接口以及它们之间的关系。]]></content>
      <categories>
        <category>ASP.NET Core</category>
      </categories>
      <tags>
        <tag>aspnet-core</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CRQS - 命令与查询职责分离]]></title>
    <url>%2Farchitecture-cqrs%2F</url>
    <content type="text"><![CDATA[参考资料: CQRS 背景CQRS 代表 Command Query Responsibility Segregation，命令与查询职责分离。 最原始的 CRUD 案例一定是仅包含数据库访问功能的应用程序:随着需求的不断增长，想要以更加个性化的方式从系统中「读取」数据，例如将多条记录合并成一条，从多张数据表中组成新的虚拟表。在「更新」方面，我们想要在持久化之前添加验证规则或从现有数据计算出合理的值。我们会发现越来越多信息的组合才是对应用程序有价值的数据，开发人员通过会在域模型之上建立概念模型以供消费方使用。 引入 CQRS 旨在将用于展示和修改系统状态的模型从概念模型中分离，在概念模型中同时包含两者将引入对两者都没有好处的复杂度。下图展示了一个 CQRS 应用程序模型:内存对象可能使用相同的数据库，也可能使用不同的数据库。使用单独的数据库意味着需要某种通信机制来同步数据。 在决定采用 CQRS 之前仍需思考再三，因为它会给项目引入复杂度，更高的复杂度意味着更高的风险。CRUD 仍然是许多系统最适合最简单的模型。CQRS 主要运用在复杂度较高的域模型设计和对性能要求较高的系统中。]]></content>
      <categories>
        <category>Architecture and Pattern</category>
      </categories>
      <tags>
        <tag>architecture</tag>
        <tag>cqrs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Repository 模式和工作单元]]></title>
    <url>%2Farchitecture-repository-pattern%2F</url>
    <content type="text"><![CDATA[参考资料: Repository Pattern UnitOfWork Design the infrastructure persistence layer Repository 模式Repository 是引入域模型与数据源提供器之间的对象，它们封装了访问数据源的功能，抽象出通用的数据访问方法，提供了更好的可维护性并将域模型与具体的数据访问组件进行解耦。 在「企业应用架构模式」一书中，Martin Fowler 这样描述一个 Repository: A repository performs the tasks of an intermediary between the domain model layers and data mapping, acting in a similar way to a set of domain objects in memory. Client objects declaratively build queries and send them to the repositories for answers. Conceptually, a repository encapsulates a set of objects stored in the database and operations that can be performed on them, providing a way that is closer to the persistence layer. Repositories, also, support the purpose of separating, clearly and in one direction, the dependency between the work domain and the data allocation or mapping. Repository 模式让数据提供层便于测试Repository 模式使得编写单元测试代码变得更加简单，当 Repository 模式的接口位于独立于具体实现的工程，便可采用模拟数据源的方式编写「假的」Repository 实现，让所有依赖 Repository 的类型的测试不再依赖具体的数据源实现，而将测试的重点放到域模型的核心逻辑上。 工作单元当将数据读取或写入数据库时，跟踪修改记录是很重要的一环，否则将无法回滚数据。在实践中，可以一旦对象状态发生变化，就修改数据库中对应的数据，这种方式将导致非常多的小的数据库访问，速度将非常慢；也可以在对象交互期间开启事务，但这会引起并发任务时的数据不同步问题。「工作单元」跟踪对对象所做的所有变更，并最后反映在数据库中。 传统 DAL 层与 Repository 模式的区别数据访问对象直接在存储引擎上执行数据访问逻辑，而Repository首先在内存中标记对象的状态变化，进而在恰当的时机提交事务。Repository 采用「工作单元」来处理事务。这意味着一个具体的用户的行为(例如注册账号)造成的系统数据变化将在一个事务中处理。 使用 Repository 隐含着一种意图倾向，即域模型需要什么 Repository 便提供什么，一切都以域的需求为核心。而 DAL 则是作为组件存在，它不关心业务规则。]]></content>
      <categories>
        <category>Architecture and Pattern</category>
      </categories>
      <tags>
        <tag>architecture</tag>
        <tag>dotnet</tag>
        <tag>repository-pattern</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《实现领域驱动设计》读书笔记(6) - 战术建模之领域服务]]></title>
    <url>%2Fddd-tactical-domain-service%2F</url>
    <content type="text"><![CDATA[系列大纲: 《实现领域驱动设计》读书笔记 本文大纲: 前言 什么是领域服务 独立的接口和命名实践 前言领域中的服务表示一个无状态的操作，它用于实现特定于某个领域的任务。当某个操作不适合放在实体和值对象上时，最好的方式便是使用领域服务了。有时我们倾向于使用聚合根上的静态方法来实现这些操作，但是在 DDD 中，这是一种代码异味。 什么是领域服务虽然领域服务中有 “服务” 这个词，但它并不意味着作为远程的，重量级的事务操作的提供方。当领域中的某个操作过程或转换过程不是实体或值对象的职责时，我们便应该将该操作放在一个单独的接口中，即领域服务。参考以下几点来对领域模型建模: 执行一个显著的业务操作过程 对领域对象进行转换 以多个领域对象作为输入进行计算，结果产生一个值对象。 以上第三点提到的 “计算”，也应该具有 “显著的业务操作过程” 的特点。请确保领域服务是无状态的，并且能够明确的表达限界上下文中的「通用语言」。 过度得使用领域服务将导致贫血领域模型，即所有的业务逻辑都位于领域服务中，而不是实体和值对象中。以下的例子是一个使用领域服务的情况，假设我们有以下需求: 系统必须对 User 进行认证(authenticate)，并且只有当 Tenant 处于激活状态时才能对 User 进行认证。 密码必须经过加密，且不能使用明文密码 此时，认证细节不属于 Tenant 或 User 的职责，应该创建一个专门处理认证逻辑的领域服务，客户端伪代码如下:12var authenticationService = DomainRegistry.AuthenticationService();var userDescriptor = authenticationService.Authenticate(tenantId, username, password);客户端只需获取到一个无状态的 AuthenticationService，然后调用它的 Authenticate 方法即可。与认证有关的所有实现细节放在领域服务中，在需要的情况下，领域服务可以使用任何领域对象来完成操作，包括对密码的加密过程。客户端不需要知道任何认证细节。该方法返回一个 UserDescriptor 值对象，这是一个很小的对象，并且是安全的。 而调用这段代码的客户方，在多数情况下为「应用服务」，它可以进一步将该 UserDescriptor 对象返回给它自己的调用者，由此可见领域服务和应用服务的区别。 独立的接口和命名实践如果该领域服务可能有多种实现，那么应该为其定义单独的接口，该接口应该与身份相关聚合(比如 Tenant，User 和 Group)定义在相同的「模块」中，因为 AuthenticationService 也是一个与身份相关的概念。而该接口的实现类——如果正在使用「依赖倒置原则」或「六边形架构」，可以放置在基础设施层的某个模块中。 在 C# 中通常以 I 字符开头来表示接口，此处的接口名称为 IAuthenticationService，但如果这里将实现类命名为 AuthentionService 或 DefaultAuthenticationService，这通常意味着根本就不需要一个接口，如果领域服务有多个实现类，那么应该根据各种实现类的特点进行命名，这也意味着在领域中存在一些特定的功能。对于非技术性的领域服务来说，去除接口是不会破坏可测试性的，因为该服务依赖的所有接口都可以注入进来。 依据笔者的理解，作者此处是想说明，接口很容易遭到滥用，很多模块将接口和其默认实现定义在同一个包中，这通常可以由一个单一的实现类来代替。]]></content>
      <categories>
        <category>Domain-Driven Design</category>
      </categories>
      <tags>
        <tag>ddd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《实现领域驱动设计》读书笔记(5) - 战术建模之值对象]]></title>
    <url>%2Fddd-tactical-value-object%2F</url>
    <content type="text"><![CDATA[系列大纲: 《实现领域驱动设计》读书笔记 本文大纲: 不变性 概念整体 可替换性 值对象相等性 无副作用行为 最小化集成 用值对象表示标准类型 实现 持久化值对象 单个值对象 值对象集合序列化到单个列中 使用数据库实体保存多个值对象 ORM 与枚举状态对象 值对象用于度量和描述事物，即便一个领域概念必须建模成实体，在设计时也应该更偏向于将其作为值对象的容器，而不是子实体的容器 笔者曾一度认为值对象就是 C# 语言中使用 struct 结构来表示的多个数据代表一个整体的集合，后来发现书中讲到的值对象无关技术实现，而是从概念上定义它的职责，包括不可变性和非唯一性。 同样的，在有了实体这把武器之后，当一个实体需要嵌套其他对象时，实体经常遭到滥用。当面临将对象定义为实体还是值对象的选择时，由于缺乏对于值对象的充分认识，很多开发人员选择了嵌套实体。 不变性当我们只关心某个对象的属性时，该对象便可作为一个值对象，为其添加有意义的属性，并赋予它们相应的行为。值对象在其生命周期中是「不可变」的，本身代表了某种状态，它没有任何身份标识，也应该尽量避免像实体一样复杂。在设计得当的前提下，我们可以对值对象的实例进行创建和传递，甚至在使用完之后将其直接扔掉。我们不必担心客户代码对值对象进行修改，一个值对象的生命周期可长可短，它就像一个无害的过客在系统中来来往往。 当决定一个领域概念是否是一个值对象时，考虑以下特征： 它度量或者描述了领域中的一件东西 它可以作为不变量 它将不同的相关的属性组合成一个概念性的整体 当度量和描述改变时，可以用另一个值对象予以替换 它可以和其他值对象进行相等性比较 它不会对协作对象造成副作用 为了保持值对象的不变性，创建它所依赖的参数必须一次性全部传给其构造函数，之后任何时间都不可能再改变它。有时根据需要，会在值对象中引用实体对象，这种情况需要谨慎，当实体对象的状态发生改变时，引用它的值对象也将发生改变，这违背了值对象不变性特征。 概念整体编程语言提供的基元类型(如 string, int, double 等)似乎是值对象的最佳类型，但有时，这种思维方式会造成对基元类型的滥用。 假如需要在 「ThingOfWorth」 类中加入名为 「Name」 的属性，我们自然而然的会想到将其定义为 string 类型，但很快我们就发现该类型的名字需要以不同的方式进行展示，此时，处理展示方式的逻辑就会莫名其妙的由客户代码来完成，例如：123// 客户代码String name = thingOfWorth.name();String capitalizedName = name.subString(0,1).toUpperCase() + name.subString(1).toLowerCase(); 在以上示例中，客户代码自己试图解决 name 的大小写问题。通过定义 「ThingName」 类型，我们可以将与 name 有关的所有逻辑操作放到该类型中，然后在构造该值对象时进行格式化，客户代码只需调用相应的方法即可得到结果，而不必自行处理这些逻辑。 有些编程语言允许我们简单地向一个类添加新的行为(例如 C# 的扩展方法)。此时，你可能会想着用 Double 类型来表示货币，如果需要计算不同货币之间的汇率，我们只需要向 Double 类型添加 convertToCurrency(Currency aCurrency) 扩展方法即可。但是在这种场景下使用语言特性就一定是一个好主意吗？首先，和货币相关的行为很有可能丢失在浮点数计算中；其次，Double 类型也丝毫没有表达出领域概念。很快，我们就会丢掉领域关注点。 当你试图将多个属性加在一个实体上，这有可能弱化了各个属性之间的关系，那么此时就应该考虑将这些相互关联的属性组合在一个值对象中了。每个值对象都是一个「内聚的概念整体」，它表达了通用语言中的一个概念。 可替换性值对象的可替换性可通过数字的替换来理解，假设领域中有一个名为 total 的概念，该概念用整数表示。如果 total 的当前值为 3，但是之后需要重设为 4，此时我们并不会将整数修改成 4，而是简单地将 total 的值重新赋值为 4。 从语言层面来说，这里的修改其实是对该属性赋新值，但看上去像是修改，实际上只是语法糖，原先为 3 的内存并不会被修改为 4，而是被新的代表 4 的内存块替代。 考虑下面一种更复杂的值对象替换：123FullName name = new FullName("金","沐");// 稍后name = new FullName("金","灶沐"); 这里，我们并没有使用 FullName 类型的某个方法来修改其自身的状态(这破坏了值对象的不变性)，而是构造一个新的值对象实例来替换原来的实例。 值对象相等性值对象的相等性应该由组成其实例的每一个属性及其类型来决定，在上文的 「FullName」 对象中，当两个 「FullName」 实例的每个属性及其类型都相等，我们才认为两个实例相等，尽管他们在内存中是不同的地址。值对象的相等性可用来支撑「聚合」唯一标识的比较，实体的唯一标识是不能改变的，这可以部分通过值对象的不变性实现。值对象的整体概念也可以用来支撑不只一个属性的实体标识，同时，如果实体的唯一标识需要一些「无副作用行为」，这些行为便可以在值对象上实现。 无副作用行为一个对象的方法可以设计成一个「无副作用函数(Side-Effect Free Function)」，该函数表示对某个对象的操作，只用于产生输出，而不会修改对象的状态。对于不变的值对象而言，所有的方法都必须是无副作用函数。下面的例子通过调用 「FullName」 对象上的无副作用方法将该对象本身替换成另一个实例：123FullName name = new FullName("金","沐");// 稍后name = name.withMiddleInitial("灶"); 这里的代码更具表达性，withMiddleInitial 方法并没有修改值对象的状态，因此它不会产生副作用。该方法通过已有 firstName 和 lastName，外加传入的 middleName 创建一个新的 FullName 值对象实例。withMiddleInitial() 还捕获到了重要的领域业务逻辑，从而避免了将这些逻辑泄漏到客户代码中。 这里所说的捕获重要的领域业务逻辑，是指该方法本身是具有表达性的，比起使用 new 语句创建实例，更像是调用了该实例支持的某个行为满足了客户代码的需求。 有些值对象的方法引用了实体，这存在一些问题。例如下面的代码，我们有一个实体对象 product，该对象被值对象 BusinessPriority 引用。1float priority = businessPriority.priorityOf(product); 我们至少可以看出以下问题： BusinessPriority 不仅依赖 Product 类型，还试图去理解该实体的内部状态，我们应该尽量使值对象只依赖于它自己的属性，并且只理解它自身的状态。 阅读本段代码的人并不知道使用了 Product 的哪些部分，这种表达方法并不明确，从而降低了模型的清晰度。更好的方式是只传入需要用到的 Product 属性。 更重要的是，在将实体作为参数的值对象方法中，我们很难看出该方法是否会对实体进行修改，测试也将变得非常困难。 有了以上分析，我们需要对值对象进行改进，要增加一个值对象的健壮性，我们传给值对象方法的参数依然应该是值对象。这样我们可以获得更高层次的无副作用行为：1float priority = businessPriority.priority(product.businessPriorityTotals()); 这里，我们把 Product 实体的 BusinessPriorityTotals 值对象传递给了 priority() 方法。 如果打算使用编程语言提供的基本值对象类型，而不使用特定的值对象，我们是无法将领域特定的无副作用函数分配给编程语言提供的基元值对象的。有些真正简单的属性是没有必要特殊对待的。例如，一些布尔类型或数值类型，它们已经能够自给了，并不需要额外的功能支持，也并不和实体中的其他属性关联。这些简单的属性称为意义整体。 最小化集成当模型概念从上游上下文流入下游上下文时，尽量使用值对象来表示这些概念。这样做的好处是可以达到最小化集成，即最小化下游模型中用于管理职责的属性数目。 用值对象表示标准类型系统中既有表示事物的实体和描述实体的值对象，同时还存在「标准类型(Standard Type)」来区分不同的类型。假设通用语言中定义了一个 「PhoneNumber」 值对象，同时需要为每个 「PhoneNumber」 对象制定一个类型，用以区分家庭电话，移动电话，工作电话还是其他类型的电话号码。不同类型的电话号码类型需要建模成一种类的层级关系吗？为每一个类型创建一个类对于客户代码的使用来说是非常困难的。此时，你需要标准类型来描述不同的电话号码，比如 Home，Mobile，Work 或者 Other。 枚举类型是实现标准类型的一种简单方法。枚举提供了一组有限数量的值对象，它非常轻量且无副作用。通常来说，没有必要为标准类型提供描述信息，只需要名字就足够了。为什么？文本描述通常只在用户界面层中才会用到，此时可以用一个显示资源和类型名字匹配起来。很多时候用于显示的文本都需要进行本地化，因此将这种功能放在模型中并不合适。通常来说，在模型中使用标准类型的名字是最好的方式。 为了维护方便，最好是为标准类型创建单独的限界上下文。 有些标准类型所表达的概念不像是某种标准而更像是一种状态，此时标准类型实现为状态模式，但为每一种状态创建单独的类会使系统变得复杂。对于实体的状态类来说，有些行为来自于自身，有些继承自抽象基类，这一方面在子类和父类之间形成了紧耦合，另一方面使代码的可读性变差。如果你不打算使用状态模式，那么枚举可能是最简单的方法。 一个共享不变的值对象可以从持久化存储中获取，此时可以通过标准类型的「领域服务」或「工厂」来获取值对象。我们应该为每组标准类型创建一个领域服务或工厂(比如一个服务处理电话号码类型，一个服务处理邮寄地址类型，另一个服务处理货币类型)，服务或工厂将按需从持久化存储中获取标准类型，而客户方代码并不知道这些标准类型是来自数据库中的。另外，使用领域服务或工厂还使得我们可以加入不同的缓存机制，由于值对象在数据库中是只读的，并且在整个系统中是不变的，缓存机制也将变得更加简单安全。 总的来说，建议尽量使用枚举来表示标准类型，即便你认为某个标准类型更像一种状态模式。 实现通常来说，值对象至少包含两个构造函数，第一个构造函数接受用于构建对象状态的所有属性参数，称为主构造函数。该构造函数调用私有的 setter 方法初始化默认的对象状态，该私有的 setter 方法向我们展示了一种自委派性。 只有主构造函数才能使用自委派性来设置属性值，除此之外，其他任何方法都不能使用 setter 方法。由于所有的 setter 方法都是私有的，消费方是没有机会调用这些方法的，这是保持值对象不变性的两个重要因素。 第二个构造函数用于将一个值对象复制到另一个新的值对象，即复制构造函数。它将构造过程委派给主构造函数，先从原对象中取出各个属性，再将这些属性作为参数传给主构造函数。 复制构造函数对于测试来说是非常重要的，测试对象时，我们希望验证值对象的不变性，通过复制构造函数创建一个原实例的副本，验证两者的相等性。 持久化值对象以下着重讨论如何持久化包含值对象的聚合实例。聚合的读取和保存通过资源库完成。 有时，值对象需要以实体的身份进行持久化。换句话说，某个值对象实例会单独占据一张表中的某条记录，而该表也是专门为这个值对象类型而设计的，它甚至拥有自己的主键列。当面临「对象 - 关系阻抗失配」时，考虑以下几个问题： 我当前所建模的概念表示领域中的一个东西呢，还是只是用于描述和度量其他东西？ 如果该概念起描述作用，那么它是否满足值对象的几个特征？ 将该概念建模成实体是不是只是持久化上的考虑？ 将该概念建模成实体是不是因为它拥有唯一标识，我们关注的是对象实例的个体性，并且需要在其整个生命周期中跟踪其变化？ 我们不应该使持久化机制影响到对值对象的建模。无论使用什么技术来完成数据建模，数据库实体，主键，引用完整性和索引都不能用来驱动你对领域概念的建模。 单个值对象当实体包含单个值对象，值对象的属性需要和包含它的实体保存在一张数据表中时，其列名最好采用与数据库一致的形式，例如：123BusinessPriority.Ratings.Benefit=&gt;business_priority_ratings_benefit 值对象集合序列化到单个列中将一个 List 或 Set 的值对象保存在单个列中需要考虑以下问题： 列宽：有些对象集合可以包含任意多个元素，但数据库的列宽是有限制的。 查询：如果需要对该集合中的元素进行查询，无法用 SQL 语句实现，但从一个集合中查询一个或多个属性是比较少见的情况。 序列化器和反序列化器：需要自定义类型来实现序列化器和反序列化器，这只是增加了工作量。 使用数据库实体保存多个值对象我们不能因为某个概念非常符合数据库实体而将其建模成领域模型中的实体。有时，是对象 - 关系阻抗失配需要我们采用这种方法，但这绝非 DDD 原则。要实现这种方案，我们可以采用「层超类型」，或又名「委派身份标识(主键)」。下面的例子使用了两层层超类型：123456789public abstract class IdentifiedDomainObject: ISerializable&#123; private long _id = -1; protected long Id &#123; get =&gt; this._id; set =&gt; this._id = value; &#125;&#125; 接下来定义另一层层超类型，该层超类型是值对象专属的：1234public abstract class IdentifiedValueObject: IdentifiedDomainObject&#123;&#125; 虽然 IdentifiedValueObject 什么也不做，但它显式地表明了建模意图。IdentifiedValueObject 还应该有另外一个专属于实体的抽象子类 Entity。现在，每一个值对象类型都可以方便地获得一个隐藏的委派主键，我们可以自由地将其映射成数据库实体，而在领域模型中将其建模成值对象。 委派标识主要用于数据建模，其没有领域模型含义，这里更多是说明当实体包含值对象集合并且需要对其进行查询时如何对它们进行持久化，这样的值对象在数据库中会有一张单独的表，但这并不代表他们就是领域模型中的实体。 ORM 与枚举状态对象参考 《实现领域驱动设计》 P230]]></content>
      <categories>
        <category>Domain-Driven Design</category>
      </categories>
      <tags>
        <tag>ddd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《实现领域驱动设计》读书笔记(4) - 战术建模之实体]]></title>
    <url>%2Fddd-tactical-entity%2F</url>
    <content type="text"><![CDATA[系列大纲: 《实现领域驱动设计》读书笔记 本文大纲: 唯一标识 委派标识 标识稳定性 实体及其本质特征 贫血领域模型 强类型实体标识 模型所扮演的角色 不变条件 验证 跟踪变化 当我们需要考虑一个对象的个性特征，或需要区分不同的对象时，我们引入实体这个领域概念。一个实体是一个唯一的东西，并且可以在相当长的时间内持续地变化。「唯一的身份标识」和「可变性特征」将实体和值对象区分开来。 常年进行 .NET 生态开发的人很容易把实体等同于 Entity Framework 中的 Entity，认为 Entity 就是数据库模型的对象映射，然而书中所说的实体完全是不同的概念，是面向业务领域的模型，数据映射模型因不具备任何行为的实体被称作「贫血领域模型」 唯一标识以下是常用的创建实体身份标识的策略，从简单到复杂依次为： 用户提供一个或多个初始唯一值作为程序输入，程序应该保证这些初始值是唯一的 程序内部通过某种算法自动生成身份标识 程序依赖于持久化存储，比如数据库来生成唯一标识 另一个限界上下文已经决定出了唯一标识，这作为程序的输入，用户可以在一组标识中进行选择 聚合根实体对象的唯一标识是全局唯一的，在同一个聚合中，一般实体的唯一标识只要和聚合内的其他实体区分开来即可。 将唯一标识的生成放在「资源库(Repository)」中是一种自然的选择 从数据库中获取标识比直接从应用程序中生成标识要慢得多，一种解决方法是将数据库序列缓存在应用程序中，比如缓存在资源库中。 有时，标识的生成和赋值时间对于实体来说是重要的，及早标识生成和赋值发生在持久化实体之前。延迟标识生成和赋值发生在持久化实体的时候 委派标识有些 ORM 工具通过自己的方式来处理对象的身份标识，如果我们自己的领域需要另外一种实体标识，此时两者将产生冲突。为了解决这个问题，需要使用两种标识，一种为领域所用，一种为 ORM 所用，在 Hibernate 中，被称为委派标识。委派标识与领域中的实体标识没有任何关系，委派标识只是为了迎合 ORM 创建的。 标识稳定性在多数情况下，我们都不应该修改实体的唯一标识，这样可以在实体的整个生命周期中保持标识的稳定性。 实体及其本质特征贫血领域模型过多拥有 getter 和 setter 方法而缺乏行为的模式可以概括为贫血领域模型。 强类型实体标识标识需要有特殊的类型还是可以使用简单的字符串？实体的唯一标识会用在很多地方，它可以用在不同限界上下文的所有实体上。在这种情况下，使用一个强类型的实体标识可以保证所有订阅方所持有的实体都能使用正确的标识。 这里所说的实体标识更多是指聚合根的实体标识？ 模型所扮演的角色在面向对象编程中，通常由接口来定义实现类的角色，在正确的设计情况下，一个类对于每一个它所实现的接口都存在一种角色。如果一个类没有显式的角色 - 即该类没有实现任何接口，那么默认情况下它扮演的即是本类的角色，也即，该类的公有方法表示该类的隐式接口。 不变条件不变条件是在整个实体生命周期中都必须保持事务一致性的一种状态，有时一个实体维护了一个或多个不变条件。如果实体的不变条件要求该实体所包含的所有对象都不能为 null，那么这些状态需要作为参数传递给构造函数，并且在相应的 setter 方法中对新值进行非 null 检查来确保一致性。 验证 自封装：无论从何处访问对象的状态，即使从对象内部访问数据，都必须通过 getter 和 setter 方法实现。 自封装首先为对象的实例变量和类变量提供了一层抽象。其次，我们可以方便地在对象中访问其所引用对象的属性。重要的是，自封装使验证变得非常简单。 验证的主要目的在于检查模型的正确性，我们将对模型进行三个级别的验证： 验证属性: 通过自封装的方式在 setter 方法中对属性进行验证 验证整体对象: 为了实现对整体对象的验证，可创建 Entity 层超类型，在其中定义 Validate 虚方法，实现类通过重写该方法按需调用验证逻辑，同时，由于验证逻辑的变化速度比实体本身还要快，所以应该将真正的验证逻辑委托给专门的验证类，实体在其 Validate 方法中使用这些验证类，从而使验证逻辑与实体解耦。 验证组合对象: 关注点从单个实体是否合法转向多个实体的是组合是否全部合法，包括一个或多个聚合实例。最好的方式是把这样的验证过程创建成一个领域服务，该领域服务通过资源库读取需要验证的聚合实例，然后对每个实例进行验证，可以是单独验证，也可以和其他聚合实例一起验证。 跟踪变化领域专家可能会关心发生在模型中的一些重要事件，此时就需要对实体的一些特殊变化进行跟踪了。跟踪变化最实用的方法是「领域事件」和「事件存储」。可以为领域专家所关心的所有状态改变都创建单独的事件类型，事件的名字和属性表明发生了什么样的事件。当命令操作执行完后，系统发出这些领域事件，订阅方接收发生在模型上的所有事件。接收到事件后，订阅方将事件保存在事件存储中。]]></content>
      <categories>
        <category>Domain-Driven Design</category>
      </categories>
      <tags>
        <tag>ddd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《实现领域驱动设计》读书笔记(3) - 战略建模之架构]]></title>
    <url>%2Fddd-strategic-archietecture%2F</url>
    <content type="text"><![CDATA[系列大纲: 《实现领域驱动设计》读书笔记 本文大纲: 分层架构 六边形架构(端口与适配器架构，洋葱架构) 依赖倒置原则 面向服务架构(Service-Oriented Architecture, SOA) REST(Representational State Transfer) RESTful HTTP 服务端的关键方面 REST 和 DDD 命令与查询职责分离 - CQRS 客户端和查询处理器 事件驱动架构 长时处理过程(Saga) 事件源(EventSource) 分层架构分层架构的一个重要原则是: 每层只能与位于其下方的层发生耦合。「严格分层架构」只允许某层与直接位于其下方的层发生耦合，而「松散分层架构」则允许任意上方层与任意下方层发生耦合。由于「用户界面」和「应用服务」经常需要与基础设施打交道，许多系统都是基于「松散分层架构」的。 在分层架构中，领域的核心域通常只位于架构的其中一层，「用户界面」和「应用服务」均位于其上。 根据笔者的理解，用户界面层对应所有对系统产生消费行为的客户端，可能是人也可能是其他系统，用户界面是应用层的直接消费方。 有人认为既然用户界面需要对用户输入进行验证，那么它就应该包含业务逻辑。事实上，用户界面进行的验证和领域模型的验证是不同的，在用户界面中使用的只是数据的渲染和展现，而领域模型的验证的关注点却跟一致性有关，此时可以使用展现模型将用户界面与领域模型解耦。 「应用服务」位于应用层中，「应用服务」和「领域服务」的职责是不同的，后续的文章专门针对两者进行了讨论。 领域逻辑不应该出现在应用服务中，应用服务可以用于控制持久化事务和安全认证，或者向其他系统发送基于事件的消息通知，另外还可以用于创建邮件以发送给用户。应用服务本身并不处理业务逻辑，但它是领域模型的直接消费者，它主要用于协调领域对象的操作，应用服务是很轻量的。同时，应用服务是表达用例和用户故事的主要手段。因此，应用服务通常的用途是: 接收来自用户界面的输入参数，再通过资源库获取到聚合实例，然后执行相应的操作，例如:1234567891011121314@Transactionalpublic void CommitBacklogItemToSprint(string tenantId, string backlogItemId, string sprintId)&#123; // construct wanted id objects. var tenantId = new TenantId(tenantId); var backlogItemId = new BacklogItemId(backlogItemId); // get backlogItem object from repository. var backlogItem = backlogItemRepository.BacklogItemOfId(tenantId, backlogItemId); var sprintId = new SprintId(sprintId); var sprint = sprintRepository.SprintOfId(tenantId, sprintId); // call the commit method from backlogItem. backlogItem.CommitTo(sprint);&#125; 上述代码很好的诠释了前文提及的关于应用服务「协调领域对象的操作」的功能 如果应用服务比上述功能复杂许多，这通常意味着领域逻辑已经泄露到应用服务中了，此时的领域模型将变成「贫血领域模型」。因此，最佳实践是将应用服务做成很薄的一层。 六边形架构(端口与适配器架构，洋葱架构)依赖倒置原则 高层模块不应该依赖于低层模块，两者都应该依赖于抽象 抽象不应该依赖于细节，细节应该依赖于抽象。 当传统的分层架构引入了依赖倒置原则，会发现已经不存在分层的概念了，无论是高层还是低层都依赖于抽象，好像把整个分层架构推平了。在六边形架构中，不同的消费者通过「对等」的方式与系统交互，当需要新增消费者时，只需添加一个新的适配器将客户输入转化成能被系统 API 所理解的参数就行了。同时，系统输出，例如「图形界面」，「持久化」和「消息」等都可以通过不同方式实现，并且是可替换的，对于每种特定的输出，都有一个新的适配器负责完成相应的转化功能。 六边形架构提倡用「内部区域」和「外部区域」来看待整个系统，在外部区域中，不同的客户代码提交输入，内部系统用于获取持久化数据，并对程序输出进行存储，或在中途将输出转发到另外的地方(比如消息)。 依据笔者理解，端口和适配器的意思是，将系统想象成一般的计算机，HTTP 协议和 AMPQ 协议以及用户界面可看作不同的端口，而适配器则负责将来自这些协议的数据转化成系统 API 能够理解的数据。 在使用六边形架构时，我们应该根据用例来设计应用程序，而不是根据需要支持的客户数目来设计。任何客户都可能向不同的端口发出请求，但是所有的适配器都将使用相同的 API。 应用程序位于六边形架构的「内部区域」，公共 API 通过「应用服务」暴露给外部区域，而如前文所述，应用服务是领域模型的直接消费者，所有的输入都将委派给内部的领域对象。 我们可以将资源库的实现看作是持久化适配器，该适配器用于访问先前存储的聚合实例，或者保存新的实例，我们可以通过不同的方式实现资源库，如关系型数据库，文档型数据库以及内存数据库，他们分别对应着不同的适配器，但服务于同一种端口——持久化，即同一个端口可以有多种适配器。 六边形架构的好处在于易于测试，整个应用程序和领域模型可以在没有客户和存储机制的条件下进行设计开发。基于六边形架构，可以扩展为 SOA，REST，事件驱动架构，CQRS 架构或者数据网织或基于网格的分布式缓存，还有可能 Map-Reduce 这种分布式并行处理方式。 面向服务架构(Service-Oriented Architecture, SOA)服务的设计原则如下: 服务契约: 通过契约文档，服务阐述自身的目的与功能 松耦合: 服务将依赖关系最小化 服务抽象: 服务只发布契约，而向消费方隐藏内部逻辑 服务重用性: 一种服务可以被其他服务重用 服务自治性: 服务自行控制环境与资源以保持独立性，这有助于保持服务的一致性和可靠性 服务无状态性: 服务负责消费者的状态管理，但不能与服务的自治性发生冲突 服务可发现性: 消费方可以通过服务元数据来查找服务和理解服务 服务组合性: 一种服务可以由其他服务组合而成，而不管其他服务的大小和复杂性如何 这些原则可以与六边形架构结合起来，此时服务边界位于最左侧，而领域模型位于中心位置，消费方可以通过 REST，SOAP 和消息机制获取服务。 业务服务可以由任意数量的技术服务来提供，技术服务可以是 REST 资源，SOAP 接口或消息类型。业务服务强调业务战略，即如何对业务和技术进行整合。 REST(Representational State Transfer)REST 既不是使用 HTTP 直接发送 XML/JSON，也不是将 URI 的查询参数传递给方法。REST 是一种架构风格，架构风格之于架构就像设计模式之于设计一样，它将不同架构实现共有的东西抽象出来，使得我们在谈论架构时不至于陷入技术细节中。分布式系统架构存在多种架构风格，包括客户端-服务器架构风格和分布式对象(例如远程过程调用)风格。REST 是 Web 架构的一种架构风格，和其他技术一样，我们可以通过不同的方式来使用 Web 协议，有些使用方式符合设计者的初衷，而有些则不然。例如，你可以使用关系型数据库管理系统(RDBMS)创建表，列，外键关联，视图和约束等，你也可以只创建一张包含两列的表，一列表示「键」，一列表示「值」，然后将序列化之后的对象保存在值列中。此时，你依然在使用 RDBMS，但你却使用不到多少 RDBMS 的功能，如查询，组合，排列和分组等。 同理，Web 协议既可以按照它的设计初衷为人所用——此时便是一种遵循 REST 架构风格的方式——也可以通过一种不遵循其设计初衷的方式为人所用。因此，当我们没有足够充分的理由享受 REST 风格的 HTTP 所带来的好处时，采用另一种分布式系统架构可能是合适的，就像在保存拥有唯一键的数值时，NoSQL 键值对存储方式是一种更好的选择一样。 RESTful HTTP 服务端的关键方面「资源」是关键的概念，系统的设计者将决定哪些有意义的「东西」可以暴露给外界，并且给这些「东西」一个唯一的身份标识。通常来说，每种资源都拥有一个 URI，每个 URI 都需要指向某个资源。 另一个关键方面是「无状态通信」，消息是自描述的，例如，HTTP 请求本身便包含了服务端所需要的全部信息，服务端可以使用其本身的状态来辅助通信，重要的是: 我们不能依靠请求本身来创建一个隐式上下文环境(会话)。无状态通信保证了不同请求之间的相互独立性，这在很大程度上提高了系统的可伸缩性。 如果将资源看作对象，那么每一个对象都支持相同的接口，可以调用的方法是一个固定的集合，它们全都可以用 HTTP 动作表示，其中最重要的有 GET，PUT，POST 和 DELETE。这也是将 REST 与其他架构风格区别开来的关键。虽然乍一看这些方法将会转化成 CRUD 操作，但通常我们所创建的资源并不表示任何持久化实体，而是封装了某种行为，当调用 HTTP 动词对应的操作时，实际上是在调用这些行为。 依据笔者理解，对象化的资源并不代表任何领域模型中的实体，而是根据某一项业务操作抽象出来的资源块，其中包括用以展示的数据和某些行为。 在 HTTP 规范中，每种 HTTP 方法都有一个明确的定义，比如 GET 方法只能用于「安全」的操作: 它可能完成一些客户并没有要求的动作行为 它总是读取数据 它可能被缓存起来 最后，通过使用 HATEOAS(Hypermedia as Engine of Application State)，REST 服务的消费方可以沿着某种路径发现应用程序可能的状态变化。简单来讲，就是单个资源并不独立存在，不同资源是相互链接在一起的，对于服务器来说，这意味着在返回中包含对其他资源的链接，由此消费方便可通过这些链接访问到相应的资源。 REST 和 DDD不应该将领域模型直接暴露给外界，这样会使系统接口变得非常脆弱，领域模型的任何改变都会导致系统接口的改变。要将 DDD 与 RESTful HTTP 合并起来使用，我们有两种方式。 第一种方法是为系统接口单独创建一个有界上下文，再在此上下文中通过适当的策略来访问核心模型，这是一种经典的方法，它将系统接口看作一个整体，通过资源抽象将系统功能暴露给外界，而不是通过服务或远程接口。这种方法让核心域和系统接口之间完成了解耦。 另一种方法用于需要使用标准媒体类型的时候。如果某种媒体类型并不用于支持单个系统接口，而是用于一组相似的客户端-服务器交互场景，此时可以创建一个领域模型来处理每一种媒体类型。这种方法本质上为 DDD 中的共享内核或发布语言。 这里提到的媒体类型表示 MIME type。 通常来讲，添加新资源并在已有资源中创建到新资源的链接是非常简单的，要添加新的格式也同样如此。另外，基于 REST 的系统也是非常容易理解，系统被分为很多较小的资源块，每一个资源块都可以独立测试和调试。HTTP 设计本身以及 URI 成熟的重写与缓存机制使得 RESTful HTTP 成为一种不错的架构选择，该架构具有很好的松耦合性和可伸缩性。 命令与查询职责分离 - CQRS从「资源库」中查询所有需要显示的数据是困难的，特别是在需要显示来自不同聚合类型与实例的数据时，领域越复杂，这种困难越大。一种被软件系统广泛采用的做法是使用「数据传输对象(Data Transfer Object, DTO)」，即从不同的资源库中获取聚合实例，然后再将它们组装成 DTO。 然而，查询这些数据所带来的性能消耗可能会随着数据量增大而显著降低，另外一种办法是使用 「CQRS(Command-Query Responsibility Segregation)」。CQRS 是将紧缩(Stringent)对象(或组件)设计原则和命令-查询分离(CQS)应用在架构模式中的结果。 一个方法要么是执行某种动作命令，要么是返回数据的查询，而不能两者皆是。换句话说，问题不应该对答案进行修改。一个方法只有在具有参考透明性的时候才能返回数据，此时该方法不会产生副作用。 [Bertrand Meyer] 在对象层面，这意味着: 如果一个方法修改了对象的状态，该方法便是一个命令(Command)，它不应该返回数据，在 Java 和 C# 中，这样的方法应该声明为 void 如果一个方法返回了数据，该方法便是一个查询(Query)，此时它不应该通过直接或间接的手段修改对象的状态，在 Java 或 C# 中，这样的方法应该以其返回的数据类型进行声明 在领域模型中，我们通常会看到同时包含命令和查询的聚合，也经常在资源库中看到不同的查询方法，这些方法对对象属性进行过滤。但在 CQRS 中，我们忽略这些常态的情形，而是通过另一种方式来查询用于呈现的数据。 假设，一个聚合不再有查询方法，只有命令方法，资源库也将变成只有 Add() 或 Save() 方法(分别支持创建和更新操作)，同时只有一个查询方法，如 FromId()，这个唯一的查询方法以聚合 ID 作为参数，然后返回该聚合实例。资源库不能使用其他方法来查询聚合，比如对属性进行过滤等。在将所有查询方法移除之后，我们将此时的模型称为「命令模型(Command Model)」，但我们仍然需要向用户显示数据，为此我们将创建第二个模型，该模型专门用于优化查询，称之为「查询模型(Query Model)」。 你可能会认为: 这种架构风格需要大量的额外工作，我们解决了一些问题，同时带来了另外的问题，而且我们需要编写更多的代码。但无论如何，不要急于否定这种架构，在某些情况下，新增的复杂性是合理的。 客户端和查询处理器客户端可以是 Web 浏览器，也可以是桌面应用程序，它们将使用运行在服务器端的一组查询处理器。查询处理器表示一个只知道如何向数据库执行基本查询并将查询结果以某种格式返回的简单组件。 事件驱动架构事件驱动架构不见得必须与六边形架构一同使用，但引入六边形架构有助于理解事件驱动架构。 长时处理过程(Saga)todo.. 事件源(EventSource)事件源是指: 某个聚合上的每次命令操作，都有至少一个领域事件发布出去，该领域事件描述了操作的执行结果。每一个领域事件都将被保存到「事件存储」中，每次从资源库中获取某个聚合时，我们将根据发生在该聚合上的历史事件来重建该聚合实例，事件的作用顺序与它们的产生顺序相同。 随着时间推移，发生在聚合实例上的事件越来越多，那么，重放这些成百上千的事件会对那些操作繁忙的模型造成影响，为了避免这种瓶颈，我们可以通过聚合状态「快照」的方式来进行优化。可以创建一个聚合内存状态的快照，此时的快照反应了聚合在事件存储历史中某个事件发生后的状态。为了达到这样的目的，我们需要利用该事件及其发生前的所有事件来重建聚合实例，之后对聚合状态进行序列化，再把序列化之后的快照保存在事件存储中。这样，便可通过聚合快照来实例化某个聚合，接着再重放比快照更新的事件来修改聚合的状态，直至读取时发生在聚合上的最后一个事件。 创建快照所需的前置事件数量临界值可以由团队确立，例如，发现某个聚合在接收到 50 个事件之后为其创建快照可以获得最佳性能，那么 50 就是其临界值。 事件通常以二进制的方式保存在事件存储中，这使得事件源不能用于查询操作。事实上，为事件源所设计的资源库只有一个接受聚合 ID 的查询方法，因此需要另外的方法来支持查询，通常将 CQRS 和事件源一同使用。]]></content>
      <categories>
        <category>Domain-Driven Design</category>
      </categories>
      <tags>
        <tag>ddd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《实现领域驱动设计》读书笔记(2) - 战略建模]]></title>
    <url>%2Fddd-strategic%2F</url>
    <content type="text"><![CDATA[系列大纲: 《实现领域驱动设计》读书笔记 本文大纲: 通用语言(Ubiquitous Language) 领域和子域 核心域 支撑子域 通用子域 问题空间(Problem Space)和解决方案空间(Solution Space) 有界上下文(Bounded Context) 上下文映射图 通用语言(Ubiquitous Language)通用语言是团队成员间能够互相理解的语言，它统一了开发团队和领域专家之间的术语体系，从而提高团队成员之间的沟通效率。通用语言不同于「统一建模语言(UML, Unified Modelling Language)」，UML 是开发人员之间的语言。 通用语言的几点注意： 有界上下文和通用语言存在一对一的关系 只有当团队工作在独立的有界上下文中时，通用语言才是「通用」的 虽然我们只工作在一个有界上下文中，但我们可能经常会与其他有界上下文打交道，这时可以通过上下文映射图对这些有界上下文进行集成，每个有界上下文都有自己的通用语言，而有时语言间的术语可能有重叠的部分 领域和子域在 DDD 中，一个领域可能包含多个有界上下文，通常一个有界上下文对应一个领域。「领域」一词承载了太多含义，领域既可以表示整个业务系统，也可以表示其中的某个核心域或支撑子域，域模型在特定的域中应该表达出清晰的含义。 例如，在一个电子商务系统中，至少要向买家展示不同类别的产品，允许买家下单和付款，还需要安排物流。这个特定的领域可以划分为「产品目录(Product Catalog)」，「订单(Order)」，「发票(Invoicing)」和「物流(Shipping)」。子域不一定会很大，可以简单到只包含一套算法，这套算法对业务系统来说可能非常重要，但并不包含在核心域之中。在正确实施 DDD 的情况下，这种简单的子域可以以「模块(Module)」的形式从核心域中分离出来。 核心域通常代表了促进业务成功的核心功能，核心域应该配备最好的领域专家和开发团队。 支撑子域如果一个有界上下文对应着业务的某些重要方面，但却不是核心，那么它便是一个「支撑子域」。 通用子域如果一个子域被用于整个业务系统，那么这个子域便是「通用子域」。例如在众多系统中都有的「认证与授权子系统」通常就是一个通用子域。 问题空间(Problem Space)和解决方案空间(Solution Space) 问题空间是领域的一部分，对问题空间的开发将产生一个新的核心域，对问题空间的评估应该同时考虑已有子域和额外所需子域。因此，问题空间是核心域和其他子域的组合。 解决方案空间包括一个或多个有界上下文，因为有界上下文即是一个特定的解决方案。 在我们实施某个解决方案之前，我们需要对问题空间和解决方案空间进行评估，首先回答以下问题： 这个战略核心域的名字是什么？ 它的目标是什么？ 它包含哪些概念？ 它的支撑子域和通用子域是什么？ 如何安排项目人员？ 你能组建一支合适的团队吗？ 解决方案空间在很大程度上受到现有系统和技术的影响。我们应该根据有界上下文仔细考虑以下问题： 有哪些软件资产是已经存在的，它们可以重用吗？ 哪些资产是需要创建的，或者从别处获得？ 这些资产是如何集成在一起的？ 还需要什么样的集成？ 假设已经有了现有资产和那些需要被创建的资产，我们还需要做些什么？ 核心域和那些支撑项目的成功几率如何？会不会出现由于其中一个失败而导致整个项目失败的可能？ 有哪些地方我们使用了完全不同的术语？ 有界上下文之间在哪些地方存在概念重叠？ 这些重叠的概念在不同的有界上下文之间是如何映射和翻译的？ 哪些有界上下文包含了核心域中的概念，其中使用了哪些战术建模工具？ 有界上下文(Bounded Context)有界上下文采用 模型+上下文 的形式来命名。 同一个概念在不同的有界上下文中的关注点是不一样的，例如在一个电子商务系统中，「顾客」这个概念在订单系统上下文中，其关注点可能有先前购买情况，忠诚度，可买产品，折扣和物流方式，而在下单时，「顾客」的上下文包括名字，产品寄送地址，订单总价和一些付款术语。所以「顾客」在这个案例中并没有一个清晰的含义。类似的问题其实是脱离了不同有界上下文中协作概念的关注点，在不同的有界上下文中，「顾客」扮演了不同的协作概念，例如在产品目录上下文中，「顾客」可以用「浏览者」表示，而在订单上下文中，「顾客」以「购买者」表示。「顾客」一词包含了太多可能的角色，不同的角色有不同的职责。在不同的有界上下文中，不同角色充当了「顾客」的某种职责，进而使得单一有界上下文该角色的含义清晰，并与其他有界上下文的关注点得以分离。 有界上下文是一个显式的语义边界，领域模型便存在于这个边界之内。领域模型把通用语言表达成软件模型，创建边界的原因在于，每一个模型概念，包括它的属性和行为，在边界之内都具有特殊的含义。 在上下文边界之外，我们通常不会使用该上下文之内的对象实例，但是不同上下文中彼此关联的对象可能共享一些状态。 当模型驱动着数据库 Schema 的设计时，数据库 Schema 也应该位于该模型所处的上下文边界之内。因为数据库 Schema 是由建模团队设计，开发并维护的。这也意味着数据库中表和列的名字应该和模型的名字保持一致。另一方面，如果数据库 Schema 已经存在，或者另有一个专门的数据建模团队要求有别于模型的数据库 Schema 设计，此时的 Schema 便不能和模型位于同一个有界上下文中了。 如果「用户界面(UI)」被用于渲染模型，并且驱动着模型的行为设计时，同样，该用户界面也应该属于模型所在的上下文边界之内。但是，这并不表示我们应该在用户界面中对领域进行建模，因为这样将导致「贫血领域对象」或者任何试图将领域概念带到领域模型之外的举措。 通常情况下，一个系统/应用程序的使用者并不只是人，还可能是另外的计算机系统。系统中有可能存在诸如 Web 服务之类的组件，或者使用 REST 资源来与模型交互，在所有可能的情形下，这些面向服务的组件都应该位于上下文边界之内。 用户界面和面向服务的端点都会将操作委派给「应用服务(Application Service)」，应用服务包含了不同类型的服务，比如安全和事务管理等。对于模型来说，应用服务扮演的是一种门面模式(Facade)。同时，应用服务还具有管理功能，它将来自用例流(Use Case Flow)的请求转换成领域逻辑的执行流。应用服务也是位于上下文边界之内的。 有界上下文主要用来封装通用语言和领域对象，但同时它也包含了那些为领域模型提供交互手段和辅助功能的内容。需要注意的是，对于架构中的每个组件，我们都应该将其放在适当的地方。有界上下文可以包含「模块(Module)」，「聚合(Aggregate)」，「领域事件(Domain Event)」和「领域服务(Domain Service)」。有界上下文应该足够大，以表达它所对应的整套通用语言。 上下文映射图上下文映射图表示了不同有界上下文之间是如何集成的，任何两个有界上下文可能存在某种模式： 合作关系(Partnership): 两个团队各自负责自己的上下文，在接口的演化上进行合作以同时满足两个系统的需求 共享内核(Shared Kernel): 两个上下文对模型和代码的共享产生一种紧密的依赖性，需要为共享的部分指定一个显式的边界，并保持共享内核的最小化。在没有与另一个团队协商的情况下，共享内核是不能改变的。应该引入一种持续集成机制来保证共享内核与通用语言的一致性。 客户方-供应方开发(Customer-Supplier Development): 两个上下文处于上-下游关系，上游团队独立于下游团队完成开发，下游团队的开发可能会受到很大的影响。因此在上游团队的计划中，应该顾及下游团队的需求。 遵奉者(Confirmist): 在存在上-下游关系的两个团队中，上游团队完全不考虑下游团队的需求，而下游团队只能盲目地使用上游团队的模型。 防腐层(Anticorruption Layer): ACL，当两个上下文不是合作，共享内核或者客户-供应方关系时，翻译将变得复杂。下游团队需要根据自己的领域模型创建一个单独的层，该层作为上游系统的代理提供功能。防腐层通过已有的接口与其他系统交互，在防腐层内部，在自己的模型和他方的模型之间进行翻译转换。如果翻译过于复杂，并且需要大量的数据复制和同步，从而使得翻译前后的模型存在很大的相似度，那么你可能过多地使用了外部上下文中的数据，导致自己的模型混淆不清了。 开放主机服务(Open Host Service): OHS，定义一种协议，其他系统通过该协议来访问该系统，协议是公开的，这样任何想与这个系统集成的人都可以使用该协议。通常来讲，我们可以将开发主机服务看成是远程过程调用 (Remote Procedure Call) 的 API。同时，它也可以通过消息机制实现。 发布语言(Published Language): PL，在两个有界上下文之间翻译模型需要一种公用的语言。此时你应该使用一种发布出来的共享语言来完成集成交流。发布语言通常与开放主机服务一起使用，常见的发布语言使用 XML Schema。在使用 REST 服务时，可以使用 XML 和 JSON，也可以使用 Google Proto Buffer 来表示。使用 REST 的好处是每个客户端都可以指明使用哪种语言，同时还可以指明资源的展现方法。 另谋他路(SeperateWay): 如果两套系统之间没有任何显著的关系，那么他们是完全解耦的，集成总是昂贵的。 大泥球(Big Ball of Mud): 当我们检查已有系统时，经常会发现系统中存在混杂在一起的模型，它们之间的边界非常模糊，此时应该为整个系统绘制一个边界，然后将其归纳在大泥球范围之列。 系统间集成经常依赖于 RPC。RPC 与编程语言中的过程调用非常相似。和在相同进程中的过程调用不同的是，RPC 更容易产生有损性能的时间延迟，并有可能导致调用彻底失败。虽然 REST 并不是真正意义上的 RPC，但它却具有与 RPC 相似的特征。然而，要与远程模型保持同步，最好的方式是在远程系统中采用面向消息的通知机制(例如 RabbitMQ)。消息通知可以通过服务总线进行发布，也可以采用消息队列或者 REST。]]></content>
      <categories>
        <category>Domain-Driven Design</category>
      </categories>
      <tags>
        <tag>ddd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《实现领域驱动设计》读书笔记(1) - 总览]]></title>
    <url>%2Fddd-overview%2F</url>
    <content type="text"><![CDATA[系列大纲: 《实现领域驱动设计》读书笔记 本文大纲: 前言 领域模型 什么是领域模型？ 前言面向对象编程的博大精深至今只浅尝一二，开发实践中一直希望能够持久向好的设计方向上靠而不过度设计。2015 年时第一次接触到领域驱动设计，当时看了 《实现领域驱动设计》这本书，初看时晦涩难懂，许多概念与当时的理解存在很大偏差，一度不理解为何要那样设计。在经过了几个项目的实战之后，如今再翻出来看，对书中总结的思考方式和方法论有了一番新的体会。现在看来，领域驱动设计之所以难以理解，在于其方法论的概念是抽象于任何语言和技术实现的，长期工作在一线的开发人员想要脱离出自己所在的技术栈去理解类似「值对象」，「标准类型」等这样的概念，需要一些时间。 「领域驱动设计」或者 DDD，是一个非常庞大的体系，它既不是设计模式，也不代表任何技术实现，其中涵盖了软件系统中涉及的方方面面。决定记下本系列的初衷在于不断修正自己对 DDD 的理解和在实践上遇到的启发，以供来日回顾。 领域模型什么是领域模型？领域模型是关于某个特定业务领域的软件模型。通常，领域模型通过对象来实现，这些对象同时包含了「数据」和「行为」，并且表达了准确的业务含义 ——《领域驱动设计》 「实现领域驱动」全书由高层视角深入到实现的细枝末节来组织章节，其索引大致为： 战略建模 通用语言(Ubiquitous Language) 领域，子域和核心域 限界上下文(Bounded Context) 上下文映射图(Context Mapping) 架构(Archiecture) 战术建模 实体(Entity) 值对象(Value Object) 领域服务(Domain Service) 领域事件(Domain Event) 模块(Module) 聚合(Aggregate) 工厂(Factory) 资源库(Repository) 集成限界上下文(Integrating Bounded Contexts) 应用程序 设计一个系统所需的所有建模工具都能在以上这些概念中找到，书中针对这些概念的应用场景也提出了指导意见和最佳实践。这些内容会在后续的笔记中一一提到，只提取我个人认为精华的部分记录下来。]]></content>
      <categories>
        <category>Domain-Driven Design</category>
      </categories>
      <tags>
        <tag>ddd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建 Ubuntu 16.04 LTS]]></title>
    <url>%2Flinux-setup-a-new-ubuntu-server%2F</url>
    <content type="text"><![CDATA[最近租用了一台预装 ubuntu 操作系统(这里选择 ubuntu 是因为笔者对其预装的工具集比较熟悉)的服务器之后，还要为这台服务器做一些额外的配置以使其能够在互联网环境中正常运行。很多云服务提供商都提供了适配不同需求的预装环境，但为了对服务器的搭建过程有一个直观的感觉和更多的控制权，决定亲手过一遍这个过程。 本篇文章涉及的所有指令细节可参考Linux 基础 - 用户管理 通常，配置一台裸机至少要完成以下几个步骤 新建群组 新建用户，并为其分配群组 配置 ssh 配置服务器安全策略 准备工作在开始配置之前，我们需要知道该服务器的以下信息： 服务器的公网 ip 地址 确认 22 端口打开 root 用户的初始密码 在 windows 系统下启动 PuTTy，使用 root 用户远程登录到该服务器 主机命名 hostname(可选的)如果不想修改云服务提供商默认分配的主机名，可跳过此步。 执行命令 hostname 显示当前主机名12$ hostnameVM-0-4 执行以下命令进行修改，修改完成后，再次执行命令以查看效果：123$sudo hostname &lt;your-new-hostname&gt;$ hostnameyour-new-hostname 新建群组 - groupadd执行如下命令新建一个带有 &lt;gid&gt; 的群组1$sudo groupadd &lt;your-new-group-name&gt; -g &lt;gid&gt; 新建用户 - useradd1$sudo useradd -u 2500 -m -c "FrostHe" -s -g sudo -G pango pango 该命令创建一个名为 pango 的用户，uid 为 2500，要求为该用户创建 Home 目录，使用预设值设置 shell 环境，加入初始群组 sudo，同时加入次要群组 pango。由于先前已经创建了群组，在创建该用户时就不会再创建与之同名的新的群组，而是将该用户加入到该群组下。 现在，新建用户 pango 还没有密码，设置密码之前是无法登录 shell 的，执行 passwd 来为新用户指定密码：123$sudo passwd pangoEnter new Unix Password:Retype new Unix Password: passwd 指令在不接参数时表示修改当前登录用户的密码 现在，退出 PuTTy 客户端，以新建用户名和密码登录，如果登录成功，则表明新用户创建无误。 配置服务器安全策略将云服务器的 22 端口暴露于互联网并允许 root 用户及一般用户以密码进行登录是不推荐的，特别是 root 帐号，一旦被攻击者破解那么服务器上的资源可任由其修改。为了使服务器免于这些危险，我们需要让这台服务器： 禁用 root 帐号密码登录，仅启用公钥认证 开启防火墙并限定端口 设置 ip 登录策略及 禁用密码登录并启用 ssh 公钥登录以新建用户登录系统，修改 sshd_config 文件：1234$sudo nano /etc/ssh/sshd_configPermitRootLogin noPublicAuthentication yesPasswordAuthentication no 该配置对 ssh 客户端远程登录作出限制：启用公钥认证并禁用密码认证，同时禁止 root 远程登录。 若要修改生效， sshd 进程需要重新读取该配置，但这会让已经通过密码登录的会话中断，并且在 public key 部署前没有任何机会重新进行远程连接，所以这一步放到最后来做。 接下来在新用户 Home 目录下的 .ssh/authorized_keys 文件中复制 openssh 格式的公钥值。 在 /etc/ssh/sshd_config 中有一行 AuthorizedKeyFiles，该行的默认值为 .ssh/authorized_keys，该项配置是 sshd 进程提取 public key 的依据，如果对该值进行了修改，那么这里新建的文件也必须要与之对应。 现在执行 sudo service sshd reload 以使配置生效。此时重新打开一个 PuTTy 客户端，使用新用户密码登录，将收到错误对话框：在 Putty 中设置对应的私钥路径，重试即可登录成功： 至此，一个基本的云服务器配置就完成了，有的云服务提供商推出了「安全组」功能，即从云端配置端口进出通道。更多安全配置查阅 为 Linux 系统配置 CSF。]]></content>
      <categories>
        <category>Linux Basic</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为 Linux 系统配置 CSF]]></title>
    <url>%2Flinux-configure-csf%2F</url>
    <content type="text"><![CDATA[本文大纲: 功能 认证失败检测守护进程 进程追踪 目录监控 消息服务 端口涌流保护 Port Knocking 连接限制保护 Port/IP 地址重定向 UI 集成 IP 屏蔽列表 安装 ConfigServer Firewall 下载 解压缩 安装 基本配置 配置端口 任何主机 Apache FTP 服务器 邮件服务器 MySQL 服务器 进阶配置 应用更改 屏蔽与允许 ip 地址 屏蔽 ip 地址 允许 ip 地址 忽略 ip 地址 Config Server Firewall(CSF) 基于一般的防火墙功能(数据包过滤)进行了扩展，支持大多数 Linux 发行版本，其支持列表可在其官网找到。以下以 ubuntu 系统为例介绍 CSF 的使用。 对 CSF 的几乎所有指令操作都需要管理员权限，本篇文章仅涵盖 ipv4 的防火墙设置 - iptables。ipv6 对应的是 ip6tables。 功能认证失败检测守护进程CSF 每隔一段时间就会检查系统登录日志，对那些登录失败的请求尝试进行监控，在达到预设的失败次数后，CSF 将对发起这些请求的 ip 地址做预设的处理，失败次数和处理动作都是可自定义的。 以下程序对该功能兼容： Courier imap, Dovecot, uw-imap, Kerio openSSH cPanel, WHM, Webmail (cPanel servers only) Pure-ftpd, vsftpd, Proftpd Password protected web pages (htpasswd) Mod_security failures (v1 and v2) Suhosin failures Exim SMTP AUTH同时，可以自定义匹配 Regex 的登录文件来，对登录失败尝试的用户进行屏蔽。 进程追踪CSF 可检测异常行为的进程或异常开启端口的行为，在捕获到这些行为时可配置发送邮件给服务器管理员。 目录监控CSF 可监控 /temp 和其他相关的目录扫描恶意脚本，并在发现风险时发送邮件给服务器管理员。 消息服务启用该功能可让 CSF 在屏蔽客户端时传送一些有用的信息，但这样做可能会为黑客提供一些线索信息，继而增加服务器的风险。 端口涌流保护该设置提供端口涌流保护，比如 DDoS 攻击，可以为每个端口指定特定时间内允许最大的连接数。启用该功能可以极大降低黑客的野蛮攻击导致服务器宕机。找到一个适合的参数需要一些尝试，太过严格的流量限制会降低正常用户的体验。 Port Knocking参考 Port Knocking。 连接限制保护该功能可限制由单一 ip 地址对特定端口建立的连接数，这也是防止 DDoS 攻击的手段之一。 Port/IP 地址重定向可配置 CSF 将对特定 IP/Port 的连接重定向到另一个 IP/Port。注意，重定向之后，请求发起的客户端将变为服务器的 ip 地址，该功能与 NAT 不同。 UI 集成除了命令行工具之外，CSF 对 cPanel 和 Webmin 提供了 UI 集成。 IP 屏蔽列表CSF 可使用该功能从预设的源下载屏蔽的 ip 地址列表。 安装 ConfigServer Firewall下载从官网下载安装包到当前工作目录：1wget http://download.configserver.com/csf.tgz 解压缩下载下来的是一个压缩包，安装之前需要解压缩1tar -xzf csf.tgz 安装在进行安装之前，首先禁用其他防火墙脚本，例如 UFW，执行以下指令禁用 UFW：1$sudo ufw disable 导航到刚刚解压出来的文件夹 csf，执行安装脚本：1234cd csf$sudo sh install.sh...Installation Completed 安装完成后，查看指定的 iptables 是否可用：123456789101112131415$sudo perl /usr/local/csf/bin/csftest.plTesting ip_tables/iptable_filter...OKTesting ipt_LOG...OKTesting ipt_multiport/xt_multiport...OKTesting ipt_REJECT...OKTesting ipt_state/xt_state...OKTesting ipt_limit/xt_limit...OKTesting ipt_recent...OKTesting xt_connlimit...OKTesting ipt_owner/xt_owner...OKTesting iptable_nat/ipt_REDIRECT...OKTesting iptable_nat/ipt_DNAT...OKRESULT: csf should function on this server 出现以上报告内容则表明 CSF 已可在服务器上正常运行。 此时，通过远程登录连接到服务器的 ip 地址会被自动加入到白名单中，同时 SSH 占用的端口(即便是自定义的端口)也会放行，CSF 默认使用测试模式，该模式下所有的 iptables 规则将在 5 分钟后自动被移除。一旦确认所有配置已经就绪，应该由测试模式切换为工作模式。 基本配置通过编辑 /etc/csf/csf.conf 文件来配置 CSF，保存更改后，执行 csf -r 来使配置重新生效。1$sudo nano /etc/csf/csf.conf 配置端口配置文件中默认开启的端口如下：1234567TCP_IN = "20,21,22,25,53,80,110,143,443,465,587,993,995"TCP_OUT = "20,21,22,25,53,80,110,113,443"UDP_IN = "20,21,53"UDP_OUT = "20,21,53,113,123" 这些端口代表的默认服务如下： Port 20: FTP 数据传输 Port 21: FTP 控制 Port 22: 安全 shell (SSH) Port 25: 简单邮件传输协议 (SMTP) Port 53: 域名系统 (DNS) Port 80: 超文本传输协议 (HTTP) Port 110: 邮局协议 v3 (POP3) Port 113: 身份协议 Port 123: 网络时间协议 (NTP) Port 143: 因特网信息访问协议 (IMAP) Port 443: 超文本安全传输协议 (HTTPS) Port 465: URL Rendesvous Directory for SSM (Cisco) Port 587: 简单邮件传输协议 (SMTP) Port 993: 因特网安全信息访问协议 (IMAPS) Port 995: 安全邮局协议 v3 (POP3S) 以下是针对常见场景开启的服务端口： 任何主机1234TCP_IN: 22,53TCP_OUT: 22,53,80,113,443UPD_IN: 53UPD_OUT: 53,113,123 Apache1TCP_IN: 80,443 FTP 服务器1234TCP_IN: 20,21TCP_OUT: 20,21UPD_IN: 20,21UPD_OUT:20,21 邮件服务器12TCP_IN: 25,110,143,587,993,995TCP_OUT: 25,110 MySQL 服务器12TCP_IN: 3306TCP_OUT: 3306 进阶配置CSF 提供了大量的可配置项，最常用的列表如下： ICMP_IN: 设置为 1 时将允许外部主机 ping，设为 0 则禁止任何请求 ICMP_IN_LIMIT: 特定时间内允许同一 ip 地址的 ping 的请求数，通常不用修改，默认值为 1/s DENY_IP_LIMIT: 设置屏蔽 ip 地址的最大数量，保留太多数量会降低服务器性能 DENY_TEMP_IP_LIMIT: 与 DENY_IP_LIMIT 类似，但仅作用于临时屏蔽的 ip 地址 PACKET_FILTER: 过滤无效的，不需要的和非法的数据包 SYNFLOOD, SUNFLOOD_RATE 和 SYNFLOOD_BURST: 这三项提供了针对 SYN flood 攻击的保护，但会降低每个连接的初始化速度，仅当明确服务器正遭受攻击时启用该项 CONNLIMIT: 限制指定端口的并发连接数 如: 22;5;443;20 - 该值允许在 22 端口上最大 5 个并发连接数，在 443 端口上最大 20 个并发连接数 PORTFLOOD: 限制指定端口上单位时间内的最大连接数 如: 22;tcp;5;250 - 该值限制如果 22 端口上已有 5 个 tcp 连接，那么第 6 个来临的 tcp 连接将等待 250 秒，之后屏蔽解除，5 个新的 tcp 连接放行 其他设置在大多数情况都无需改动，如果确实需要自定义这些配置，阅读 /etc/csf/csf.conf 各项配置上的注释来了解其用途。 应用更改在应用更改前将第一项配置 TESTING = “1” 改为 TESTING = “0” 以使 csf 切换为工作模式。再以管理员权限执行 sudo csf -r 使更改生效。 屏蔽与允许 ip 地址防火墙最基础的功能是屏蔽，允许及忽略特定的 ip 地址，csf 可通过编辑 csf.deny, csf.allow 和 csf.ignore 文件来实现。 屏蔽 ip 地址使用编辑器打开 csf.deny1$sudo nano /etc/csf/csf.deny 每一行代表一条屏蔽项，可以是单一的 ip 地址，也可以是一个网段，例如：121.2.3.42.3.0.0/16 允许 ip 地址如果希望指定的 ip 地址或网段避开屏蔽和过滤扫描，可将它们加入到白名单列表，一旦将它们加入白名单，即便它们在 csf.deny 中已经存在，也会让它们绕过防火墙。 编辑 csf.allow 文件来加入白名单：1$sudo nano /etc/csf/csf.allow 忽略 ip 地址忽略名单与白名单的区别在于，忽略名单仅仅不进行过滤检查，但依然可能被加入黑名单中。1$sudo nano /etc/csf/csf.ignore 最后，执行 sudo csf -r 重载 csf 以使配置生效。]]></content>
      <categories>
        <category>Linux Basic</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 基础 - 指令与档案的搜索(which/whereis/locate/updatedb/find)]]></title>
    <url>%2Flinux-document-search%2F</url>
    <content type="text"><![CDATA[which(寻找「可执行文件」)1$ which [-a] command -a: 将所有定义在 $PATH 中与该指令相关的路径都列出来。 例如:1234567$ which ifconfig/sbin/ifconfig$ which whichalias which='alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde' /bin/alias /usr/bin/which 这里涉及到了命令别名 which 预设是搜索 PATH 内定义的目录，有些 bash 内建的指令并没有在 PATH 中定义，所以有可能找不到，例如 history 指令。 whereiswhereis 仅针对特定目录进行查找，所以速度会比 find 指令快，想知道哪些目录，执行 whereis -l 即可。1$ whereis [-bmsu] 档案名或目录名 -l: 列出 whereis 查询的主要目录 -b: 只找 binary 类型的文件 -m: 只找在说明档 manual 路径下的档案 -s: 只招 source 来源档案 -u: 搜寻不在上述三个项目中的其他特殊档案 举例:12$ whereis ifconfig/sbin/ifconfig /usr/share/man/man8/ifconfig.8.gz locate / updatedblocate 在「已经建立的资料库(/var/lib/mlocate/)」中搜索，因此速度很快，但不同的 Linux 发行版建立资料库的预设周期都不同(CentOS 7.x 是每天更新一次)，如果在资料库新建之前使用该命令，有可能找不到目标资料，这时可执行 updatedb 手动更新资料库，updatedb 指令首先读取 /etc/updatedb.conf 配置文件，再去硬盘里搜索档案名，最后更新整个资料库档案，由于要进行硬盘操作，整个过程可能会比较慢。1$ locate [-ir] 关键字 -i: 忽略大小写 -c: 不输出档案名称，仅计算找到的档案数量 -l: 输出行数，如输出 5 行则是 -l 5 -S: 输出 locate 所使用的资料库档案的相关咨询，包括该资料库记录的档案/目录数量等 -r: 后接正则表达式 find12345678910111213141516171819202122232425262728293031323334353637$ find [PATH] [option] [action]选项与参数：1. 与档案权限及名称有关的参数： -name filename：搜寻档案名称为 filename 的档案； -size [+-]SIZE：搜寻比 SIZE 还要大 (+) 或小 (-) 的档案。这个 SIZE 的规格有： c: 代表 byte， k: 代表 1024 bytes。所以，要找比 50KB 还要大的档案，就是『 -size +50k 』 -type TYPE ：搜寻档案的类型为 TYPE 的，类型主要有：一般正规档案(f), 装置档案(b, c), 目录(d), 连结档(l), socket(s), 及 FIFO(p) 等属性。 -perm mode ：搜寻档案权限『刚好等于』 mode 的档案，这个 mode 为类似 chmod 的属性值，举例来说，`-rwsr-xr-x` 的属性为 4755 ！ -perm -mode ：搜寻档案权限『包含 mode 的权限』的档案，举例来说， 我们要搜寻 `-rwxr--r--` ，亦即 0744 的档案，使用 -perm -0744， 当一个档案的权限为 `-rwsr-xr-x` ，亦即 4755 时，也会被列出来， 因为 `-rwsr-xr-x` 的属性已经包括 -rwxr--r-- 的属性了。 -perm /mode ：搜寻档案权限『包含任一 mode 的权限』的档案，举例来说，我们搜寻 `-rwxr-xr-x` ，亦即 -perm /755 时，但一个档案属性为 `-rw-------` 也会被列出来，因为他有 -rw.... 的属性存在！找出档名为passwd这个档案 [root@study ~]# find / -name passwd找出档名包含了passwd这个关键字的档案 [root@study ~]# find / -name "*passwd*" #利用这个-name可以搜寻档名啊！预设是完整档名，如果想要找关键字，# 可以使用类似* 的任意字元来处理找出/run目录下，档案类型为Socket的档名有哪些？[root@study ~]# find /run -type s #这个-type的属性也很有帮助喔！尤其是要找出那些怪异的档案，# 例如socket 与FIFO 档案，可以用find /run -type p 或-type s 来找！搜寻档案当中含有SGID或SUID或SBIT的属性 [root@study ~]# find / -perm /7000 #所谓的7000就是---s--s--t ，那么只要含有s或t的就列出，所以当然要使用/7000，# 使用-7000 表示要同时含有---s--s--t 的所有三个权限。而只需要任意一个，就是/7000 ～了乎？ 更多参数参考 http://linux.vbird.org/linux_basic/0220filemanager.php。]]></content>
      <categories>
        <category>Linux Basic</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 基础 - 档案内容查阅(cat/tac/nl/more/less/head/tail/od/touch)]]></title>
    <url>%2Flinux-document-inspect%2F</url>
    <content type="text"><![CDATA[cat(concatenate)1cat [-AbEnTv] 档案名 参数与选项: -A: 忽略空白字符，列出不可见的特殊字符 -b: 列出行号，仅针对非空白行 -E: 将结尾的换行字符 $ 显示出来 -n: 列出行号，包括空白行 -T: 将 Tab 以 ^| 显示 -v: 列出不可见的特殊字符 在使用 cat -A 指令后，Tab 以 ^| 显示，而换行符以 $ 显示，这样有助于查看空白部分到底是什么字符。 tac(反向串联)tac 命令恰好是 cat 命令反写，cat 从第一行输出至最后一行，而 tac 从最后一行输出到第一行。 nl(添加行号)1nl [-bnw] 档案名 参数与选项: -b: 指定行号的方式，主要有两种: -ba: 类似 cat -n，空行也列出行号 -bt: 忽略空白行的行号，预设值 -n: 列出行号表示方法，主要三种: -n ln: 行号位于左侧 -n rn: 行号位于右侧 -n rz: 行号位于右侧，且添零补齐 -w: 行号占位字符数举例:1234nl -ba -n rz -w 3 /etc/issue001 \S002 Kernel \r on an \m003 翻页(more 和 less)ln, cat 和 tac 都是将档案的全部内容一次性输出到屏幕上，more 与 less 指令提供了翻页功能。 more12345678more /etc/man_db.conf### This file is used by the man-db package to configure the man and cat paths.# It is also used to provide a manpath for those without one by examining# their PATH environment variable. For details see the manpath(5) man page.#--More--(28%) 使用 more 指令后，可以注意到最下端一行多出了一个百分比，此时如果按下: Space: 下一页 b: 上一页 Enter: 下一行 q: 退出 more 指令 /{字符串}: 向下查找 「字符串」 匹配的文本，按下 Enter 开始查找，按下 n 查找下一个， :f: 显示档案名及当前显示的行数lessless 在 more 的基础上做了改进，less 使用 PGUp 和 PGDown 来翻页。并且多出了一些选项: Space: 下一页 pagedown: 下一页 pageup: 上一页 /{字符串}: 向下查找 「字符串」 匹配的文本 ?{字符串}: 向上查找 「字符串」 匹配的文本 n: 重复前一个查找 N: 反向重复前一个查找 g: 跳转至第一行 G: 跳转至最后一行 q: 退出 less 指令 man 指令是执行 less 指令产生的结果，所以两者在用法上是相通的 文本截取(head 和 tail)head1head [-n number] 档案名 选项与参数: -n: 后接数字，代表显示前 n 行，如果不指定 -n 参数，默认情况下该指令显示前 10 行，如果指定为 -100，则表示显示最后 100 行之前的所有行举例: 123head /etc/man_db.conf # 输出前 10 行head /etc/man_db.conf -n 20 # 输出前 20 行head /etc/man_db.conf -n -100 # 输出最后 100 行前的所有行 tail1tail [-n number] 档案名 选项与参数: -n: 后接数字，表示输出最后 n 行，默认值为 10， -f: 表示实时侦测文档，Ctrl + C 来取消举例:1234tail /etc/man_db.conf # 输出最后 10 行tail -n 20 /etc/man_db.conf # 输出最后 20 行tail -n +100 /etc/man_db.conf # 输出 100 行后的所有行tail -f /var/log/messages # 实时监测该文档的内容，可与 -n 并用 如果希望输出某个文档的第 10-20 行，那么可以执行 head -n 20 /etc/man_db.conf | tail -n 10，意为先去前 20 行，再将其结果交给 tail 指令输出最后 10 行。 1cat -n /etc/man_db.conf | head -n 20 | tail -n 10 # 取 /etc/man_db.conf 的 10-20 行，并显示行号 非纯文本档案: od上述的所有指令都是针对纯文本的档案读取，对非纯文本档案的读取使用 od 指令:1od [-t TYPE] 档案名 选项与参数: -t: 接档案类型，类型有: a: 使用预设的字符输出 c: 使用 ASCII 输出 d[size]: 使用十进制(decimal)输出资料，每个整数占用 [size] 字节 f[size]: 使用浮点数(floating)输出资料，每个数占用 [size] 字节 o[size]: 利用八进(octal)制输出资料，每个整数占用 [size] 字节 x[size]: 利用十六进制(hexadecimal)来输出资料，每个整数占用 [size] 字节 该命令可用于快速定位字符的 ASCII 编码，例如: echo password | od -t oCc 修改档案时间或新建档案: touch对于某个档案，其主要有 3 个时间变动的入口: modification time(mtime): 档案的「内容」更改时，会更新该时间 status time(ctime): 档案的「状态」改变时，会更新该时间，例如权限和属性被更改 access time(atime): 「档案的内容被读取」时，会更新该时间，例如用 cat 指令读取某个档案 默认情况下，当使用 ls 指令时，得到的时间是 mtime，即该档案内容上次被修改的时间，如果发现时间不对，可 touch 指令修改时间:1touch [-acdmt] 档案名 选项和参数: -a: 仅修改 aceess time -c: 仅修改档案时间，若档案不存在则不建立新档案 -d: 修改 atime 和 mtime，后接目标时间，可用 –date=”日期或时间”代替 -m: 仅修改 mtime -t: 修改 atime 和 mtime，后接目标时间，格式为 [YYYYMMDDhhmm]举例:123touch testtouch # 建立新的空档案，三个时间都会更新会当前时间date; ll bashrc; ll - -time=atime bashrc; ll --time=ctime bashrctouch -d "2 days ago" bashrc # 修改 ; 用于分割连续下达的指令，这些指令会依次执行，ctime 是无法通过指令修改的，即便是完全复制一条档案，也无法复制 ctime，该属性记录了档案的状态变化时间。]]></content>
      <categories>
        <category>Linux Basic</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 基础 - 档案与目录管理(ls/cp/rm/mv/basename/dirname)]]></title>
    <url>%2Flinux-document-management%2F</url>
    <content type="text"><![CDATA[档案管理主要涉及: 显示档案详情 拷贝 删除档案 移动档案 ls(检视档案)123ls [-aAdfFhilnrRSt] 档名或目录名ls [--color=&#123;never,auto,always&#125;] 档名或目录名ls [--full-time] 档名或目录名 ls 常用的选项有: -a: 全部档案，包括隐藏档案 -A: 全部的档案，包括隐藏档案，但不包括 . 与 .. 两个目录 -d: 仅列出目录 -f: 直接列出结果，而不进行排序(ls 预设会以名称排序) -F: 为档案名添加特殊符号以标识其类别，例如 * 代表可执行档案，/ 代表目录，=: 代表 socket 档案，|: 代表 FIFO 档案。 -h: 将档案容量以人类友好的方式列出(GB, KB) -i: 列出 inode 号码 -l: 列出详情 -n: 使用 UID 与 GID 而非用户名称和群组名称 -r: 将排序结果反向输出 -R: 递归显示所有目录 -S: 以档案容量大小排序 -t: 以时间排序 ls 指令包含了很多功能，Linux 档案系统记录了与档案有关的权限和属性，这些数据都放在 i-node 里面，有关 i-node 的详情，见后文。 由于 ls -l 非常常用，很多 Linux 的发布版本使用 ll 指令使其成为 ls -l 的缩写，而这是由 Bash shell 的 alias 功能实现的，有关这部分内容，见后文。 cp(复制档案或目录)12cp [-adfilprsu] source destinationcp [options] source1 source2 source3 .... directory cp 常用选项: -i: 若目标已经存在，则要求询问是否覆盖 -d: 若源为 link 档，则复制 link 档的属性而非档案本身的属性 -f: force 的简写，若目标档已经存在且无法开启，则移除后再试一次 -p: 复制档案及其属性，备份常用 -r: 启用递归复制 -s: 复制为符号链接(symbolic link) -l: 复制为硬式链接(hard link) --preserve=all: 除了 -p 的相关属性外，还加入 SELinux 的属性，links，xattr 也复制。 -a: 相当于 -dr --preserve=all 如果不加任何选项，档案被复制后其属性会发生改变，如果想要完全复制档案，则需要加上 -a 选项。 在复制其他用户的资料时(必须要有 Read 权限)，总是希望得到的档案权限归自身用户所有，所以 cp 指令预设复制后的档案归复制者所有，这意味着在不加任何选项的情况下，得到的档案权限与复制者用户一致。在使用 cp 指令进行复制时，考虑以下几点: 是否需要完整保留原始档案的咨询？ 原始档是否为符号链接档 原始档是否为特殊的档案，例如 FIFO，socket 等？ 原始档是否为目录？ rm(移除档案或目录)1rm [-fir]档案或目录 rm 指令关键选项: -f: force 的简写，忽略不存在的档案，不会出现警告 -i: 互动模式，在删除询问使用者 -r: 递归删除 使用 * 通配符可以删除任意匹配的档案或目录 Linux 系统下，为了防止档案被 root 误删，很多发行版预设加入了 -i 这个选项。但是使用 rm -r 这个指令系统不会再次询问，使用前要特别注意。如果确定目录不要了，那么使用 rm -r 来递归删除是不错的方式。 mv(移动档案与目录，或更改名称)12mv [-fiu] source destination mv [options] source1 source2 source3 .... directory mv 指令关键选项: -f: force 的缩写，如果目标档已经存在，则不询问而直接覆盖 -i: 互动模式，若目标档案已经存在，则会询问是否覆盖 -u: 若目标档案已经存在，且原始档较新才会执行移动 -u 选项可以用来测试新旧档案，看看是否需要搬移；rm 指令可以用来重命名文件，但 Linux 有另外一个 rename 指令可以进行批量改名。 basename 和 dirname12basename /etc/sysconfig/networknetwork basename 用于获取档案本身的名称12dirname /etc/sysconfig/network/etc/sysconfig dirname 用于获取包含档案的目录的完整路径]]></content>
      <categories>
        <category>Linux Basic</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 基础 - 目录操作与 $PATH]]></title>
    <url>%2Flinux-directory-operations%2F</url>
    <content type="text"><![CDATA[本文大纲: 绝对路径与相对路径 常用目录操作 cd(change directory, 变换目录) pwd(print working directory, 显示当前所在目录) mkdir(make directory, 新建目录) rmdir(remove directory, 删除目录) 执行程序的环境变量: $PATH 绝对路径与相对路径Linux 中路径分为绝对路径与相对路径 绝对路径：由根目录作为起始路径 相对路径：由当前所在路径作为起始路径，当前路径可用 ./ 表示 在编写 shell 脚本时最好采用绝对路径，因为这样不会随着脚本文件所在的路径而对代码执行结果产生影响 常用目录操作Linux 系统常见的目录操作指令有: cd: 变换目录 pwd: 显示当前的目录 mkdir: 创建新目录 rmdir: 删除目录 cd(change directory, 变换目录)每一个登入 Linux 系统的用户第一个进入的目录都是该用户的 Home 目录，即 ~，同样也可以执行 cd ~ 回到 Home 目录，如果仅仅输入 cd 代表的就是 cd ~，cd - 代表回到前一个目录，在预设指令模式(bash shell)中，可以利用 tab 键来自动补齐路径。 pwd(print working directory, 显示当前所在目录)如果想要知道当前所在的工作目录，执行 pwd 即可。 -P 选项是显示当前目录链接的真实目录，例如，ubuntu 系统在 /var/spool/mail 下执行 pwd 会显示 /var/spool/mail，而执行 pwd -P 指令会显示 /var/mail，这表明 /var/spool/mail 链接到了 /var/mail。 返回上一级目录执行 ls -al 我们会看到 mail 目录指向了 ../mail/。12345drwxr-xr-x 0 root root 512 Sep 23 2017 ./drwxr-xr-x 0 root root 512 Mar 1 01:54 ../drwxr-xr-x 0 root root 512 Sep 23 2017 cron/lrwxrwxrwx 1 root root 7 Sep 23 2017 mail -&gt; ../mail/drwx------ 0 syslog adm 512 Apr 5 2016 rsyslog/ mkdir(make directory, 新建目录)默认情况下，执行 mkdir /home/pango/testing 目标目录需要一层一层的新建才行，为了递归创建目录，添加 -p 选项可以自动创建不存在的目录。 另外，通过 -m 选项可以在新建目录时为该目录指定权限，例如当执行 mkdir -p -m 711 /home/pango/testing 时，在该目录树上的所有新建的目录都会具有 drwx--x--x 权限。如果不指定 -m 选项，其默认权限会与 umask 有关，见后文。 rmdir(remove directory, 删除目录)与 mkdir 指令类似，默认情况下，目标目录需要一层一层的删除才行，且被删除的目录必须为空，即该目录下不能存在任何目录或文件。 而 -p 提供了递归删除目录选项，且会删除指定目录下的任何目录和文件，该操作比较危险，使用时需谨慎。 执行程序的环境变量: $PATH指令 ls 的二进制可执行程序所在的目录为 /bin/ls，可是为何可以在任何目录下执行 ls 这个指令呢？这就是环境变量 $PATH 的作用。 当执行 ls 指令时，系统会根据 PATH 的值去每个定义的目录下搜索名称为 ‘ls’ 的可执行文件，如果在 PATH 定义的目录中包含多个名称为 ‘ls’ 的可执行文件，那么先被找到的指令会被执行。 执行 echo $PATH 会在屏幕上打印出所有定义的路径值，$ 表示环境变量，PATH 表示环境变量的键，注意 PATH 一定都是大写字母，其定义的多个路径每个之间由 : 分隔。 现在，如果将 ls 指令从 /bin/ls 通过 mv /bin/ls /root/ 移动到 /root/ 目录下， 即使执行 cd /root 切换到与其相同的目录下，执行 ls 指令仍被告知找不到指定的指令，因为 PATH 中并未定义 /root 路径，系统搜索不到该指令。 可以通过使用绝对路径或相对路径来执行该指令: /root/ls 或 ./ls。 可通过 PATH=&quot;${PATH}:/root&quot; 将 /root 加入到 PATH 变量中。 此外，关于 PATH 需要注意以下几项: 不同的用户的环境变量 PATH 的值是不同的。 PATH 是可以修改的 相比修改 PATH 的值，优先使用绝对路径或相对路径来执行某个指令。 指令放置到正确的目录下 最好不要将当前目录 . 加入到 PATH 当中。]]></content>
      <categories>
        <category>Linux Basic</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 基础 - 目录配置]]></title>
    <url>%2Flinux-directory-configuration%2F</url>
    <content type="text"><![CDATA[参考资料: http://linux.vbird.org/linux_basic/0210filepermission.php#dir 本文大纲: Linux 目录配置 根目录 /usr 的意义与内容 /var 的意义与内容 Linux 目录配置Linux 采用 FHS(Filesystem Hierarchy Standard) 标准作为配置目录结构的参考依据，目前，大多数 Linux 的发行版本都遵循了这套标准。FHS 将目录定义为四种交互形态，表格如下： 可分享的(shareable) 不可分享的(unshareable) 不变的(static) /usr(软件所在位置) /etc(配置目录) /opt(第三方协议软件) /boot(开机与核心档) 可变的(variable) /var/mail(用户邮件信箱) /var/run(程序相关) /var/spool/news(新闻群组) /var/lock(程序相关) 可分享的: 可分享给其他系统挂载使用的目录，包括可执行程序与邮件等 不可分享的: 仅与本地系统或配置有关的，分享给其他主机将无法直接使用 不变的: 例如函数库，文件说明系统管理员管理的主机服务配置文件等 可变的: 经常需要改变的资料，如登录档案，用户收取的新闻等。 事实上, FHS 仅定义以下三层目录的用途： /(root, 根目录): 与开机系统有关 /usr(unix software resource): 与软件安装/执行有关 /var(variable): 与系统运作过程有关 从用户角度看，root 指系统的超级管理员身份，从目录角度看，root 指系统的根目录 根目录所有的目录都是从根目录衍生出来。根目录与开机/还原/系统修复等动作有关，FHS 建议根目录不要放在非常大的分区内，且应用程序安装的软件最好也不要与根目录放在同一个分区内，内容越多的分区出错的几率也越高。以下是 FHS 定义的次目录： 必须要存在的目录 档案 描述 /bin 系统有多个放置可执行程序的目录，但 /bin 比较特殊，该目录放置的是「在单人维护模式下仍然能够执行的程序」，该目录的指令可以被 root 与一般用户执行，主要有 cat, chmod, chown, date, mv, mkdir, cp, bash 等常用指令 /boot 主要放置开机会使用的档案，包括 Linux 核心档案及开机选单与开机所需配置等 /dev 在 Linux 系统中，任何装置与外设都是以文件形态存在于这个目录中，存取该目录下的文件等同于存取某个设备，比较重要的有 /dev/null, /dev/zero, /dev/tty, /dev/loop, /dev/sd 等等 /etc 系统主要的⎡配置文件⎦几乎都放在该目录下，FHS 不建议放置任何可执行文件(binary)在这个目录下，例如 /etc/modprobe.d/, /etc/passwd, /etc/fstab, /etc/issue。同时，FHS 还建议：/etc/opt(必须): 这里放置 /opt 下第三方协议软件对应的配置信息 /etc/X11(建议): 与 X Window 有关的各种配置信息放置在这里，尤其是 xorg.conf 这个 X Server 的配置 /etc/sgml(建议): 与 SGML 格式有关的各项配置 /etc/xml(建议): 与 XML 格式有关的各项配置 /lib 系统的函数库非常多，「/lib 放置的是开机会用到以及在 /bin 或 /sbin 下的指令会调用的函数库」。另外，FHS 要求在该目录必须要存在: /lib/modules: 放置可插拔的核心相关模块(驱动程序等) /media 放置可移除的装置，包括软碟，光碟，DVD 等都暂时挂载于此。常见的有 /media/floppy, /media/cdrom 等 /mnt 暂时挂载额外装置的目录，早些时候该目录与 /media 用途相同，在有了 /media 之后，该目录就主要是暂时挂载用途了 /opt 第三方协议软件的目录(即非 Linux 发行版本自带的软件程序)，早些时候，这些软件多数放在 /usr/local 下 /run 早期的 FHS 规定系统开机后所产生的各项资讯应该要放置到 /var/run 目录下，新版的 FHS 则规范到 /run 底下。由于 /run 可以使用内存来模拟，因此具有更高的性能 /sbin Linux 系统有非常多的指令用来设定系统环境，这些指令只有 root 才能使用，其他用户只能使用查询功能，/sbin 下包含了开机，修复，还原系统所需要的指令。某些服务器软件程序，一般放置在 /usr/sbin 中，而本机自行安装的软件产生的系统执行文件(system binary)，则放置在 /usr/local/sbin 中了，常见的指令包括: fdisk, fsck, ifconfig, mkfs 等等 /srv srv 可视为「service」的缩写，某些网络服务启动后，需要取用的资料目录，例如 www，ftp 服务，如果这些服务不需要公开提供给互联网，那么建议放置到 /var/lib 下 /tmp 一般用户或正在执行的程序暂时放置档案的地方，任何用户都可以存取该目录，所以需要定期清理，FHS 建议在开机时应该要将 /tmp 下的资料都删除 /usr 见后文 /var 见后文 FHS 建议可以存在的目录： 档案 描述 /home 系统预设的用户 Home 目录，新用户的 Home 目录会默认创建在该目录下，其代号字符为：~：当表当前用户的 Home 目录~&lt;username&gt;: 代表 username 的 Home 目录 /lib/qual 存放与 /lib 不同格式的二进制函数库，例如 64 位 /lib64 函数库等 /root 系统管理员 root 的 Home 目录，如果进入单人维护模式而仅挂载根目录时，该目录就能够拥有 root 的 Home 目录，所以通常 root 用户的 Home 目录与根目录放置在同一个分区中 /usr 的意义与内容首先 usr 是 Unix Software Resource 的缩写，表示「操作系统软件资源」所放置的目录，而不是 User 的缩写。FHS 建议所有软件开发者应该将他们的资料分别合理的放置到该目录下的次目录中，而不要自行创建独立的目录。Linux 发行版本的所有内置软件都会放到 /usr 下，系统安装完毕后该目录会占用最多的硬盘容量，/usr 次目录的建议有： FHS 要求必须要存在的目录 档案 描述 /usr/bin/ 一般用户能够使用的指令都放在这里，目前 CentOS 7 已经将全部的用户指令放置于此，而使用链接将 /bin 链接至此，意即，/usr/bin 与 /bin 是一摸一样了。另外，FHS 要求在此目录下不应该有子目录。 /usr/lib/ 基本与 /lib 相同，/lib 就是链接到此目录中的 /usr/local/ 系统管理员在本机自行下载安装的软件建议安装到此目录 /usr/sbin/ 非系统正常运行所需要的系统指令，目前 /sbin 链接到此目录中 /usr/share/ 主要放置只读架构的资料档案，包括共享文件 FHS 建议可以存在的目录 档案 描述 /usr/games/ 与游戏相关的资料目录 /usr/include /usr/libexec 某些不会被一般用户常用的执行文件或脚本会放置在该目录 /usr/lib 与 /lib/ 功能相同，/lib 就是链接到此目录 /usr/src 源代码放置目录 /var 的意义与内容/var 会在系统运行过程中渐渐产生内容，包括缓存，日志及某些软件运行所产生的数据，例如 MySQL 的数据文件等，常见的次目录有：FHS 要求必须要存在的目录 档案 描述 /var/cache/ 应用程序运行过程中产生的暂存数据 /var/lib/ 应用程序运行过程中，需要使用的资料档案放置的目录，此目录下每个软件应该有自己的目录，举例来说，MySQL 的资料库应该放置到 /var/lib/mysql。 /var/lock/ 用于对某些装置或档案资源进行排他加锁，目前此目录已移动到 /run/lock /var/log/ 至关重要，放置了程序运行所产生的日志文件 /var/mail/ 放置个人电子邮件的目录，已移动到 /var/spool/mail/ 目录中 /var/run/ 某些程序或服务启动后，会将他们的 PID 放置在这个目录下。与 /run 相同，链接到 /run /var/spool/ 该目录通常放置队列数据，crontab 文件就放置在 /var/spool/cron/ 目录中 以 CentOS 7 为例，比较其目录结构与 FHS 规定的内容的差异： /bin –&gt; /usr/bin /sbin –&gt; /usr/sbin /lib –&gt; /usr/lib /lib64 –&gt; /usr/lib64 /var/lock –&gt; /run/lock /var/run –&gt; /run 主要是将许多原本在根目录下 / 的资料移到了 /usr 中，然后设置了链接]]></content>
      <categories>
        <category>Linux Basic</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 基础 - 预设权限(umask)，隐藏权限(chattr/lsattr)和特殊权限(SUID/SGID/SBIT)]]></title>
    <url>%2Flinux-document-preset-and-hidden-privilage%2F</url>
    <content type="text"><![CDATA[预设权限umaskumask 表示当前用户建立档案和目录时的预设权限。12$ umask0022 umask 针对档案和目录的权限是不同的，对于新的档案，是不包括执行(x)权限的，而目录则包括所有权限，返回的数字是指应该减去的分数，进行反向计算，0022 表示，新的档案的权限为 -rwxr-xr-x。例如:123456789$ mkdir test$ cd test$ umask 0022$ touch test_file$ mkdir test_dir$ ls -Aldrwxr-xr-x 0 Pango Pango 512 May 14 23:23 test_dir-rw-r--r-- 1 Pango Pango 0 May 14 23:23 test_file umask -S 加上 -S 参数则显示正向计算的结果12$ umask -Su=rwx, g=rx,o=rx 0022 表示，user 拥有全部权限，而 group 和 others 则被减去了 write 权限。 1$ umask 002 # 直接通过后接数字来设置 umask 的值。 在架设 SAMBA Server 或 FTP Server 时，umask 的值涉及到你的用户能否对新建的档案进行进一步操作的问题。 root 用户的 umask 是 022，一般用户则是 002，这是出于安全的考虑，关于 umask 预设设定可以参考 /etc/bashrc 这个文件，不过不建议修改该档案。 隐藏权限chattr修改档案或目录的隐藏属性，change attribute。1$ chattr [+-=][ASacdistu] 档案或目录名称 +: 追加一个特殊参数 -: 移除一个特殊参数 =: 设置特殊参数 A: 当设定了该参数后，当读取此档案或目录时，其 atime 不会被修改 S: 一般的档案是异步写入磁盘的，如果设置了 S 参数，则对档案进行的任何修改，都会以同步方式写入磁盘 a: 该档案只能新增资料，而不能删除也不能修改资料，只有 root 用户能设定该属性 c: 自动压缩档案，读取时自动解压缩，存储时先压缩再存储 d: 当 dump 程序执行的时候，被设定为 d 属性的档案不参与备份。 i: 使一个档案「无法被删除，修改，改名，设置连接」，只有 root 用户可以设置此属性。 s: 硬删除，无法进行磁盘复原 u: 与 s 相反，如果该档案被删除，可以使用相关工具复原。 以上属性中最重要的当属 a 和 i 了。+a 常用于对某些非常重要的档案的安全控制，而 +i 则常用于日志档案。 lsattr显示档案或目录的隐藏属性，list attributes1$ lsattr -[adR] 档案或目录 -a: 将隐藏档案的属性也显示出来 -d: 如果连接的是目录，仅列出目录本身的属性而非目录内的档案 -R: 递归显示 特殊权限SUIDSet UID 的缩写，该权限有以下限制和功能: SUID 仅对二进制程序有效 执行者对于该程序需要有 x 的执行权限 SUID 仅在执行该程序的过程中有效 执行者将获得该程序拥有者的权限。 例如，/etc/shadow 档案保存了所有用户的密码，该文档的权限为 --------- l root root，意即该档案仅 root 用户可以强制写入，那么一般用户在执行 passwd 命令时其实是可以修改自己的密码的，这就是 SUID 的功能，即: 一般用户对 /usr/bin/passwd 程序具有 x 权限 shadow 档案拥有者是 root 用户 一般用户执行 passwd 的过程中，会「暂时」获得 root 的权限 /etc/shadow 就能被一般用户执行的 passwd 修改。 SUID 对目录是无效的，其以 s 取代「拥有者用户」一栏的 x 权限。 SGID当 s 出现在群组权限的执行权限上时，则称为 SGID。SGID 有如下功能: SGID 对二进制程序有用 使用该程序的用户必须对该程序有 x 权限 用户在执行过程中会获得该程序群组的权限 当 SGIP 作用于目录时，将: 用户对此目录具有 r 和 x 的权限，该用户能够进入此目录 用户在此目录下的有效群组将会变成该目录的群组若用户在目录下有 w 权限，则用户新建的档案，该档案所属的群组与目录所属的群组相同。 当设置 SGID 后，将以 s 取代在「群组」权限一栏的 x 权限。 Sticky Bit目前只针对目录有效，其作用是，用户对某个目录具有 w 和 x 权限时，在该目录下创建档案或目录后，仅用户自己与 root 才能删除这些档案或目录。该功能让多个用户在同一目录下管理与自己相关的文件。 对目录设置 SBIT 后，将以 t 取代「其他用户」权限的 x 权限。 设定 SUID/SGID/SBIT之前的权限设定是只有 3 个数字，加上 SUID/SGID/SBIT 之后变成了 4 个数字，执行 chmod 4755 filename 来为该文件新增特殊权限。4755 的字符串表示为 -rwsr-xr-x。 s 与 t 都是取代 x 这个权限，但当权限为 7666 时，由于在「用户」，「群组」和「其他用户」三栏都不包含「执行(x)」权限，字符串将以大写 S 和 大写 T 来表示，以示该权限实际上无效。例如:12$ chmod 7666 test; ls -l test -rw S rw S rw T 1 root root 0 Jun 16 02:53 test 除了数字法赋值权限之外，还可以使用 u+s 追加 SUID 权限、g+s 追加 SGID 权限和 o+t 追加 SBIT 权限。 file(观察档案类型)file 指令用于判断档案的类型，例如:12$ file ~/.bashrc/root/.bashrc: ASCII text]]></content>
      <categories>
        <category>Linux Basic</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 基础 - 档案与权限(chgrp/chown/chmod)]]></title>
    <url>%2Flinux-profile-and-privilege%2F</url>
    <content type="text"><![CDATA[参考资料: http://linux.vbird.org/linux_basic/0210filepermission.php#filepermission_perm 本文大纲: 修改档案属性及权限 更改群组 更改档案拥有者 更改权限 权限的意义 当执行 ls -al 后，当前目录下所有档案的详情被列出 12dr-xr-xr-x. 17 root root 4096 May 4 17:56 ..-rw-------. 1 root root 1816 May 4 17:57 anaconda-ks.cfg 第 1 列用一组字符组合来表示其类别和属性，该字符串的第一位标识该档案的类别，详情见后文，而后连续 9 个字符，每 3 个一组，表示该权限的拥有者，同群组的其他用户和其他用户对该档案的权限，例如 -rwxr-xr-- 表示一个档案的权限为： 该档案为文件 拥有者对其拥有读取，修改和执行权限 同一群组中的其他用户对其拥有读取和执行权限 其他用户对其仅有读取权限 第 2 列表示有多少不同的档案名链接到该档案的 i-node，每个档案将会将它的权限与属性记录到档案系统的 i-node 中 第 3 列表示档案的拥有者用户 第 4 列表示该档案所属第群组 第 5 列表示该档案所占用第磁盘空间，预设单位为 bytes 第 6 列表示该档案的创建日期或修改日期 第 7 列为档案名 修改档案属性及权限更改群组chgrp: 该指令为 change group 的缩写，目标群组必须在 /etc/group 中存在，使用 -R 指定递归改变父级目录下的群组:1$sudo chgrp &lt;target-group&gt; -R filename/directory 更改档案拥有者chown 为 change owner 的缩写，目标用户必须在 /etc/passwd 中存在，可使用 -R 选项指定递归更改选项。 该命令还可以顺便修改群组，例如:1$sudo chown user1:group1 filename 可使用 . 或者 : 来隔开用户名和群组名，但如果在用户名中包含 . 字符，则容易造成混淆，所以一般建议使用 : 来隔开用户名和群组。 chown 也可通过 . 直接更改群组,如:1$sudo chown .group1 filename 更改群组一个常见的应用为，当通过 cp 复制一个档案时，也会同时复制命令执行者的属性与权限，此时更改属性和权限就显得尤其必要了 更改权限chmod 为更改档案权限的指令，默认情况下，可使用字符来为三种角色指定权限，首先指定角色: u: 代表拥有者，即 users g: 代表拥有者群组，即 group o: 代表其他，即 others a: 代表所有，即 all 然后使用以下连字符修改权限: =: 代表赋值，指定 +: 代表增加权限 -: 代表移除权限 例如 chmod u=rwx,go=r-x filename 表示设定档案的权限为 rwxr-xr-x，或 chmod g+w filename 在不知道原来权限的基础上增加群组的写入权限。 chmod 可以使用数字或字符来更改档案的权限，数字代表的含义为: r: 4 w: 2 x: 1 -: - 每种身份的权限由三者数字累加起来得到一个数字，例如 chmod 740 filename 表示拥有者具有 rwx 权限，同群组其他用户具有 r-- 权限，其他用户则具有 --- 权限。 权限的意义权限分为三种： r: 读取权限 针对文件：读取文件的实际内容 针对目录：读取目录结构清单，例如使用 ls 指令 w: 写入权限 针对文件: 可编辑，新增或修改文件的内容，但不含删除操作 针对目录: 具有对改动该目录结构的权限，包含： 新建文件与目录 删除已经存在的文件或目录(不受被删除文件和目录的权限限制) 重命名文件或目录 移动文件或目录 x: 执行权限 针对文件: 执行文件(如果该文件可执行) 针对目录: 指示用户能否进入该目录，如执行 cd 指令表格形式如下： 元件 内容 迭代物件 r w x 文件 详细资料 文件夹文件 读取文件内容 修改文件内容 执行文件内容 目录 目录名称 可分类抽屉 读取目录内容 修改目录结构 进入该目录 除了文件和目录两种档案之外，还有其他一些档案类型： 常规文件(regular file)，常规文件档案，权限的第一栏为 -，例如 -rwxrwxrwx，常规文件又可分为三类： 文本文件: 可以直接读取的内如，几乎所有的配置型文件都属于这一类，可执行 cat &lt;filename&gt; 来查看文件内容 二进制文件: Linux 系统仅认知且可执行二进制文件(binary file)，script 脚本及批处理不算，例如，当执行 cat 指令时，cat 就是一个 binary file。 数据文件(data): 供不同的程序自己使用的特殊格式的文件，例如，当使用 Linux 登入时，系统会将登录日志记录在 /var/log/wtmp 文件内，但该文件是一个数据文件，只能通过 last 指令读出来，若使用 cat 读取该文件会显示乱码 目录(directory): 目录档案，权限第一栏为 d，例如 drwxrwxrwx 链接(link): 类似于 windows 系统的快捷方式，第一栏为 l，例如 lrwxrwxrwx 软链接: 见 inode 硬链接: 见 inode 设备与装置档案: 系统周边及存储等相关的档案，通常集中在 /dev 目录下，他们又分为： 区块(block)设备档案: 存储资料，提供系统随机存储的设备，硬盘与软盘都属于这类，第一栏为 b，可查阅 /dev/sda 下的内容。 字符(character)设备档: 亦即外设，如键盘，鼠标等，这些设备的特点是「一次性读取」，不能截断输出，例如，不能让鼠标「跳跃到」另外一个地方，而是「连续滑动」到另一个地方。权限第一栏为 c 数据接口档案(sockets): 主要用于网络数据通信，第一栏为 s，该类型通常位于 /run 或 /tmp 这些目录中 数据传输接口档案(FIFO, pipe): FIFO(first in first out)也是一种特殊的档案类型，它是为了解决多个解决同时存取一个文件所造成的错误问题。第一栏为 p 设备是系统文件，最好不好随意修改。 windows 系统中可执行文件通常带有 .exe .bat 等扩展名，而 Linux 系统中基本没有所谓的「扩展名」概念，一个 Linux 文件能否被执行与它的权限栏 10 个属性有关，与其文件名或扩展名没有任何关系，只要其权限中带有 x 属性，该文件就可以被执行。 为了保持可读性，通常还是会在文件末尾加上扩展名以让用户了解该文件是什么，常用的扩展名有： *.sh: 脚本或批处理文件，因为这些文件基于 shell 写出，所以为其添加了 .sh 扩展名 Z, .tar, .tar.gz, .zip, *.tgz: 压缩包文件，由不同的压缩程序如 gunzip, tar 等输出，所以根据不同的程序命名不同的扩展名 .html, .php: php 语法写成的网页文件等 总之，Linux 的文件名仅仅是为了让用户了解其用途而已，能否执行取决于文件权限，如果 /bin/ls 文件的可执行权限被移除，那么 ls 便无法使用了。 关于档案的几点注意： 单一文件或目录文件名长度不超过 256 字节 名称中不得包含 * ? &gt; &lt; ; &amp; ! [ ] | \ ‘ “ ` ( ) { } 等特殊字符 第一个字符为 . 时，表示该档案为隐藏档案]]></content>
      <categories>
        <category>Linux Basic</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 基础 - 用户和群组]]></title>
    <url>%2Flinux-account-and-group%2F</url>
    <content type="text"><![CDATA[参考资料： http://linux.vbird.org/linux_basic/0410accountmanager.php 本文大纲: 用户帐号管理 新建用户帐号 - useradd 设置帐号密码 - passwd 管理帐号密码策略 - chage 修改用户帐号信息 - usermod 删除用户帐号 - userdel 用户端指令 - id, finger, chfn, chsh 群组管理 新增群组 - groupadd 修改群组 - groupmod 删除群组 - groupdel 群组管理员 - gpasswd 初始群组，次要群组和有效群组 Linux 使用文件及配置相应的权限来存储用户帐号和群组信息，在成功创建好用户帐号之后，以下几处文件会发生相应的改变 /etc/passwd: Linux 管理用户帐号的数据库 /etc/shadow: Linux 管理用户帐号密码配置的数据库 /etc/group: Linux 管理群组的数据库 /etc/gshadow: Linux 管理群组密码配置的数据库 用户帐号管理Linux 系统用户管理相关命令主要有： useradd：新建用户 passwd：设置用户密码 chage: 变更密码策略 usermod：编辑用户 userdel：删除用户 新建用户帐号 - useraddlinux 系统以 useradd 命令来新建 Unix 用户，该命令带有一系列参数： 12345678910111213useradd [-u UID] [-g 初始群组] [-G 次要群组] [-mM] [-c 说明栏] [-d 家目录绝对路径] [- s shell] &lt;new-user-name&gt;-u ：接 UID ，一组数字，直接指定一个特定的 UID 给这个用户-g ：为该用户指定初始群组 initial group，该群组的 GID 会被放置到/etc/passwd 的第四个栏位-G ：为该用户指定次要群组，该选项与参数会修改 /etc/group 内第四栏的值-M ：不要为用户建立 Home 目录(系统帐号预设值)-m ：为用户建立 Home 目录(一般帐号预设值)-c ：用户备注，该值修改 /etc/passwd 文件的第五栏的内容-d ：指定特定目录成为该用户的 Home 目录，而不采用预设值，需指定绝对路径-r ：建立一个系统帐号，该帐号的 UID 会有限制(参考/etc/login.defs)-s ：指定 `shell` ，若不指定则预设为 /bin/bash-e ：指定该用户的过期日期，格式为『YYYY-MM-DD』此项写入 `/etc/shadow` 第八栏-f ：指定密码是否立即失效，写入 /etc/shadow 的第七栏位。0 为立刻失效，-1 为永远不失效(密码只会过期而强制于登入时重新设定而已) 例如，执行以下命令新建一个用户：1$sudo useradd pango 该命令创建一个名为 pango 的用户，由于没有使用 -r 指令，将随机分配一个 1000 以上的数值作为 uid，创建一个名为 pango 的群组并作初始群组，为该用户创建 Home 目录，使用 /bin/bash 作为工作环境。该命令对系统的以下部分做出修改： 在 /etc/passwd 里面新建一行用户值，包含 UID/GID/Home 目录等； 在 /etc/shadow 里面将此用户的密码相关参数填入，但是尚设置密码； 在 /etc/group 里面加入一个与用户名称一样的群组名称，如果已经存在与该用户名同名的群组名，则不会新建群组 在 /home 目录下新建一个与帐号同名的目录作为用户的 Home 目录，且权限为 700 注意，在 linux 系统中新增用户帐号和群组时，名称是区分大小写的 useradd 指令参考 /etc/defaults/useradd 文件中的配置作为缺省参数的预设值，使用 useradd -D 指令查看预设值：12345678$ useradd -DGROUP=100 # 预设的群组，系统内 GID = 100 的群组为 users 群组，但目前很多发行版都采用私有群组制，即为每个新建的用户帐号创建与之同名的群组来隔离权限HOME=/home # 预设的 Home 目录INACTIVE=-1 # 密码失效日期，对应 /etc/shadow 第 7 栏EXPIRE= # 用户帐号失效日，对应 /etc/shadow 第 8 栏SHELL=/bin/sh # 默认使用的 shell 程序名，如果 server 不希望任何新建的用户帐号登入系统取得 shell，那么将此项改为 /sbin/nologinSKEL=/etc/skel # Home 目录初始内容参考目录，即为新建用户创建 Home 目录时需要复制的初始内容，例如，在该目录下新增 www 目录，那么后续每个创建的新用户 Home 目录都会有 www 目录CREATE_MAIL_SPOOL=no # 是否主动帮用户建立邮件信箱，如果该项为 yes，则会新建 /var/spool/mail/&#123;username&#125; 目录作为该用户的邮箱 使用 nano 或 vim 查看 /etc/default/useradd 文件可以得到更多的详细信息：1$ nano /etc/default/useradd 登录信息参考在 /etc/login.defs 文件中定义，使用 nano 查看该文件123456789101112131415161718192021$ nano /etc/login.defsMAIL_DIR /var/spool/mail # 用户预设邮件信箱放置目录PASS_MAX_DAYS 99999 # /etc/shadow 内的第 5 栏，多久需变更密码日数 PASS_MIN_DAYS 0 # /etc/shadow 内的第 4 栏，多久不可重新设定密码日数 PASS_MIN_LEN 5 # 密码最短字符长度，已被 pam 模组取代PASS_WARN_AGE 7 # /etc/shadow 内的第 6 栏，过期前会警告的日数UID_MIN 1000 # 用户最小的 UID，意即小于 1000 的 UID 为系统保留 UID_MAX 60000 # 用户能够用的最大 UID SYS_UID_MIN 201 # 保留给用户自行设定的系统帐号最小值 UID SYS_UID_MAX 999 # 保留给用户自行设定的系统帐号最大值 UID GID_MIN 1000 # 用户自订群组的最小 GID，小于 1000 为系统保留 GID_MAX 60000 # 用户自订群组的最大 GID SYS_GID_MIN 201 # 保留给用户自行设定的系统帐号最小值 GID SYS_GID_MAX 999 # 保留给用户自行设定的系统帐号最大值 GIDCREATE_HOME yes # 在不加 -M 及 -m 时，是否主动建立用户家目录UMASK 077 # 用户 Home 目录建立的 umask ，因此权限会是 700 USERGROUPS_ENAB yes # 使用 userdel 删除时，是否删除初始群组 ENCRYPT_METHOD SHA512 # 密码加密的机制使用的是 sha512 加密算法 所以，系统在执行 useradd 命令时至少会参考： /etc/default/useradd /etc/login.defs /etc/skel/* 现在查看 /etc/passwd 档案的最后一行：1pango:x:1000:1000::/home/pango:/bin/bash 该文件是存放所有用户信息的数据库，每一行代表一个用户，每行由 6 个 : 分隔成了 7 个栏位： 用户名 密码 用户 UID：0 保留给系统管理员 root 账号；1~999 保留给系统账号，这些账号通常为执行某些系统服务所用，不能通过 shell 登录；1000~4294967295，保留给一般账号 用户初始群组 GIP 备注 Home 目录，预设值为 /home/{username} 执行 Shell 的程序目录，预设值为 /bin/bash 设置帐号密码 - passwd现在，新建的用户 pango 还没有密码，在设置密码之前是无法登录的，执行 passwd 来为新用户指定密码：12345678910111213141516$ passwd [--stdin] [帐号名称] # 所有人均可使用来改自己的密码 $ passwd [-l] [-u] [--stdin] [-S] [-n 日数] [-x 日数] [-w 日数] [-i 日数] 帐号 # root 功能选项与参数：--stdin ：可以透过来自前一个管线的资料，作为密码输入，对 shell script 有用-l ：是 Lock 的意思，会将 /etc/shadow 第 2 栏最前面加上 '!' 使密码失效；-u ：与 -l 相对，是 Unlock 的意思-S ：列出密码相关参数，亦即 shadow 档案内的大部分信息-n ：自上一次修改密码后的密码不可修改天数，shadow 的第 4 栏位-x ：自上一次修改密码后的密码有效天数，shadow 的第 5 栏位-w ：密码过期前的警告天数，shadow 的第 6 栏位-i ：密码失效缓冲天数，shadow 的第 7 栏位$sudo passwd pangoEnter new Unix Password:Retype new Unix Password: passwd 指令在不接参数时表示修改当前登录用户的密码 密码设置成功后，在 /etc/shadow 文件中发生了一些改变，定位到该文件的最后一行：1pango:$6$csIys5qj$OslSKU.3SljbHXTXJEPgWvNi1w9CGlBKO3uqJyWueQN1ypA7SuNzJWjesdSvg6KPv0X6tRmkkDBFI2cbSJ.xR/:17600:0:99999:7::: 该文件存储了所有用户的密码相关配置，每一行代表一个用户的密码信息，每行由 8 个 : 分隔为 9 个栏位： 用户名 经过加密的密码 最近修改密码日期，该值为一个代表 day 的数值，从 1970-01-01 日算起 密码不可修改天数：该值指示密码在最近一次修改后多久之后才能再次被修改 密码有效期（天）：该值指示密码再最近一次修改后的有效天数 密码需要变更前的警告天数 密码失效延迟（天）：密码过期后的缓冲时间 账号失效日期（天）：该值指示该用户的总生命周期多长，与密码有效无效无关 系统保留扩展项： 通过标准输入 --stdin 来修改密码，例如，帮助 pango 用户将其密码修改为 ‘abc543CC’ 123$ echo "abc543CC" | passwd --stdin pangoChanging password for user pango.passwd: all authentication tokens updated successfully. --stdin 选项并不存在于所有 Linux 发行版本的系统中，使用前先 man passwd 查看是否支持 管理帐号密码策略 - chage除了使用 passwd 指令，还可以使用 chage 指令来管理密码策略，其用法大致如下：123456789$ chage [-ldEImMW] 用户帐号名选项与参数：-l ：列出该帐号的详细密码参数；-d ：修改 shadow 第 3 栏位(最近一次更改密码的日期)，格式 YYYY-MM-DD-E ：修改 shadow 第 8 栏位(帐号失效日)，格式 YYYY-MM-DD-I ：修改 shadow 第 7 栏位(密码失效日期)-m ：修改 shadow 第 4 栏位(密码最短保留天数)-M ：修改 shadow 第 5 栏位(密码多久需要进行变更)-W ：修改 shadow 第 6 栏位(密码过期前警告日期) passwd -S 只是简单显示了密码详情，而 chage -l 更多为管理员提供了更强的参考信息，列出 pango 的详细密码参数 ：12345678$ chage -l pangoLast password change : Jul 20, 2015Password expires : Sep 18, 2015Password inactive : Sep 28, 2015Account expires : neverMinimum number of days between password change : 0Maximum number of days between password change : 60Number of days of warning before password expires : 7 修改用户帐号信息 - usermod当需要修改用户帐号的信息时，我们可以通过前往相应的文件例如，/etc/passwd 和 /etc/shadow 中去修改对应行的值以达到修改用户帐号信息的目的。也可以使用 usermod 指令对用户帐号进行修改：1234567891011121314$ usermod [-cdegGlsuLU] username 选项与参数：-c ：修改用户备注，对应 /etc/passwd 第 5 栏-d ：修改帐号 Home 目录，对应 /etc/passwd 的第 6 栏；-e ：修改帐号失效日期，格式是 YYYY-MM-DD，对应 /etc/shadow 内的第 8 栏-f ：修改密码失效延迟时间，对应 shadow 的第 7 栏。-g ：修改初始群组，修改 /etc/passwd 的第 4 栏-G ：修改次要群组组，修改该用户支援的群组，修改应用到 /etc/group-a ：与 -G 合用，表示 append，追求次要群组而非改变-l ：修改帐号名称， /etc/passwd 的第 1 栏-s ：修改 shell 接入程序，后面接 Shell 的实际程序，例如 /bin/bash 或 /bin/csh 等等-u ：修改 uid 对应 /etc/passwd 第 3 栏-L ：暂时锁定用户，暂时无法登入。仅修改 /etc/shadow 的密码栏。-U ：解锁用户，移除 /etc/shadow 密码栏的 '!' 删除用户帐号 - userdel当需要删除用户帐号时，执行 userdel 命令，该命令会对以下文件造成影响： 用户帐号/密码相关值：/etc/passwd，/etc/shadow 用户群组相关参数：/etc/group，/etc/gshadow 用户个人资料目录：/home/{username}，/var/spool/mail/{username} 该指令用法如下：123$ userdel [-r] username 选项与参数：-r ：连同用户的 Home 目录也一起删除 例如，删除 pango 用户帐号及其 Home 目录：1$sudo userdel -r pango 通常，在移除一个帐号时，我们可以手动修改 /etc/passwd 和 /etc/shadow 文件中该用户关联的行数据。如果该帐号只是「暂时冻结」，那么将 /etc/shadow 中第 8 栏（帐号失效日）设为 0 就可让该账户无法使用，但所有与该帐号相关的资料都会保留，使用 userdel 意味着「真的确定该用户不会在主机上的使用任何资料了」。 通常，一个用户在使用主机一段时间之后，会在更多其他的目录中产生属于他的文档，因此，在下达 userdel -r username 之前，先以 find / -user username 指令查出整个系统内属于 username 的档案，删除之后，再删除该用户帐号。 用户端指令 - id, finger, chfn, chshuseradd，usermod，userdel 都是系统管理员才能使用的命令，一般用户无法进行操作，有以下几个指令供一般用户使用： id: 该指令可以查询当前用户或其他用户的 UID/GID 值 finger: 查询用户的口令信息，将有 Login: 用户帐号信息 Name: 备注信息 Directory: Home 目录 Shell: shell 对应的程序 Never logged in: 登入信息 No mail: 查看 /var/spool/mail 中的信箱资料 No Plan: 查看 ~{username}/.plan 资料 chfn: 修改指纹信息，不常用 chsh: 修改 shell，参数如下： -l，列出所有可用的 shell，即 /etc/shells 中的内容 -s，修改为指定的 shell 群组管理群组管理涉及新增，修改和删除，群组的内容与以下两个档案有关： /etc/group /etc/gshadow 新增群组 - groupadd使用 groupadd 来新增群组，该命令使用方法如下：1234$ groupadd [-g gid] [-r] 群组名称选项与参数：-g ：指定群组 GID-r ：指定该群组为系统群组，与 /etc/login.defs 内的 GID_MIN 有关 执行命令查看新建的群组：123$ nano /etc/group...&lt;your-new-group-name&gt;:x:&lt;gid&gt;: 该命令查询 /etc/group 文件，该文件是 linux 系统保存所有群组的数据库，每一行代表一个群组，每行的值由 3 个 : 分隔为 4 栏不同的值，其具体指： 群组名称 群组密码，以 x 表示，引用 /etc/gshadow 的第 2 栏 群组 id 该群组包含的用户名称，每个用户名称由 , 分隔 x 表示该群组的密码，其在 /etc/gshadow 文件中对应第 2 栏的值，gshadow 文件保存了所有群组的详细配置，但只有拥有 root 权限的用户才能查看该文件。由于该群组刚刚创建，没有指定任何用户，故该值为空。 查看 /etc/gshadow 文件可以看到对应的行，其格式如下：1&lt;your-new-group-name&gt;:!::usernames 这个文件内的格式几乎与 /etc/group 一摸一样，第 2 栏是密码栏，如果密码栏为 ‘!’ 或空，表示该群组不具有群组管理员： 群组名称 密码栏，若为 ‘!’ 表示无合法密码，无群组管理员 群组管理员的帐号 所有加入该群组的帐号，与 /etc/group 内容相同 修改群组 - groupmod与 usermod 类似，groupmod 指令用于对已有群组的信息进行修改1234$ groupmod [-g gid] [-n group_name] 群组名选项与参数：-g ：修改既有的 GID 值；-n ：修改既有的群组名称 一个群组创建之后，为了避免引起不必要的错乱，通常不建议随意修改其 GID 删除群组 - groupdel1groupdel [groupname] 使用 groupdel 来删除已有的群组，如果有用户帐号已经关联一个群组作为其初始群组，将无法直接删除该群组，否则当用户登入系统后，系统将找不到其对应的群组。想要删除该群组，必须： 修改与之关联的用户的初始群组 删除该用户，再删除群组 群组管理员 - gpasswd1234567891011$ gpasswd groupname $ gpasswd [-A user1,...] [-M user3,...] groupname $ gpasswd [-rR] groupname 选项与参数：若没有任何参数时，表示给予 groupname 一个密码(/etc/gshadow)-A ：将 groupname 的主控权交由参数代表的多个用户管理(该群组的管理员)-M ：将某些帐号加入这个群组当中！-r ：将 groupname 的密码移除-R ：让 groupname 的密码栏失效-a ：将用户加入到 groupname 这个群组中-d ：将用户移除 groupname 这个群组中 初始群组，次要群组和有效群组在执行 useradd 命令新建用户时，使用 -g 命令指定初始群组，该群组的 GID 被写入到 /etc/passwd 对应的 GID 栏位，而 -G 指定的次要群组则将用户名写入 /etc/group 第 4 栏。 当用户登入系统进入 shell 环境后，系统总是以该用户所在的初始群组作为有效群组，即，当用户执行类似 touch 的指令创建新的文件或文件夹时，其权限会给予用户当前的有效群组。执行 groups 可查看当前登录用户所属的所有群组，排在第一位的即表示当前有效群组。 可通过执行 newgrp 指令将用户所属的另一个群组切换为当前有效群组，该动作导致用户进入另一个 shell 环境，当用户完成操作不再需要该群组支持时，应使用 exit 指令退回到之前的 shell 环境。]]></content>
      <categories>
        <category>Linux Basic</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 基础 - 磁盘分区(df/du/lsblk/blkid/gdisk/mkfs/mount/umount)]]></title>
    <url>%2Flinux-partition%2F</url>
    <content type="text"><![CDATA[参考资料: 主机规划与磁盘分区 本文索引: 前言 硬盘和分区方式 MSDOS(MBR) GPT(Guid partition table) BIOS UEFI(Unified Extensible Firmware Interface) 存储 df 命令 du 命令 lsblk 命令 blkid 命令 fdisk/gdisk - 磁盘分区 mkfs - 对分区建立文件系统(格式化) mount 挂载分区 查看当前挂载的信息 卸载分区 开机自动挂载 前言Linux 所有的设备都以档案的形式参与到目录树中，包括磁盘分区，通常，SATA/USB 都是以 SCSI 模块驱动的，所以这些接口在系统中相当的档案名出现。 物理磁盘以 /dev/sd[ad] 形式在档案系统中出现，如一台电脑有 6 个 SATA 口，第一和第五分别插入了硬盘，此时两者以 /dev/sda 和 /dev/sdb 在档案系统中呈现 虚拟化之后的磁盘以 /dev/vd[ad] 形式在档案系统中出现 硬盘和分区方式物理硬盘以磁盘、机械臂、磁碟头与主轴马达组成，资料都写入在磁盘上，磁盘又分为「磁区(Sector)」与「磁轨(Track)」两种单位，其中磁区的物理量有两种大小: 512 字节和 4K 字节。 MSDOS(MBR)Master Boot Record，主开机记录，早期的 Windows 系统对硬盘进行分区的方式，其以第一磁区(512 字节)记录 「开机管理程序」: 安装开机管理程序的地方，446 字节 「分区表」: 记录硬盘分区的状态，64 字节 由于分区表仅 64 字节大小，所以一块硬盘最多只能包含 4 个分区的信息，这 4 个分区信息被称为「主要(Primary)分区」或「扩展分区(Extended)」，且分区的最小存储单位为「磁柱(cylinder)」。 每块硬盘的 MBR 区域仅允许一个扩展分区，而该扩展分区主要用于划出更多的「逻辑分区」，逻辑分区可使用的磁柱区域被划定在扩展分区边界内，如下图所示:这样，在 Linix 系统中的档案名为: P1:/dev/sda1 P2:/dev/sda2 L1:/dev/sda5 L2:/dev/sda6 L3:/dev/sda7 L4:/dev/sda8 L5:/dev/sda9 系统会保留 MBR 的 4 个分区编号，所以逻辑分区以 sda5 开始。由于分区是以「磁柱」为单位的连续磁盘空间，所以分区时尤其要注意主分区与逻辑分区的划分，例如，主分区 P2 与逻辑分区 L1 是无法合并的。而 L1 和 L2 则是可以合并的。 由于每个分区表仅有 16 字节，因此系统无法识别硬盘空间在 2.2TB 以上的硬盘。而每当操作系统需要读写磁盘，都要从 MBR 的分区表中读取参考信息，一旦该硬盘的第一个磁区，即 MBR 损坏了，那么整个硬盘就无法使用了。鉴于这诸多的限制，后来有了 GPT 分区表。 GPT(Guid partition table)GPT 已经支持 4K 磁区，但为了兼容以往的 512 字节磁区。GPT 使用「逻辑区块地址(Logic Block Address)」来划分整个硬盘，而 LBA 预设大小为 512 字节，从 0 开始编号，即第一个 LBA 磁区为 LBA0。GPT 磁盘分区的最小物理单位为磁区。 GPT 使用前 34 个 LBA 磁区来记录分区信息，这与 MBR 将所有分区信息记录在第一个磁区上不同，且硬盘的最后 33 个 LBA 磁区作为备份，结构如下:从上图可以看到: LBA0(MBR 兼容磁区): 该磁区为了与 MBR 兼容，也将其分为「开机管理程序(446 字节)」和分区表(64 字节)两部分，而这里的分区表仅存放一个特殊的分区，以表示此磁盘为 GPT 格式。 LBA1(GPT表头记录): 该磁区记录了分区表的位置与大小与备份分区表的磁区位置。 LBA2 ~ 33(实际记录分区信息): 从 LBA2 开始，每个 LBA 都可以记录 4 个分区记录，所以默认情况下，最多可以支持 4 * 32 个分区，而每个 LBA 磁区容量为 512 字节，因此每个分区信息可用 128 字节空间(不同于 MBR 16 字节)，这可以识别高达 1ZB 的硬盘容量。 GPT 分区表也没有了主分区，扩展分区和逻辑分区的概念，每个分区都独立存在。然而并不是所有操作系统都能够读取 GPT 的硬盘分区格式，这取决于「开机引导程序(BIOS 和 UEFI)」。 BIOS没有软件程序的硬件是没有用的，操作系统的诞生是为了更好的调配各个硬件资源，但操作系统并不是电脑执行的第一个软件程序，主板首先加载的是写入主板上的开机引导程序，又称固件。 电脑开机后 主板首先启动固件的 BIOS BIOS 分析电脑有哪些设备，找到其第一个磁区的 MBR 位置，然后读取 446 字节的「开机管理程序」，然后 BIOS 将退出，全权交给开机管理程序(Boot Loader) Boot Loader 是由操作系统提供的，因此它认识操作系统提供的文件系统以及启动操作系统所需的核心文件的位置，一旦操作系统的核心文件启动，后续的工作就交给操作系统了。 BIOS 和 MBR 都是硬件支持的功能，而 Boot Loader 则是操作系统安装在 MBR 上的一个软件程序，Boot Loader 提供了: 提供选单，用户可以选择不同的开机项目 加载核心文件，启动操作系统 转交给其他 Loader UEFI(Unified Extensible Firmware Interface)UEFI 使用 C 语言，比起使用组合语言的传统 BIOS 更容易开发，同时支持了更多的功能，UEFI 更像是一个小型的操作系统，UEFI 大多用来作为操作系统启动之前的硬件检测、开机管理、软件设置等目的，一旦操作系统启动，UEFI 就会停止工作。更重要的是，UEFI 可以直接取得 GPT 分区表，并同时兼容 MBR 分区表。 存储Linux 系统内的所有资料都是以文件的形态呈现的，因此整个 Linux 系统就是一个目录树，以根目录为根向下延伸。而文件和目录其实是放置在磁盘分区中，「挂载(mount)」就是目录树与磁盘分区的粘合剂。 挂载是将磁盘分区的资料放在目标目录下。进入该目录，就进入了该磁盘分区，如下图所示: df 命令df 命令用来查阅系统各个分区的磁盘用量，例如:例如:123456789101112$ df -hTFilesystem Type Size Used Avail Use% Mounted on/dev/root ext4 15G 5.9G 8.1G 43% /devtmpfs devtmpfs 460M 0 460M 0% /devtmpfs tmpfs 464M 20K 464M 1% /dev/shmtmpfs tmpfs 464M 48M 416M 11% /runtmpfs tmpfs 5.0M 4.0K 5.0M 1% /run/locktmpfs tmpfs 464M 0 464M 0% /sys/fs/cgroup/dev/mmcblk0p1 vfat 43M 22M 21M 51% /boot/dev/sda1 xfs 3.7T 2.2T 1.5T 60% /mnt/sharedtmpfs tmpfs 93M 0 93M 0% /run/user/1000 常用选项与参数有: -a: 列出所有文件系统，包括系统特有的 /proc 等文件系统； -k: 以 KBytes 的容量显示各文件系统； -m: 以 MBytes 的容量显示各文件系统； -h: 以人们较易阅读的 GBytes, MBytes, KBytes 等格式自行显示； -H: 以 M=1000K 取代 M=1024K 的进位方式； -T: 连同该 partition 的 filesystem 名称(如 xfs)也列出； -i: 不用磁碟容量，而以 inode 的数量来显示 du 命令du 命令用于查询目标目录或文件的磁盘占用量，例如:123$ sudo du -hs ./1.4G . 常用选项与参数有: -a: 列出所有 entry -h: 以阅读友好的格式展示数据 -s: 仅展示当前目录下的统计数据 lsblk 命令list block device 的缩写，列出所有存储设置:123456$ lsblk -dmpNAME SIZE OWNER GROUP MODE/dev/sda 3.7T root disk brw-rw----/dev/sdb 465.8G root disk brw-rw----/dev/mmcblk0 14.8G root disk brw-rw---- 常用可选参数有: -d: 仅展示存储设备本身，而不展示分区 -f: 包括文件系统名称 -m: 包括权限信息 -p: 展示完整文件名称 -t: 包含详细信息 blkid 命令显式存储设置的 UUID 信息:123456$ (sudo) blkid/dev/mmcblk0p1: LABEL="boot" UUID="A365-6756" TYPE="vfat" PARTUUID="358ecf74-01"/dev/mmcblk0p2: LABEL="rootfs" UUID="90a83158-560d-48ee-9de9-40c51d93c287" TYPE="ext4" PARTUUID="358ecf74-02"/dev/sda1: LABEL="NT2" UUID="fef3c944-4e1e-4aeb-9b79-6f567c50ea6c" TYPE="xfs" PARTLABEL="Linux filesystem" PARTUUID="7f99994b-2b44-4f75-a55e-170d32f1c41e"/dev/mmcblk0: PTUUID="358ecf74" PTTYPE="dos" fdisk/gdisk - 磁盘分区MBR 分区使用 fdisk 命令，GPT 分区使用 gdisk 命令gdisk 只有 root 用户才能执行，对目标设备进行 GPT 分区:12345678910111213$ gdisk /dev/sdbGPT fdisk (gdisk) version 1.0.1Partition table scan: MBR: not present BSD: not present APM: not present GPT: not presentCreating new GPT entries.Command (? for help): ? 根据提示输入 ?:1234567891011121314151617Command (? for help): ?b back up GPT data to a filec change a partition's named delete a partitioni show detailed information on a partitionl list known partition typesn add a new partitiono create a new empty GUID partition table (GPT)p print the partition tableq quit without saving changesr recovery and transformation options (experts only)s sort partitionst change a partition's type codev verify diskw write table to disk and exitx extra functionality (experts only)? print this menu 现在，假设我们需要在该存储设备上创建一个单一的分区，并且文件系统为 xfs，输入 p:12345678910Command (? for help): pDisk /dev/sdb: 976773056 sectors, 465.8 GiBLogical sector size: 512 bytesDisk identifier (GUID): 6BA9CCEA-BF10-4D3D-99FA-0016432D489APartition table holds up to 128 entriesFirst usable sector is 34, last usable sector is 976773022Partitions will be aligned on 2048-sector boundariesTotal free space is 976772989 sectors (465.8 GiB)Number Start (sector) End (sector) Size Code Name 可以看到该存储设备上没有任何分区，输入 n 新建一个分区:1234567Command (? for help): nPartition number (1-128, default 1):First sector (34-976773022, default = 2048) or &#123;+-&#125;size&#123;KMGTP&#125;:Last sector (2048-976773022, default = 976773022) or &#123;+-&#125;size&#123;KMGTP&#125;:Current type is 'Linux filesystem'Hex code or GUID (L to show codes, Enter = 8300):Changed type of partition to 'Linux filesystem' 过程中会要求输入第一磁区号，最后磁驱号(默认会占满整个硬盘)，文件系统等，这里均采用默认值。完成之后再次输入 p，新的分区已经准备好:1234567891011Command (? for help): pDisk /dev/sdb: 976773056 sectors, 465.8 GiBLogical sector size: 512 bytesDisk identifier (GUID): 6BA9CCEA-BF10-4D3D-99FA-0016432D489APartition table holds up to 128 entriesFirst usable sector is 34, last usable sector is 976773022Partitions will be aligned on 2048-sector boundariesTotal free space is 2014 sectors (1007.0 KiB)Number Start (sector) End (sector) Size Code Name 1 2048 976773022 465.8 GiB 8300 Linux filesystem 由于创建或删除分区是敏感操作，此时需要输入 w 确认操作或输入 q 放弃操作12345678Command (? for help): wFinal checks complete. About to write GPT data. THIS WILL OVERWRITE EXISTINGPARTITIONS!!Do you want to proceed? (Y/N): yOK; writing new GUID partition table (GPT) to /dev/sdb.The operation has completed successfully. 现在，执行 lsblk /dev/sdb 确认该分区已经创建:12345$ lsblk /dev/sdbNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsdb 8:16 0 465.8G 0 disk└─sdb1 8:17 0 465.8G 0 part mkfs - 对分区建立文件系统(格式化)分区创建完成之后，接下来就是要格式化分区以创建目标文件系统，mkfs(make filesystem) 是创建文件系统 - 即格式化分区的指令，根据目标文件系统类型的不同，执行不同的子命令，例如，此处要创建的 xfs 文件系统，那么应该使用 mkfs.xfs 命令:1234567891011$ sudo mkfs.xfs /dev/sdb1meta-data=/dev/sdb1 isize=512 agcount=4, agsize=30524093 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=1, sparse=0, rmapbt=0, reflink=0data = bsize=4096 blocks=122096371, imaxpct=25 = sunit=0 swidth=0 blksnaming =version 2 bsize=4096 ascii-ci=0 ftype=1log =internal log bsize=4096 blocks=59617, version=2 = sectsz=512 sunit=0 blks, lazy-count=1realtime =none extsz=4096 blocks=0, rtextents=0 执行 lsblk -mp 查看当前可用分区:12345678910$ lsblk -mpNAME SIZE OWNER GROUP MODE/dev/sda 3.7T root disk brw-rw----└─/dev/sda1 3.7T root disk brw-rw----/dev/sdb 465.8G root disk brw-rw----└─/dev/sdb1 465.8G root disk brw-rw----/dev/mmcblk0 14.8G root disk brw-rw----├─/dev/mmcblk0p1 43.1M root disk brw-rw----└─/dev/mmcblk0p2 14.7G root disk brw-rw---- mount 挂载分区分区都以是目录作为挂载点供系统使用，而该目录应该遵循: 该目录已经存在 同一个目录不应该重复挂载多个分区 作为挂载点的目录，理论上应该都是空目录 例如，现在将 /dev/sdb1 挂载到 /mnt/storage1 目录下，首先创建该目录:123456789$ ls /mnt/ -ldrwxrwxr-x+ 13 pi pi 4096 Dec 28 08:17 shared$ mkdir /mnt/storage1$ ls /mnt/ -ldrwxrwxr-x+ 13 pi pi 4096 Dec 28 08:17 shareddrwxr-xr-x 2 pi pi 4096 Jan 11 13:57 storage1 将分区挂载到该目录下:1$ mount /dev/sdb1 /mnt/storage1 常见选项与参数有: -a: 将 /etc/fstab 中所有未挂载的分区全部挂载 -l: 仅执行 mount 命名时将显式当前挂载的信息，加上 -l 可包括 Label 名称 -t: 指定欲挂载分区的文件系统，常见的 Linux 支持的类型有 xfs、ext3、ext4 -n: 默认情况下，系统会将实际挂载的信息写入 /etc/mtab 中，但在某些情况下(例如单人维护摸下下)为了避免问题想要不写入，则使用 -n 选项 -o: 可跟一些常用的参数，例如帐号、密码、读写权限等: async，sync: 表示该文件系统使用同步写入(sync)还是异步写入(async)-atime, noatime: 是否修改档案的读取时间，为了性能考虑，某些情况下可使用 noatime ro, rw: 挂载的文件系统为只读(ro)还是可读可写(rw) auto, noauto: 是否允许此分区可被 mount -a 自动挂载 dev, nodev: 是否允许该分区建立存储设备文件 suid, nosuid: 是否允许此分区包含 suid/sgid 文件格式 exec, noexec: 是否允许可在此分区执行 binary 程序 user, nouser: 是否允许其他用户执行 mount。一般来说，mount 仅有 root 用户能够执行，但添加 user 参数可让其他用户也能对该分区执行 mount nofail: 不进行挂载错误检查，以避免启动挂载错误导致系统无法正常启动 defaults: 预设值为: rw, suid, dev, exec, auto, nouser, async remount: 重新挂载，在系统出错或重新更新参数时，很有用。 查看当前挂载的信息1234$ mount | grep sd/dev/sda1 on /mnt/shared type xfs (rw,relatime,attr2,inode64,noquota)/dev/sdb1 on /mnt/storage1 type xfs (rw,relatime,attr2,inode64,noquota) 卸载分区使用 umount 命令来执行卸载分区的命令:1$ umount [设备档案文件或挂载点] 常见选项和参数有: -f: 强制卸载 -l: 立即卸载，比 -f 更疯狂的参数 n: 不更新 /etc/mtab 的情况下卸载 开机自动挂载查看存储设备的 UUID:12345$ lsblk -fNAME FSTYPE LABEL UUID MOUNTPOINTsdb└─sdb1 xfs 235669cd-d06b-4630-8d3e-5881287ba057 /mnt/storage1 编辑 /etc/fstab 以添加挂载点:123$ nano /etc/fstabUUID="235669cd-d06b-4630-8d3e-5881287ba057" /mnt/storage1 xfs defaults,noatime,user 0 0 执行 mount -a 测试自动挂载(特别重要)，如果 /etc/fstab 中有语法错误，Linux 系统将无法正常启动，必须进入紧急模式进行恢复，参考 Emergency Mode due to fstab 再执行 df 查看刚刚添加的挂载点是不是已经挂载:1234$ dfFilesystem 1K-blocks Used Available Use% Mounted on/dev/sdb1 488147016 280117988 208029028 58% /mnt/storage1]]></content>
      <categories>
        <category>Linux Basic</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git Module 与嵌套 Repository]]></title>
    <url>%2Fgit-embeded-repository%2F</url>
    <content type="text"><![CDATA[本文大纲: 添加一个 Submodule 获取子项目更新 Git Module Git 可将一个 Git repository 作为另外一个 Git repository 的子目录，这允许在你的项目中引用另一个项目，并将两个项目分开维护。假设我们希望将一个现有的 Git repository 作为一个 submodule 添加到当前工作项目上，执行 git submodule add 并跟上绝对或相对 url 作为参数来添加 submodule。 Submodules 至少有两种应用场景： 项目依赖一个外部项目，并希望将两者分开维护 将一个大项目拆分为多个小项目并将它们黏合在一起 添加一个 Submodule1$ git submodule add https://github.com/chaconinc/DbConnector 默认情况下，submodules 将使用与 Git repository 一致的名称作为 directory 添加到当前项目的根目录下，在这个例子中为 “DbConnector”。也可以在命令最后指定一个自定义的路径作为该 submodule 的目录。 执行 git status，看到以下变化：123456789$ git statusOn branch masterYour branch is up-to-date with 'origin/master'.Changes to be committed: (use "git reset HEAD &lt;file&gt;..." to unstage) new file: .gitmodules new file: DbConnector 一个新的文件 .gitmodules 被创建了，该配置文件存储了当前项目与 submodule 之间的关系映射，以下是其内容举例：123[submodule "DbConnector"] path = DbConnector url = https://github.com/chaconinc/DbConnector 如果包含多个 submodule，那么该文件会有更多的 entry，值得注意的是，该文件一起受 git 版本控制。 作为 submodule 被管理的 Git repository 将不会受到父级 Git repository 的状态追踪。因此，在当前项目执行 git push origin master 之后，从另一台机器 git clone 父级项目时，将只包含 .gitmodules 文件及对应于各个 submodules 的空的 directory。123456789101112131415161718192021222324$ git clone https://github.com/chaconinc/MainProjectCloning into 'MainProject'...remote: Counting objects: 14, done.remote: Compressing objects: 100% (13/13), done.remote: Total 14 (delta 1), reused 13 (delta 0)Unpacking objects: 100% (14/14), done.Checking connectivity... done.$ cd MainProject$ ls -latotal 16drwxr-xr-x 9 schacon staff 306 Sep 17 15:21 .drwxr-xr-x 7 schacon staff 238 Sep 17 15:21 ..drwxr-xr-x 13 schacon staff 442 Sep 17 15:21 .git-rw-r--r-- 1 schacon staff 92 Sep 17 15:21 .gitmodulesdrwxr-xr-x 2 schacon staff 68 Sep 17 15:21 DbConnector-rw-r--r-- 1 schacon staff 756 Sep 17 15:21 Makefiledrwxr-xr-x 3 schacon staff 102 Sep 17 15:21 includesdrwxr-xr-x 4 schacon staff 136 Sep 17 15:21 scriptsdrwxr-xr-x 4 schacon staff 136 Sep 17 15:21 src$ cd DbConnector/$ ls$ 要获得与提交之前的 submodules，一种方式是执行 git submodule init 指令来初始化本地配置和 git submodule update 从 submodules 对应的地址 clone 所有数据并签出对应的 commit。12$ git submodule init$ git submodule update 或者：1git submodule update --init --recursive 另外一种方式是在执行 git clone 父级项目时添加 --recurse-submodules 参数，将一次完成父级项目及所有 submodules 的克隆1$ git clone --recurse-submodules https://github.com/chaconinc/MainProject 之后，如果希望同父级项目一同获取所有 submodules 的更新，执行1git pull --recurse-submodules 获取子项目更新使用 Git Submodules 一个最典型的应用场景是，引用一个由外部维护的 Git repository，仅仅使用它而不做任何修改。 首先导航到指定 submodule 所在目录，执行 git fetch 和 git merge 获取本地更新。12345678910$ git fetchFrom https://github.com/chaconinc/DbConnector c3f01dc..d0354fc master -&gt; origin/master$ git merge origin/masterUpdating c3f01dc..d0354fcFast-forward scripts/connect.sh | 1 + src/db.c | 1 + 2 files changed, 2 insertions(+) 回到父级项目目录，执行 git diff --submodule，可以看到 submodules 已经获得更新并列出一个添加到该项目的 commit 列表。如果不想每次在执行 git diff 时都输入 --submodule 参数，可在 git config 文件中添加该命令的默认参数或执行 git config diff.submodule log，之后再执行 diff 将会将列出所有子项目更新日志。12345$ git config --global diff.submodule log$ git diffSubmodule DbConnector c3f01dc..d0354fc: &gt; more efficient db routine &gt; better connection routine 此时如果主项目提交至远程 Git repository，之后其他开发人员再获取代码时将会得到与主项目同步后的 submodule。 另外一种方式是直接在主项目目录下执行 git submodule update --remote 命令，git 将自动更新所有 submodules。12345678$ git submodule update --remote DbConnectorremote: Counting objects: 4, done.remote: Compressing objects: 100% (2/2), done.remote: Total 4 (delta 2), reused 4 (delta 2)Unpacking objects: 100% (4/4), done.From https://github.com/chaconinc/DbConnector 3f19983..d0354fc master -&gt; origin/masterSubmodule path 'DbConnector': checked out 'd0354fc054692d3906c85c3af05ddce39a1c0644' 该命令将默认以所有 submodules 的 master branch 作为更新依据，如何以另外一个 branch name 作为默认更新的依据，参考下文的Git Module 可在 git config 文件中为 status 命令添加默认参数或执行 git config status.submodulesummary 1，之后执行 git status 显示简短的摘要1234567891011121314151617$ git config status.submodulesummary 1$ git statusOn branch masterYour branch is up-to-date with 'origin/master'.Changes not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) modified: .gitmodules modified: DbConnector (new commits)Submodules changed but not updated:* DbConnector c3f01dc...c87d55d (4): &gt; catch non-null terminated lines Git Modulesubmodule 是嵌套在另一个 repository 中的 repository，submodule 有自己的版本历史，包含子模块的 repository 称为 superproject .gitmodules 放置在一个 Git 工作树的顶级目录下，该文件是一个匹配 git-config 的文本文件。该文件的每个 subsection 代表一个 submodule 的配置项，subsection 的值为 submodule 的名称，如果不显式指定 name 选项，该名称值将取该 submodule 的路径作为名称。同时，每一个 subsection 包含以下必填值： submodule.&lt;name&gt;.path: 相对于 Git working tree 顶层目录的路径，默认迁出位置，该值不能以 / 结尾，所有 submodule 的路径必须唯一。 submodule.&lt;name&gt;.url: 克隆 submodule 的 url，该值可以是一个绝对 url，也可以 ./ 或 ../ 起头作为 superproject origin repository 的相对 url。 同时，还有以下可选参数： submodule.&lt;name&gt;.update: 定义 submodue 的默认更新行为，在 superproject 执行 git submodule update 指令时如何更新 submodule.&lt;name&gt;.branch: 提供用于检测更新的 branch 名称，如果不指定该值，默认取 master。. 作为特殊值告知 git 取与当前 repository 当前 branch 一致的名称 submodule.&lt;name&gt;.fetchRecurseSubmodules: 该用于控制对 submodule 的递归 fetch，如果在 superproject 的 .git/config 中已经设置了该值，那么该值将覆盖在 .gitmodules 中的值。两者均可被 git fetch 和 git pull 使用 --[no-]recurse-submodules 选项覆盖 submodule.&lt;name&gt;.ignore: git status 和比较器如何对已经做出修改的 submodules 进行反应，可取以下值 all: submodule 永远不会被认为已经 modified，但在 staged 后会显示出来 dirty: 所有对 submodule 工作目录下做出的修改将被忽略，只有其 Head 与 superproject 的记录状态会纳入考虑 untracked: 只有 untracked 文件会被忽略 none: 所有修改都不会被忽略 submodule.&lt;name&gt;.shallow: 当设置为 true 时，该 submodule 会执行浅 clone(只包含一层深度的历史信息) 例子：123[submodule "libfoo"] path = include/foo url = git://foo.com/git/lib.git 文件系统中，一个 submodule 通常 在 superproject 的 $GID_DIR/modules/ 有一个 Git 目录 在 superproject 工作目录下有一个对应的子目录作为其工作目录 在其工作目录中根目录下包含一个 .git 文件指向 (1) 所在的位置 假设一个 submodule 的 Git 目录位于 $GIT_DIR/modules/foo/，工作目录位于 path/to/bar/，superproject 通过一个 path/to/bar/ 目录树下的 gitlink 和 .gitmodules 文件中的一个条目 submodule.foo.path = path/to/bar 来追踪这个 submodule。 参考资料： https://git-scm.com/book/en/v2/Git-Tools-Submodules https://git-scm.com/docs/gitmodules https://git-scm.com/docs/gitsubmodules]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>embeded-repository</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git - 推送至远程仓库]]></title>
    <url>%2Fgit-push-to-remote-repository%2F</url>
    <content type="text"><![CDATA[生成仓库目录12mkdir -p development/hobby-project/my-first-git-repositorycd development/hobby-project/my-first-git-repository 不带任何参数的 mkdir 命令将不会递归创建目录，-p 选项在任何层级的目录不存在的情况下递归创建目录 初始化仓库现在，development/hobby-project/my-first-git-repository 将作为远程 repository 根目录，执行：12$ sudo git init --bareInitialized empty Git repository in /Users/XXX/development/hobby-project/my-first-git-repository/ git init --bare 参数指明该 repository 用于分布式版本控制的中心仓库，git 将仅保存历史记录，一般来说服务器上的仓库多使用 --bare 创建，其目的在于分发而非修改，参考 what is a git bare repository。 使用 local protocol 在本地拉取 git repo:1$ git clone file://&#123;path-to-your-repo&#125; git 支持 4 种 protocol，具体参考Git on the Server - The Protocols。]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>remote-repository</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo 及 NexT 定制]]></title>
    <url>%2Fhexo-next-customization%2F</url>
    <content type="text"><![CDATA[本文索引: 前言 配置搜索引擎优化 安装站点地图插件 向谷歌提交站点地图 向百度站长平台提交站点地图 百度站长平台自动提交及主动提交 自动提交 手动提交 与站点配置相关的定制 设置页面文章的篇数 与主题配置相关的定制 修改主题文字的显示文本 设置 Copyright 声明 开启博文打赏功能 为指定文章添加打赏功能 添加「Fork me on Github」 添加置顶文件标识 修改文章底部标签的图标 前言针对 Hexo 博客的定制化分为两部分，一部分仅与站点配置文件有关，主项目跟踪文件的变化，第二部分与主题配置文件有关，虽然 NexT 主题提供了强大的定制空间，但目前没有找到好的办法将定制化的内容由主 Repo 跟踪并在生成阶段替换这些内容。因此现阶段不得不将已经修改的定制化文件单独备份，以防下次主题更新之后覆盖了原有的内容。以下将分开进行讨论。 配置搜索引擎优化安装站点地图插件安装站点地图相关的组件，一个用于 google 搜索引擎优化，一个用于百度站点优化。12$ npm install hexo-generator-sitemap --save$ npm install hexo-generator-baidu-sitemap --save 在站点配置文件中添加如下代码:12345678910Plugins:- hexo-generator-baidu-sitemap- hexo-generator-sitemap# Sitemapbaidusitemap: path: baidusitemap.xmlsitemap: path: sitemap.xml 重新生成站点:12$ hexo clean$ hexo g 在 public 文件夹下发现多了 sitemap.xml 和 baidusitemap.xml 即表示生成成功了，接下来重新部署一次站点。 同时将博客部署至 Github Pages 及 Coding Pages修改 站点配置文件 中的 deploy 配置节，如下:1234567deploy: - type: git repo: https://github.com/BerdyPango/BerdyPango.github.io.git branch: master - type: git repo: https://git.coding.net/frosthe/blogs.git branch: master 这样，当每次执行 hexo d 时都将同时推送至 Github 和 Coding。 在 Coding Pages 绑定自定义域名时 SSL 证书无法获取当在 Coding 绑定自定义域名后，阿里云的域名解析记录如下: 此时为 Coding Pages 申请 SSL 证书会失败，原因是同一个二级域名记录解析到了两个记录值，只是线路不一样，而 Coding 的服务器也在境外，导致 Coding 在向 CA 申请证书时获取了错误的域名解析记录值。解决办法是，在申请 Coding Pages 的 SSL 证书前，先暂停境外路线的解析记录，申请成功之后，再启用该条记录。 向谷歌提交站点地图登陆 Google Web Master，找到左侧的提交站点地图的位置: 向百度站长平台提交站点地图登陆 百度搜索资源平台，按照步骤添加并验证站点，之后百度可能需要一天时间来验证站点的 HTTPS。 百度站长平台自动提交及主动提交自动提交修改主题配置文件中的如下节点:1baidu_push: true 在目录 \themes\next\layout\_third-party\seo\baidu-push.swig 中的 JS 替换为:1234567891011121314&lt;script&gt;(function()&#123; var bp = document.createElement('script'); var curProtocol = window.location.protocol.split(':')[0]; if (curProtocol === 'https') &#123; bp.src = 'https://zz.bdstatic.com/linksubmit/push.js'; &#125; else &#123; bp.src = 'http://push.zhanzhang.baidu.com/push.js'; &#125; var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(bp, s);&#125;)();&lt;/script&gt; 手动提交Github 禁止百度爬虫访问博客，导致博客无法被百度收录，百度提供了主动提交的接口，使用主动推送还将: 及时发现：可以缩短百度爬虫发现您站点新链接的时间，使新发布的页面可以在第一时间被百度收录 保护原创：对于网站的最新原创内容，使用主动推送功能可以快速通知到百度，使内容可以在转发之前被百度发现 有作者专门制作了针对 hexo 手动提交百度链接的链接生成器: https://github.com/huiwang/hexo-baidu-url-submit 安装该插件:1$ npm install hexo-baidu-url-submit --save 插件的配置文件中包含秘钥，请把 Hexo 博客源文件托管到私有仓库里，密钥可从百度搜索资源平台 查找。 在站点配置文件中加入以下内容:12345baidu_url_submit: count: 3 ## 比如3，代表提交最新的三个链接 host: blog.example.com ## 在百度站长平台中注册的域名 token: your_token ## 请注意这是您的秘钥，请不要发布在公众仓库里 path: baidu_urls.txt ## 文本文档的地址，新链接会保存在此文本文档里 最后，在站点配置文件中添加新的 deployer:12345deploy: - type: git repo: https://your-hexo-pages-repo.git branch: master - type: baidu_url_submitter 这样，当执行 hexo g 时将生成包含链接的 baidu_urls.txt 文件，在执行 hexo d 时提取该文件并推送至百度搜索引擎。 与站点配置相关的定制设置页面文章的篇数在 Hexo 里可以为首页和归档页面设置不同的文章篇数，但可能需要安装 Hexo 插件。详细步骤如下。123npm install --save hexo-generator-indexnpm install --save hexo-generator-archivenpm install --save hexo-generator-tag 安装完成后，在站点配置文件中设定如下:12345678910index_generator: per_page: 5archive_generator: per_page: 20 yearly: true monthly: truetag_generator: per_page: 10 与主题配置相关的定制这部分将涉及替换主题 Repo 的某些文件 修改主题文字的显示文本在主题 repo 下的 language 目录下，有针对各个 key 在不同语言下的显示名称，此处找到 languages/default.yml 文件中的对应的键，改为自定义的值。 同时，在站点配置文件中要将 language 设置为对应的语言才能生效 设置 Copyright 声明在主题配置文件中，添加如下节点:1234post_copyright: enable: true license: CC BY-NC-SA 3.0 license_url: https://creativecommons.org/licenses/by-nc-sa/3.0/ 可在 themes/next/layout/_macro/post-copyright.swig 编辑显示细节:1234567891011121314&lt;ul class="post-copyright"&gt; &lt;li class="post-copyright-author"&gt; &lt;strong&gt;&#123;&#123; __('post.copyright.author') + __('symbol.colon') &#125;&#125;&lt;/strong&gt; &#123;&#123; post.author | default(config.author) &#125;&#125; &lt;/li&gt; &lt;li class="post-copyright-link"&gt; &lt;strong&gt;&#123;&#123; __('post.copyright.link') + __('symbol.colon') &#125;&#125;&lt;/strong&gt; &lt;a href="&#123;&#123; post.url | default(post.permalink) &#125;&#125;" title="&#123;&#123; post.title &#125;&#125;"&gt;&#123;&#123; post.url | default(post.permalink) &#125;&#125;&lt;/a&gt; &lt;/li&gt; &lt;li class="post-copyright-license"&gt; &lt;strong&gt;&#123;&#123; __('post.copyright.license_title') + __('symbol.colon') &#125;&#125; &lt;/strong&gt; &#123;&#123; __('post.copyright.license_content', theme.post_copyright.license_url, theme.post_copyright.license) &#125;&#125; &lt;/li&gt;&lt;/ul&gt; 开启博文打赏功能在 主题配置文件 中加入如下配置信息，并分别填入微信和支付宝的付款码图片，图片支持 .jpg 及 .png 格式，可放入类似 /source/assets/ 下。123reward_comment: 坚持原创技术分享，您的支持将鼓励我继续创作！wechatpay: /path/to/wechat-reward-imagealipay: /path/to/alipay-reward-image 为指定文章添加打赏功能找到 /themes/next/layout/_macro/post.swig 中的:12345&#123;% if (theme.alipay or theme.wechatpay or theme.bitcoin) and not is_index %&#125; &lt;div&gt; &#123;% include 'reward.swig' %&#125; &lt;/div&gt;&#123;% endif %&#125; 在其外套上一层 if post.reward，然后在指定文章的 Front-matter 中指定 reward: true 即可:1234567&#123;% if page.reward %&#125; &#123;% if (theme.alipay or theme.wechatpay or theme.bitcoin) and not is_index %&#125; &lt;div&gt; &#123;% include 'reward.swig' %&#125; &lt;/div&gt; &#123;% endif %&#125;&#123;% endif %&#125; copyright 与 reward 功能都可能存在于 css 文件没有引入的问题，目前找到的解决办法是将 /themes/next/source/css/_common/components/post/post.styl 文件中定位到12@import "post-reward";@import "post-copyright"; 两行，删除之后的 if 语句可解决，但其原因至今不明，参考 GitHub Issue。 添加「Fork me on Github」首先在 GitHub Ribbons 找到自己喜欢的风格:1&lt;a href="https://github.com/you"&gt;&lt;img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"&gt;&lt;/a&gt; 其中，将 href=&quot;&quot; 改为自己的 GitHub 链接。接下来将对应的代码粘贴到 themes/next/layout/_layout.swig headband 的下面: 添加置顶文件标识找到 /themes/next/layout/_macro/post.swig，搜索 &lt;div class=&quot;post-meta&quot;&gt;，在下一行添加以下代码:12345&#123;% if post.top %&#125; &lt;i class="fa fa-thumb-tack"&gt;&lt;/i&gt; &lt;font color=7D26CD&gt;Stick on Top&lt;/font&gt; &lt;span class="post-meta-divider"&gt;|&lt;/span&gt;&#123;% endif %&#125; 修改文章底部标签的图标找到 /themes/next/layout/_macro/post.swig，搜索 rel=&quot;tag&quot;，将 # 替换为 1&lt;i class="fa fa-tag"&gt;&lt;/i&gt;]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>next-theme</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建 Hexo 轻博客]]></title>
    <url>%2Fhexo-setup%2F</url>
    <content type="text"><![CDATA[本文索引: 前言 环境准备 初始化 配置 _config.yml 网站(site) 网址(url) 本地测试 部署到 Github Pages 为 Github Pages 指定自定义域名 前言如果你 希望摆脱对第三方云笔记的依赖 对 Git 有足够的了解 那么 Hexo 将是个人博客很好的一个选择。Hexo 是一个轻量级的基于 Markdown(.md) 的轻博客框架。 环境准备 Node.js 安装 hexo npm 包 git bash 客户端 hexo 是 npm 的一个包，首先从 Node.js 官网下载对应系统的安装包。Node.js 安装完成后会自动在环境变量中加入 npm cli 的路径，接着在 cli 中使用以下命令安装 hexo 包：1npm install -g hexo-cli 确认安装已经成功：1hexo version 初始化以下两种途径初始化 hexo： 首先创建指定目录作为 hexo 的根目录，在该目录下运行命令行工具，执行 hexo init，该命令会以当前目录作为 hexo 的根 启动命令行工具，执行 hexo init &lt;folder&gt; 初始化指定目录为 hexo 的根，随后执行 cd &lt;folder&gt; 导航到该目录 hexo init &lt;folder&gt; 命令中，如果 folder 所包含的目录层级中包含不存在的层级，该命令会自动创建该层级下的目录 初始化完成后，得到以下的目录结构：12345678.├── _config.yml├── package.json├── scaffolds├── source| ├── _drafts| └── _posts└── themes 在初始化完成后的目录中包含了 package.json 文件，意味着该项目有其自己的 npm 包依赖，执行 npm install 解析依赖并在本地安装。 配置 _config.yml_config.yml 文件包含了对 hexo 博客站点的配置信息。 网站(site) 参数 描述 title 网站标题 subtitle 网站副标题 description 网站描述 author 作者名字 language 网站使用的语言 timezone 时区 其中，description 主要用于 SEO，为搜索引擎提供一个关于站点的简单描述，通常建议包含网站的关键词。author 参数用于主题显示文章的作者。 网址(url) 参数 描述 默认值(示例值) url 根地址 http://www.your-site.conm/blog/ root 站点根目录 /blog/ permalink 文章的永久链接格式 :year/:month/:day/:title/ permalink_defaults 永久链接中各部分的默认值 永久链接是指，当执行 hexo s 或发布到 web server 之后，其生成文件的 url 组成策略，默认值为 :year/:month/:day/:title/，这意味着 url 将以分隔的日期值来定位文章。 url 和 root 总是成对修改，例如，想要把站点的根目录放在子目录 /blog 下，那么 root 的值应该修改为 /blog/，url 的值对应修改为 http://www.your-site.com/blog/。 官方文档中的网站存放于子目录的意思是，hexo 项目包含的是生成站点的源代码文件，包括 source/_posts 目录，均用于生成网站，而“网站”是指生成好之后的静态资源文件集。 更多配置详情参考官方文档 本地测试本地生成并 serve：123cd &lt;target-directory&gt;hexo ghexo server 此时在浏览器中访问 localhost 对应的端口号将看到一个新的模板页面已经生成成功，执行如下命令来创建新的文章，在 source/_posts 目录下一个对应的文件被创建1hexo new "my-first-post" 导航到该文件可以看到其模板内容 12345---title: my-first-postdate: 2018-03-01 02:51:53tags:--- 重新生成博客文章并启动 hexo server12hexo generatehexo server -o --debug -o 参数代表在成功 serve 立即打开一个浏览器窗口以访问站点的根页面，--debug 参数启用在控制台打印 debug 级别的日志信息，方便排错。hexo generate 可简写为 hexo g，hexo server 可简写为 hexo s 文章列表中已经列出刚刚创建的文章名称，进一步修改该文件，hexo server 将实时更新页面内容 部署到 Github Pages当站点准备就绪后，下一步就是要给它找个家，GitHub 为每个账号提供了站点寄宿服务——GitHub Pages，在 GitHub 中创建一个 username.github.io 的公开仓库，将 build 好的站点资源文件集 push 到该仓库，再访问唯一的 https://username.github.io/ 即可。 hexo 提供了自动部署机制，在 _config.yml 中找到 deploy 这一项：123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: git@github.com:username/username.github.io.git branch: master 部署的更多详情参考官方文档 为 Github Pages 指定自定义域名GitHub Pages 支持自定域名解析，假设已经有了一个根域名 example.com，可配置将 blog 二级域名指向 username.github.io，具体参考「官方指南」，Github Pages 接受使用 CNAME 记录将自定义域名指向 username.github.io，其实现原理是在站点根目录下放置一个名为 CNAME 的文件，其内容包含一行自定义域名值:1blog.example.com 该文件并不由 hexo 项目维护，所以每次运行 hexo d 之后该文件都将被删除。为了解决这个问题，可在 hexo 项目的 /source 目录下包含一个 CNAME 文件用于告知 Github Pages 自定义域名的值，在执行 hexo g 之后，生成的 public 文件夹也将包含该文件。这样，每次部署都会将该文件一同上传至 username.github.io 项目。]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
